\documentclass[sigplan,10pt,review,anonymous]{acmart}

% Packages {{{
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{graphs}
\usetikzlibrary{cd}
\usepackage{bussproofs}
\usepackage{stmaryrd}
% }}}

% Macros {{{

\newcommand{\kw}[1]{\ensuremath{ \textsf{#1} }}
\newcommand{\ifr}[1]{\ [{#1}]\ }
\newcommand{\ifrw}[2]{\ [{#1}]_{#2}\ }
\newcommand{\alt}{\ |\ }

\newcommand{\EC}{\kw{C}}
\newcommand{\simrel}{\kw{simrel}}

% Moves
\newcommand{\mcall}[3]{\kw{#1}({#2})@{#3}}
\newcommand{\pcall}[3]{%
  \underline{\mcall{#1}{#2}{#3}}%
}
\newcommand{\mret}[2]{{#1}@{#2}}
\newcommand{\pret}[2]{%
  \underline{\mret{#1}{#2}}%
}
\newcommand{\mretx}[3]{{#1}@{#2}/{#3}}
\newcommand{\pretx}[3]{%
  \underline{\mretx{#1}{#2}{#3}}%
}

% Pointers for justified sequences %{{{

% Parameters
\newcommand{\pshift}{1.6ex}
\newcommand{\pcdist}{2.5}
\newcommand{\pcangle}{60}

% Pointer hook
\newcommand{\ph}[1]{%
  \tikz[remember picture]{\coordinate (#1);}}

% Pointer to
\newcommand{\pt}[1]{%
  \rule{0pt}{1.4em}%
  \tikz[remember picture, overlay]{
    \draw[->]
      let \p{dest} = (#1),
          \n1 = {ln(veclen(\x{dest}, \y{dest}) + 1)},
          \p1 = ($(0,0)+(0,\pshift)$),
          \p4 = ($(#1)+(0,\pshift)$),
          \p2 = ($(\p1)!\n1*\pcdist!-\pcangle:(\p4)$),
          \p3 = ($(\p4)!\n1*\pcdist!+\pcangle:(\p1)$) in
        (\p1) .. controls (\p2) and (\p3) .. (\p4);}}

%}}}

% }}}

% Various parameters {{{
\bibliographystyle{ACM-Reference-Format}
\citestyle{acmnumeric}
%}}}

\begin{document}

\title{%
  Composable Compcert%
}

\author{J\'er\'emie Koenig}
\affiliation{
  \department{Computer Science}
  \institution{Yale University}
}
\email{jeremie.koenig@yale.edu}

\begin{abstract} %{{{
\end{abstract}
%}}}

\maketitle

\section{Introduction} %{{{

\subsection{[Context]}

The state of the art in formal verification is:
we can verify individual artefacts of decent size
(Compcert, CertiKOS, seL4, file systems, CPUs, network protocols).
But the grand challenge is figuring out
how to connect such components together
to obtain large-scale, end-to-end verified systems.
[name-drop the DeepSpec project, cyber-physical systems etc.]
In that context,
compilers are particularly interesting and relevant
because they are a ubiquitous tool
involved at many layers
in the construction of large-scale software systems.

Since the introduction of Compcert \cite{compcert} a decade ago,
there have been very successful efforts aimed at
interfacing it with other verification tools (VST),
using it as a component in larger verification projects (CertiKOS),
and refining its correctness theorem
to model real-world compiler use
in increasingly realistic detail
\citep{qompcert,sepcompcert,compcompcert,compcerttso,compcertshm}.
With each step,
the user can gain more confidence in the reliability of Compcert:
existing work testing the correctness of existing compilers
has found fewer bugs in Compcert,
compared to unverified alternatives \citep{csmith},
and efforts to make Compcert's correctness theorem more realistic
have uncovered and removed some of the few remaining bugs \citep{sepcompcert}.

\subsection{[Gap]}

Yet, most of this work
focuses on the reliability of the compiler
as an individual component.
The role this component plays in the construction of larger systems
is usually treated informally:
real-world use case scenarios are presented
to explain the meaning and justify the suitability
of the correctness theorem being proved.
However,
beyond \emph{system components that are certified},
achieving end-to-end verification of large-scale systems
will require \emph{components of certified systems},
which can in turn be used and composed
to build larger certified systems.

To achieve this, we need to take
a more systematic view of
how large-scale systems are constructed and
how to reason about them,
and use that insight to
articulate design principles for
components of certified systems
and the mathematical tools we use to analyze them.

\subsection{[Innovation]}

In this work, we attempt to answer the question:
what is a \emph{composable} certified compiler?

We identify six criteria for theories of systems (ie. semantic domains)
to be suitable in the context of building larger systems:
expressivity, abstraction, refinement,
compositionality, open systems, resources.

We apply this analytical framework (or rather 1-5)
to the problem of certified compilation,
and to Compcert in particular.
Our criteria suggest natural,
minimal ways in which the semantic framework
used by Compcert should be extended.

We show that we can extend the correctness proof of Compcert
to fit this new framework and
demonstrate how the resulting artefact
can be used to construct fancy certified stuff.

Our analytical framework is also a good way to:
evaluate the limitations of our work
(we need more expressivity for concurrency,
we don't have a good story for resources);
classify and compare previous work on compositional compilation;
map out promising directions for future work.

{\color{gray} %{{{

\subsection{Obsolete ramblings}

[XXX: Redistribute into the main ideas section]

Challenges:
\begin{enumerate}
\item Expressivity.
  [Need not be achieved all at once,
  if we can embed the semantic domain used to analyse a system
  into a broader one.
  The bar should be,
  our formalism should be rich enough to account for
  the full range of possible interaction of a system with its environment
  in the real world.
  Then there should be a way to embed in the formalism
  used to analyze / build any larger system of which it is a component.
  We demonstrate this when we build our richer semantics of Compcert in Sec~4
  and embed our minimalistic one from Sec~3.]
\item Compositionality.
  [Complex systems can only be understood
  as the relationship of simpler components,
  which can be reasoned about in isolation.]
\item Open systems.
  [Compositionality should work from the bottom up, not top down.
  Components should not be understood as fragments of a fixed whole.
  There is no whole system.
  Every system is a component.
  \emph{But},
  it may be reasonable to partially close a subsystem
  after we built it up from components,
  as long as the resulting one
  is still able to interact with its environment]
\item Abstraction.
  [Reductionism is shit.
  You can't \emph{understand} a book
  as a collection of atoms of ink, paper and glue.
  Let alone how that relates to the corresponding e-book.
  Let alone its place within a genre of literature.
  Every level of abstraction exists in its own right.
  Its nature cannot be explained by a particular realization.
  The relation between them ]
\item Refinement.
  [The role of a component is realized in a specific way.
  We don't want to sweat the details when looking at the big picture.]
\item Resources.
  [The role of a component is realized in an imperfect way.
  An ideal, infinite model only exists in the real world
  as a series of finite approximations;
  resource limitations introduce a discontinuity.
  Abstractions break down beyond certain threshold:
  we run out of stack space,
  insufficient network capacity introduces congestion,
  a heap becomes too fragmented to satisfy
  requests for a contiguous block of memory.

  A satisfactory treatment of resources
  allows us to caracterize the range of conditions
  under which refinement and abstraction hold,
\end{enumerate}

In the context of the theory programming languages,
[enumerate things that have tackled combinations of these
challenges:
subtyping -> refinement;
traditional game semantics -> expressivity, compositionality, open systems;
interface automata -> compositionality, $\approx$ open systems, refinement;
certikos -> abstraction, refinement;
lax modality -> compositionality, resources;
logical relations -> abstraction and refinement (sometimes), compositionality;
...]

Context of Compcert:
original compcert uses relatively expressive model
(event traces are fairly general),
and has a notion of refinement (inclusion of sets of behaviors, Vundef),
but not compositional (whole program),
not that open (it's unclear how to connect all kinds of interesting things),
no abstraction (behavior of source and target expressed in same model),
no account of resources (infinite stack at Asm).

[mention that Compcert's model of the userspace is very naive;
impossible to encode a specification such as POSIX
as external function semantics]

Various works seek to extend to support some of these things:
CompCompCert, separate compcert, CompCertX, Qompcert

In this paper:
sketch something for challenges 2-5
out of (traditional game semantics + interface automata + abstraction layers).
Illustrate how these ideas play out in the context of compilers,
and apply them to solve the open problem of
compositional certified compilation.

\subsection{Contributions}

Specifically,
we identify six principles [...]
Give a clear ``test'' for each.
Can guide design.

We apply our analytical framework to the problem of certified compilation:
\begin{itemize}
\item analyze previous work in pl semantics and certified compilation
  in this framework to assess and explain the strenghts and weaknesses of each
  [sec. 12 Related Work]
\item show [in sec. 3 Semantics with External Calls]
  how these ideas yield a natural solution
  when applied to the open problem of compositional compilation
\item formulate new challenge / next step:
  that of a compiler which can be used as a component
  for end-to-end verification;
\item In Sec.~4 [richer semantics],
  show that our semantic model can be made more expressive
  in a way that our compiler remains correct in that setting;
\item In Sec.~5 [applications],
  illustrate with some applications
  the ways in which our compiler can be connected
  to a larger system
\item Assess the remaining gap between our compiler
  and our new challenge (concurrency, resources),
  and apply our analytical framework to suggest
  what a solution might look like.
\end{itemize}

[Basic claim: the answer to compositional verification
is an undestanding of abstraction and refinement in the context of games.]
The present work applies this analysis to
solve the open problem of certified compositional compilation of low-level languages
plus an understanding of refinement and abstraction in that context.]

\subsection{Limitations}

No concurrency
(not expressive enough:
accesses to memory between external calls are not observable
--- this being said existing work on Concurrent CertiKOS shows
it may be possible to map our model in a more general one),
no good story for resources.

In Sec.~N [Future Work] [spell out some leads to fill these gaps.]

} %}}}

%}}}

\section{Main ideas} %{{{

\subsection{Languages} %{{{

Formally,
a programming language $L$ is understood as
a set of programs $p$
which are assigned a meaning $\llbracket p \rrbracket$
in a set $\mathbb{D}$.
We call \emph{programs} or \emph{modules} the elements of $L$,
preferring \emph{module} when
the language supports
a notion of horizontal composition (see Sec.~\ref{sec:cccomp}).
We call \emph{behaviors} or \emph{specifications}
the elements of the \emph{semantic domain} $\mathbb{D}$,
preferring \emph{specification} when
the semantic domain is equipped with
a notion of refinement,
and the specification under consideration
may be refined by more specific behaviors.

[I was hoping the examples below could provide a way to illustrate
the concepts,
but now I'm not sure if it's worth the space
and reader's mental energy.
Maybe use Compcert languages instead,
two birds with one stone?]

{\color{gray} %{{{

As a running example,
we present two simple languages
whose programs define single-argument integer functions.

\begin{example}[$\kw{AlgExp}$] %{{{
We consider algebraic expressions
built out of integer constants, $+$, $\times$,
and a single variable $x$.
This language $\kw{AlgExp}$ is defined by the following grammar:
\[
  e \in \kw{AlgExp} ::= c \:|\: x \:|\: (e + e) \:|\: (e \times e) \,,
\]
where $c \in \mathbb{Z}$ is any constant,
and $x$ is a terminal symbol.
One ``program'' in this language is the following expression:
\[
  e_a := ((x \times (3 + x)) + 2)
\]
An expression $e$ in \kw{AlgExp} is assigned a meaning
$\llbracket e \rrbracket : \mathbb{Z} \rightarrow \mathbb{Z}$
as follows:
to compute $\llbracket e \rrbracket(n)$,
substitute $n$ for $x$ in $e$,
then evaluate the resulting integer expression.
For example:
\[
  \llbracket e_a \rrbracket (n) = n^2 + 3n + 2 \,.
\]
\end{example}
%}}}

\begin{example}[$\kw{RegProg}$] %{{{
Consider a machine with an infinite number of registers,
which can perform elementary algebraic operations.
The grammar of programs is:
\begin{align*}
  r \in \kw{RegName} &::= \kw{r1} \:|\: \kw{r2} \:|\: \cdots \\
  e \in \kw{RegExpr} &::= c \:|\: r \:|\: r + r \:|\: r \times r \\
  p \in \kw{RegProg} &::= r \leftarrow e; \, p \:|\: \bullet \,,
\end{align*}
where $\bullet$ denotes the empty program.
An example is:
\[
  p_a :=
  \kw{r2} \leftarrow 1; \,
  \kw{r2} \leftarrow \kw{r1} + \kw{r2}; \,
  \kw{r3} \leftarrow \kw{r2} \times \kw{r2}; \,
  \kw{r1} \leftarrow \kw{r2} + \kw{r3};
\]
Each assignment $r \leftarrow e$ evaluates the computation $e$,
then stores the result in register $r$.
To interpret programs as functions,
we initialize $\kw{r1}$ with the value of the argument,
execute the program's assignments in sequence,
then read out the answer from the new contents of $\kw{r1}$.
The reader is invited to check that
the behavior $\llbracket p_a \rrbracket$ associated to the program above
is the same as that of $e_a$.
\end{example}
%}}}

The $\kw{AlgExp}$ and $\kw{RegOps}$ languages
are sufficient to illustrate a number of interesting phenomena.
Because of their simplicity,
it will be possible to do so with some degree of formality.
Concurrently,
we will discuss in a more casual manner
the way in which these phenomena play out
in the context of the compilation of C to assembly languages.

} %}}}

%}}}

\subsection{Compilers} %{{{

Given a source language $L_s$
and a target language $L_t$,
a compiler can be understood as a function
$C : L_s \rightarrow L_t$
which transforms a program $p \in L_s$
into a program $C(p) \in L_t$.
When the two languages are interpreted into
a common semantic domain,
the correctness of the compiler can be stated as:
\[
  \llbracket p \rrbracket_s = \llbracket C(p) \rrbracket_t \,.
\]

{\color{gray} %{{{

\begin{example}[\kw{AlgExp} to \kw{RegOps}] %{{{
To illustrate this definition,
we define a simple compiler $C_a : \kw{AlgExp} \rightarrow \kw{RegOps}$.
Compiling simple expressions is straightforward:
\[
  C_a(c) := \kw{r1} \leftarrow c; \qquad
  C_a(x) := \bullet
\]
Compiling binary operations is more involved,
because we need to evaluate each operand,
making sure that the first computation does not overwrite
the input value,
and that the second computation does not overwrite
the result of the first.
To this end,
we define a \emph{shift} operator ${\uparrow} p$,
which replaces every register name in $p$ by its successor,
so that for example:
\[
  {\uparrow} p_a =
  \kw{r3} \leftarrow 1; \,
  \kw{r3} \leftarrow \kw{r2} + \kw{r3}; \,
  \kw{r4} \leftarrow \kw{r3} \times \kw{r3}; \,
  \kw{r2} \leftarrow \kw{r3} + \kw{r4};
\]
We can now define for each binary operation $* \in \{+, \times\}$:
\begin{align*}
  C(e_1 * e_2) = \quad  % XXX overloading e_1
    &\kw{r2} \leftarrow \kw{r1}; \, % XXX copy not allowed
    {\uparrow} C(e_1); \\
    &\kw{r3} \leftarrow \kw{r1}; \,
    {\uparrow\uparrow} C(e_2); \\
    &\kw{r1} \leftarrow \kw{r2} * \kw{r3};
\end{align*}
The subprogram ${\uparrow} C(e_1)$
will use $\kw{r2}$ for its input and output,
and use registers $\kw{r3}$ and above for its intermediate results,
leaving the contents of $\kw{r1}$ unchanged.
Likewise,
${\uparrow\uparrow} C(e_2)$
will operate on registers $\kw{r3}$ and above,
leaving both $\kw{r1}$ and $\kw{r2}$ unchanged.
The last instruction in the program performs
the top-level operation and stores the result
in the output register $\kw{r1}$.
\end{example}
%}}}

To formally establish the correctness of $C_a$,
we seek to prove that
$\llbracket C_a(e) \rrbracket = \llbracket e \rrbracket$
by structural induction on $e$.
It is easy enough to check that:
\[
  \llbracket \bullet \rrbracket = \llbracket x \rrbracket \qquad
  \llbracket \kw{r1} := c \rrbracket = \llbracket c \rrbracket
\]
However,
the inductive cases for $e_1 + e_2$ and $e_1 \times e_2$
are less obvious to handle.
To articulate why,
it is useful [to be overly pedantic:]

When compiling $(e_1 * e_2)$,
$C_a$ constructs a $\kw{RegProg}$ system
in terms of the simpler components $C_a(e_1)$ and $C_a(e_2)$.
As we try to understand the behavior of the resulting artefact,
the mathematical theory we use to specify and analyse
the behavior of these components,
namely the semantic domain $\mathbb{Z} \rightarrow \mathbb{Z}$,
should help us connect
the behavior of the components to
the behavior of the whole,
ultimately allowing us to prove
the conclusion $\llbracket C_a(e_1 * e_2) \rrbracket = \llbracket e_1 * e_2 \rrbracket$
from our induction hypotheses
$\llbracket C_a(e_1) \rrbracket = \llbracket e_1 \rrbracket$ and
$\llbracket C_a(e_2) \rrbracket = \llbracket e_2 \rrbracket$.
However,
our theory is not rich enough to support this process:
$\mathbb{Z} \rightarrow \mathbb{Z}$
is not the right semantic domain
to describe $\kw{RegProg}$ modules.

%This is because while the program $C(e_1 * e_2)$
%was built by stitching together more elementary components,
%we have not yet defined a corresponding notion of \emph{composition}
%at the level of our semantic domain (Sec.~\ref{sec:cccomp}).
%[Condense the following tease]
%Moreover,
%the semantic domain $\mathbb{Z} \rightarrow \mathbb{Z}$
%is not \emph{expressive} enough to account for the behavior of $\uparrow$:
%using our convention for the meaning of $\kw{RegOps}$ programs,
%$\llbracket {\uparrow}p \rrbracket$ is always the identity function!
%This is addressed in Sec.~\ref{sec:ccexpr} by defining
%a richer semantics for $\kw{RegOps}$.
%Because this richer semantics no longer matches
%the domain used to interpret the source language $\kw{AlgExp}$,
%we then need to account for the \emph{abstraction} relationship
%between the behaviors of $\kw{AlgExp}$ programs
%and the behaviors of $\kw{RegOps}$ ones (Sec.~\ref{sec:ccabs}).
%[refinement, open system whatever that means in this context].

} %}}}

%}}}

{\color{gray} %{{{

\subsection{Expressivity} %{{{

The expressivity of our theories
should be assessed
[real-world,
from the point of view of the outside.]

The first problem we encounter when we try to understand $C_a(e_1 * e_2)$
is the lack of expressivity of our semantic domain.
For instance,
$\mathbb{Z} \rightarrow \mathbb{Z}$
fails to even explain the effect of the shift operator $\uparrow$:
in fact, for any $\kw{RegProg}$ program $p$,
the program ${\uparrow}p$ leaves $\kw{r1}$ unchanged,
so that it is indistinguishable from the empty program!
Note that this problem did not appear
when defining our notion of compiler correctness.
In fact,
given a sufficiently precise semantics of $\kw{RegProg}$,
there is no doubt we could work around the problem:
bite the bullet, treat $C_a(e_1 * e_2)$ as a whole,
and prove our compiler correct.
However,
the situation illustrates an important point:
by overfitting our choice of semantics to the problem at hand,
we have failed to account for important ways in which
$\kw{RegProg}$ programs can interact with their environments
in ways that $\kw{AlgExp}$ programs cannot.
This limits the usefulness of our target semantics,
and as such that of the compiler correctness theorem
(or the induction hypotheses in this case).

A better approach would have been to
assess the expressivity of our semantics,
not in terms of formulating the problem at hand,
but in terms of the ways in which our system
could be used.
What is a $\kw{RegProg}$ machine good for?
With a different convention,
it could be used to compute function of several variables.
It could be a component in a handheld calculator,
or the control system of an airplane.

[it seems like pandora's box,
but maximal expressivity in how system communicates with its environment
+ open system = everything you want]

Likewise, C programs are used to do all kind of things,
but we don't need to know what:
only the basic interaction principles
between the C program and its environment that are involved
in those things.
Although communication model between program
and the underlying system is simple and uniform
(system calls / external function invocation),
this protocol is general enough that
when we link with the outside world,
the source/target machine models are enough to
implement all kinds of stuff:
network services, GUIs, drivers, control software,
operating systems, distributed computations, \ldots
The same compiler is used in all of these contexts.

%}}}

} %}}}

\subsection{Abstraction} %{{{

The assumption that the source and target programs
can be naturally assigned meanings in the same semantic domain
is reasonable for compiler passes
where the source and target languages are fairly similar.
It can also hold when observable behaviors are simple:
if we are only interested in the final result produced by a program,
then the corresponding notion of behavior
can be fairly language-independent.
However,
in most practical cases we are interested in
the program's interaction with its environment
as well as its ultimate outcome,
and this interaction is often understood very differently
in the context of the source and target languages.

For instance,
in the C programming language
the memory is understood in terms of independent objects.
Each object corresponds to a variable declared in the program,
or to a chunck of heap-allocated memory.
In C, a function call is performed
by allocating and initializing new objects
corresponding to the callee's arguments and local variables.
By contrast,
an assembly program
operates in a single address space:
the memory is essentially seen as a large array of bytes;
the very notion of a function call in assembly
is largely conventional as opposed to a primitive notion,
and their mechanics are understood in very different terms.
Consequently,
semantic domains that can accurately account
for module interaction will necessarily be distinct in C and assembly.

This underscore importance of \emph{abstraction}:
C compilers operate in the context of a given \emph{calling convention},
which establishes a relationship between the behaviors of C modules
and that of assembly modules.
This calling convention can be modelled as a function
$\mathbb{C} : \mathbb{D}_s \rightarrow \mathbb{D}_t$,
which is in some sense the semantic counterpart to the compiler $C$.
Our correctness criterion becomes:
\[
  \mathbb{C}(\llbracket p \rrbracket_s) =
  \llbracket C(p) \rrbracket_t
\]

[Compcert goes to great length to ensure $\mathbb{D}_s = \mathbb{D}_t$,
defining unified memory model etc.
Much compositional Compcert works keeps with this approach
but this creates problems.
In fact, even when $\mathbb{D}_s = \mathbb{D}_t$ formally,
the source and target behaviors may be distinct
and it can be important/useful to define
$\mathbb{C} : \mathbb{D} \rightarrow \mathbb{D}$.
In Sec.~\ref{sec:callconv} we show how taking abstraction seriously
solves the extcall\_args problem.]

%}}}

\subsection{Refinement} %{{{

In and of itself,
abstraction is insufficient to reflect
the relationship between the behaviors of C and assembly modules.
This is because there is more than one way to realize
a given C function call at the level of assembly.
For instance,
a typical calling convention specifies a classification of machine registers
into \emph{callee-save} registers,
which are guaranteed to be left unchanged by the function being invoked,
and \emph{caller-save} registers,
which the function being invoked may modify at will.
Two assembly functions
which modify the caller-save registers differently
may still implement the same C behavior;
however, they will be observationally distinct at the level of assembly.

To account for this situation,
the target semantic domain $\mathbb{D}_t$
should contain specifications
allowing a range of possible behaviors,
and be equipped with a notion of refinement
in the form of a transitive relation $\sqsupseteq$.
The target behavior $\mathbb{C}(\sigma_s)$
corresponding to the source behavior $\sigma_s$
can then be broad enough to state,
for instance,
that the callee-save registers
may contain any value after a function
specified in $\sigma_s$ returns.
Target programs
which leave specific values in these registers
but otherwise agree with $\mathbb{C}(\sigma_s)$
will be considered valid implementations
because their behavior will refine that specification.
Taking this into account,
the correctness statement becomes:
\[
  \mathbb{C}(\llbracket p \rrbracket_s) \sqsupseteq
  \llbracket C(p) \rrbracket_t
\]

Note that while abstraction and refinement are distinct concepts,
it can sometimes be advantageous to unify them
in the form of a single, heterogenous relation
${\sqsupseteq_\mathbb{C}} = {\sqsupseteq} \circ {\mathbb{C}}$.
[Reference popl15's abstraction relations]
[Forward reference to where we do that in this work].
[Explain that confusing the two is the root of some limitation
in existing work].

[Role of refinement/abstraction in permitting optimizations?]

%}}}

\subsection{Open systems} %{{{

Using powerset of behaviors is not good enough for refinement,
we need to take distinction between system and environment seriously.
-> this is how we define a notion of refinement in Sec.~3
that solves some of the issues

Discuss contextual refinement,
which is not enough \emph{a priori}, and \emph{practically},
because we don't want to limit ourselves to a set of systems we're gonna connect with.
But also contextual refinement might be enough
if the interaction of all the environments we would ever want to connect with
can be "coobservationally equivalent" to a context in our set
from the point of view of the program (aka oracle).

Specs need to be able to express constraints on the environment.

[Fit somewhere:]
This calls into question
the centrality of contextual refinement and contextual equivalence
in standard approaches to compositionality.
[Use game semantics and a smarter refinement instead;
you'll get contextual refinement for free
for whatever that's worth.]
[There is no completed system.
At the very least the context itself
should have facilities to communicate with the larger world
that are expressive enough.]

%}}}

\subsection{Compositionality} %{{{

[Large programs are split into compilation units,
which are compiled independently,
then linked to produce the final artefact.]

Syntactic composition
(the way we stitch together components to build a system in the real world)
should have corresponding notion
in the semantics
(the theory we use to analyse systems).

%}}}

\subsection{Resources} %{{{

[The source model is usually much more idealized than target.
Example: infinite stack vs. finite address space.]

%}}}

%}}}

\section{Open Modules for Compcert} %{{{

Applying our principles to the labeled transition systems
used in Compcert yields a natural extension
able to support compositional compilation.

Labeled transition systems (LTS)
are the main kind of semantic objects used by Compcert.
A Compcert LTS specifies a set of states $S$,
a labeled transition relation ${\rightarrow}$,
and distinguished subsets of initial and final states;
in addition,
final states are associated with the a final integer result.
Compcert LTS support a notion of interaction with the environment
in the form of event traces:
a transition $s \stackrel{t}{\rightarrow} s'$,
indicates that the state $s$ may transition to state $s'$
through an interaction recorded as the event trace $t$.

\subsection{Language Interfaces} %{{{

\begin{table*}
  \begin{tabular}{llll}
    \hline
    Name & Query & Reply & Description \\
    \hline
    \kw{li\_c} & $(\kw{id}, \kw{sg}, \vec{v}, m)$ & $(v', m')$ &
      C-style function calls \\
    \kw{li\_locset} & $(\kw{id}, \kw{sg}, \kw{ls}, m)$ & $(\kw{ls}', m')$ &
      Arguments are passed in abstract locations (LTL, Linear) \\
    \kw{li\_mach} & $(\kw{id}, \kw{sp},\kw{ra},\kw{rs}, m)$ & $(\kw{rs}', m')$ &
      Arguments are passed through the in-memory stack (Mach) \\
    \kw{li\_asm} & $(\kw{rs}, m)$ & $(\kw{rs}', m')$ &
      Assembly-style control transfers (Asm) \\
    \hline
  \end{tabular}
  \caption{Language interfaces for the various Compcert intermediate languages.}
  \label{tbl:li}
\end{table*}

This model is insufficient to express
the semantics of C and assembly modules.
Compcert only accounts for
whole programs with a single entry point,
which terminate by producing a single numerical result.
By contrast,
control can enter and exit open modules
in a variety of language-dependent configurations.
These language-dependent aspects are captured
by the following notion.

\begin{definition}[Language interface]
A \emph{language interface} $\tau$ consists in a pair $(Q, R)$
which specifies
a set $Q$ of \emph{queries} and
a set $R$ of \emph{replies}.
Queries
correspond to the states in which
a module can be entered, whereas
replies
correspond to the states in which
the module can return control
to its environment.
\end{definition}

Table~\ref{tbl:li}
shows the language interfaces used by Composable Compcert.
At the level of C,
queries consist of
the name and signature of the function being invoked,
the values of its arguments,
and the state of the memory at the point of entry.
Replies
will consist of the function's return value
and the state of the memory at the point of exit.
At the assembly level,
both queries and replies are defined as
the values of registers and the state of the memory.

%}}}

\subsection{Calling conventions} \label{sec:callconv} %{{{

\begin{table*} % tbl:cc Calling conventions {{{
  \begin{tabular}{lccp{.6\textwidth}}
    \hline
    Name & Source & Target & Description \\
    \hline
    \kw{cc\_id} & $\tau$ & $\tau$ &
      Identity calling convention;
      used in equality passes. \\
    \kw{cc\_inj} & \kw{li\_c} & \kw{li\_c} &
      Rectangular injection diagram;
      C-style external calls in injection passes. \\
    \kw{cc\_ext} & \kw{li\_c} & \kw{li\_c} &
      Rectangular extension diagram;
      C-style external calls in extension passes. \\
    \kw{cc\_inj\_triangle} & \kw{li\_c} & \kw{li\_c} &
      Triangular injection diagram;
      outer interface in injection passes. \\
    \kw{cc\_ext\_triangle} & \kw{li\_c} & \kw{li\_c} &
      Triangular extension diagram;
      outer interface in extension passes. \\
    \kw{cc\_alloc} & \kw{li\_c} & \kw{li\_locset} &
      Outer interface for the \kw{Allocation} pass.
      Arguments are now in abstract locations;
      uses a memory extension. \\
    \kw{cc\_stacking} & \kw{li\_locset} & \kw{li\_mach} &
      Outer interface for the \kw{Stacking} pass;
      Abstract locations are mapped to registers and the in-memory stack;
      uses a memory injection. \\
    \kw{cc\_asmgen} & \kw{li\_mach} & \kw{li\_asm} &
      Outer interface for \kw{Asmgen};
      registers are mapped to their architecture-specific versions;
      function being called is specified by the program counter. \\
    \kw{cc\_compcert} & \kw{li\_c} & \kw{li\_asm} &
      End-to-end calling convention;
      essentially a composition of
      \kw{cc\_alloc}, \kw{cc\_stacking}, and \kw{cc\_asmgen}. \\
    \hline
  \end{tabular}
  \caption{Calling conventions.}
  \label{tbl:cc}
\end{table*}
%}}}

In order to compare behaviors formulated in terms of
different language interfaces,
we need to specify a correspondance
between the queries and between the replies
of the source and target languages.
We formalize this correspondance in the following way.

\begin{definition}[Calling convention]
Given a source language interface $\tau_1 = (Q_1, R_1)$ and
a target language interface $\tau_2 = (Q_2, R_2)$,
a \emph{calling convention} is a pair
$\mathbb{C} = (\mathbb{C}_Q, \mathbb{C}_R)$.
The component
$\mathbb{C}_Q \subseteq Q_1 \times Q_2$
relates queries of the source language to
corresponding queries of the target language.
Given related source and target queries,
the component
$\mathbb{C}_R(q_1, q_2) \subseteq R_1 \times R_2$
relates replies of the source language to
corresponding replies of the target language.
\end{definition}

Table~\ref{tbl:cc} describes the various calling conventions
used in Composable Compert.

[Reframe] Compcert does not use explicit notions of
language intefaces and calling convenentions.
However,
its model of external calls
(\kw{extcall\_sem}),
the requirements it imposes on their semantics
(\kw{extcall\_properties}),
and the internal invariants used by its simulation proofs
can be read in this light
and used to define
compatible notions of refinement and calling conventions
across Compcert languages.

For simplicity,
Compcert uses a common language interface
for all of its languages.
Queries are of the form:
\[
  Q = \{ f(\vec{v})@m : (f, \vec{v}, m) \in
    \kw{ident} \times \kw{val}^* \times \kw{mem} \} \,,
\]
where $f$ identifies the function being called,
$\vec{v}$ provides values for the function's arguments, and
$m$ specifies the global memory's initial state for the call.
Replies are of the form:
\[
  R = \{ v'@m' : (v', m') \in
    \kw{val} \times \kw{mem} \} \,,
\]
where $v'$ gives the function's return value and
$m'$ specifies the global memory's new state.

The refinement convention associated with this language interface
specifies that
related queries should carry the same function identifier,
and that the values of arguments and the states of the memories
can be related in one of three ways:
\begin{itemize}
\item they can be equal;
\item the source query may be
  \emph{less defined} than the target query,
  meaning that the special value $\kw{Vundef}$
  in the components of the source query
  can be refined into concrete values in the target query,
  and that the target memory,
  in addition to having more defined contents,
  may carry more liberal permissions
  (a relation known as \emph{memory extension});
\item they can related by a \emph{memory injection} $\iota$,
  allowing memory addresses to be remapped
  between the source and target queries.
\end{itemize}
Memory injections only constrain the contents of memories
at addresses which are related by $\iota$.
At these addresses,
the contents of the target memory is furthermore
allowed to be more defined than the contents of the source
memory at the corresponding address.

Given two queries related by
the Compcert refinement convention,
matching replies
must be related in a compatible way:
\begin{itemize}
\item if the queries were equal,
  the replies must be equal as well;
\item if the source query was
  \emph{less defined} than the target query,
  then this must be true of the corresponding
  replies as well;
\item if the source and target queries
  were related through a memory injection $\iota$,
  then the corresponding replies
  must be related through a potentially \emph{larger}
  injection $\iota' \ge \iota$.
\end{itemize}
In addition,
previously allocated regions of the target memory
must remain unchanged
at any addresses that were not mapped to valid locations
of the initial source memory.
This allows the target language to allocate additional,
private memory locations (such as stack frames),
which are not visible at the level of the source language.
Compcert's refinement convention
expresses the expectation that such locations
will be left unchanged by the environment.

Although the Compcert refinement convention is used as
the calling convention for most compiler passes,
a more specific calling convention is used
at the point where function call arguments
are marshalled onto the stack.
There,
in addition to the criteria defined above,
[arguments must be encoded into the target memory,
but \emph{only} the target memory.]

%}}}

\subsection{Semantic objects} %{{{

Extending Compcert LTS to account for
this extra structure yields the following definition.

\begin{definition}[Labeled transition system]
Given a language interface $\tau = (Q, R)$,
a \emph{labeled transition system} for $\tau$
is a tuple $\sigma = (S, \rightarrow, I, F)$ where
$S$ is a set of states,
${\rightarrow} \subseteq S \times \mathbb{E}_\tau^* \times S$
is a ternary \emph{transition relation},
$I \subseteq Q \times S$
assigns a set of \emph{initial states} to each query, and
$F \subseteq S \times R$
is a relation designating \emph{final states}
together with the reply they produce.
\end{definition}

[Introduce determinacy?]

We have not yet specified the set $\mathbb{E}_\tau$ of events
used by a language interface $\tau$.
They will consist of the same events already present in Compcert,
augmented with a set of external call events.

%}}}

\subsection{External call events} %{{{

The use of language-specific queries and replies
in the definition of transition systems
takes care of the variety of ways
in which the environment may invoke an open module,
but does not account for the ways in which
the module may itself invoke the environment.
We remedy this by introducing \emph{external call events}.

Following \cite{cpp15},
we use external call events of the form $\kw{extcall}[q, r]$,
recording the fact that an external call was performed
with the query $q$,
and produced the reply $r$.

Compcert does account for the fact that the program
may call the outside world in the form of a global parameter
specifying the semantics of external calls:
\[
  \kw{external\_call} :
    \kw{ident} \rightarrow
    \kw{val}^* \times \kw{mem} \rightarrow
    \mathbb{E}^* \rightarrow
    \mathcal{P}(\kw{val} \times \kw{mem})
\]
In addition,
the predicate $\kw{extcall\_properties}$ defines
requirements which must be satisfied by the semantics
of every external function.
The correctness proof of Compcert is contingent
on the fact that for every external function $f$,
the assertion $\kw{extcall\_properties}(\kw{external\_call}(f))$ holds.

We can instantiate $\kw{external\_call}$ for the C language as:
\[
  \AxiomC{$e = \kw{extcall}[f(\vec{v})@m, v'@m']$}
  \AxiomC{$\kw{valid}(e)$}
  \BinaryInfC{$\kw{external\_call}(f) :
    (\vec{v}, m) \stackrel{e}{\rightarrow} (v', m')$}
  \DisplayProof
\]
This technique allows us to reuse Compcert's existing infrastructure
for handling external calls,
and ensures that our changes to the
definition of semantics and the correctness proof are minimal.
However,
to make it work we need to update $\kw{extcall\_properties}$
to account for trace refinement.

%}}}

\subsection{Refinement} %{{{

Compcert uses \emph{backward simulations}
as its primary notion of refinement between labeled transition systems.
Our version takes into account the notion of calling convention
introduced in Sec.~\ref{sec:callconv}:
because our events may expose language-specific details,
we cannot assume the traces generated by the two LTS can be directly compared.
Instead,
we use the calling convention to compute an appropriate relation.
Furthermore,
the calling convention may introduce
constraints on the environment in the target specification:
for instance,
when compiling a C module performing an external call,
the target assembly module is not required to handle
all possible assembly-style replies from the environment,
but only those corresponding to the possible C-style replies
handled by the source module.
To handle this,
Composable Compcert uses a notion of alternating simulation,
similar for instance to the notion of refinement
described in \cite{gmos}.

[what we're doing
is allow our semantic objects
to place constraints on the environment.
This departs from receptivity requirement in Compcert,
and we should be more explicit about that]

To adapt alternating simulations to the context of Compcert,
it is important to understand that Compcert events
denote two actions:
a request by the module,
which may additionally include some output information,
followed by a response from the environment,
which may simply acknowledge the request
but may also carry any input associated with the event.
To show that
a given source behavior is refined by
a given target behavior,
we need to show that any request performed by the target behavior
is already present in the source behavior,
and that any response permitted of the source environment
is properly reflected by
a response permitted of the target environment.

This leads us to introduce two distinct relations on events,
separating the contribution of the module and that of the environment.
The relation $\succeq_\mathbb{C}$
relates events
which have a related request component,
but may differ in their response component.
For regular Compcert events,
this corresponds to the usual $\kw{match\_traces}$ relation.
[exapand?]
For external call events, we define:
\[
  \kw{extcall}[q_1, r_1] \succeq_\mathbb{C} \kw{extcall}[q_2, r_2]
  \stackrel{\text{def.}}{\Leftrightarrow}
  (q_1, q_2) \in \mathbb{C}_V
\]
The second relation $\sqsupseteq_\mathbb{C}$
relates events whose query and response components
both match.
For regular Compcert events,
$\sqsupseteq_\mathbb{C}$ coincides with equality.
For external call events, we define:
\begin{align*}
  \kw{extcall}[q_1, r_1] \sqsupseteq_\mathbb{C} \kw{extcall}[q_2, r_2]
  &\stackrel{\text{def.}}{\Leftrightarrow}
  (q_1, q_2) \in \mathbb{C}_Q \\ &\wedge \ 
  (r_1, r_2) \in \mathbb{C}_R(q_1, q_2)
\end{align*}
These relations are extended to traces in the natural way
[maybe not: if environment breaks the deal at any point
then the two traces should still be related by $\succeq$
even though only a common prefix matches?]
and allow us to define
our notion of refinement as follows.

\begin{definition}[Alternating simulation]
Given a calling convention $\mathbb{C}$ between
a source language interface $\tau_1 = (Q_1, R_1)$
a target language interface $\tau_2 = (Q_2, R_2)$,
an \emph{alternating simulation} between
an LTS $\sigma_1 = (S_1, \rightarrow_1, I_1, F_1)$ and
an LTS $\sigma_2 = (S_2, \rightarrow_2, I_2, F_2)$
is a relation $R \subseteq S_1 \times S_2$
with the following properties:
\begin{description}
\item[Preservation of system half-steps]
  For any pair of related states $(s_1, s_2) \in R$,
  if the target behavior takes a step $s_2 \stackrel{t_2}{\rightarrow} s_2'$,
  then there exist $t_1$, $s_1'$ such that
  $s_1 \stackrel{t_1}{\rightarrow^*} s_1'$,
  $t_1 \succeq_\mathbb{C} t_2$, and
  $(s_1', s_2') \in R$.
  [That is, every request the target behavior performs
  must also be possible in the source behavior]
\item[Preservation of environment half-steps]
  For any pair of related states $(s_1, s_2) \in R$ such that
  the source behavor takes a step
  $s_1 \stackrel{t_1}{\rightarrow} s_1'$,
  the target behavior takes a step
  $s_2 \stackrel{t_2}{\rightarrow} s_2'$, and
  the event traces
  $t_1 \succeq_\mathbb{C} t_2$ have related module behaviors,
  there exist $t_2', s_2''$ such that
  $s_2 \stackrel{t_2'}{\rightarrow} s_2''$
  and $t_1 \sqsupseteq_\mathbb{C} t_2'$.
  [That is, all environment behaviors specified in the source
  must be accounted for in the target]
\item[Compatibility of initial states]
  Given two related queries $(q_1, q_2) \in \mathbb{C}_Q$
  and a corresponding source state $s_1$ such that $(q_1, s_1) \in I_1$,
  there exists a target state $s_2$ such that $(q_2, s_2) \in I_2$ and $(s_1, s_2) \in R$.
\item[Compatibility of final states]
  Given two related states $(s_1, s_2) \in R$ and
  a target reply $r_2$ such that $(s_2, r_2) \in F_2$,
  there exits
  a source reply $r_1$ such that $(s_1, r_1) \in F_1$
  such that $(r_1, r_2) \in \mathbb{C}_F$.
\end{description}
\end{definition}

[Forward simulations.
Now we only need to flip module steps,
so we still use determinacy but don't need receptivity.]

%}}}

\subsection{Composition of passes} %{{{

\begin{table*} % tbl:passes Passes of Composable Compcert %{{{
  \begin{tabular}{lll@{\hspace{2em}}p{.5\textwidth}}
    \hline
    Language/pass & External calls & Outer interface & Description \\
    \hline
    \bf
    \textbf{Clight} & \kw{\bf li\_c} & \kw{\bf li\_c} &
      A simpler version of CompCert C
      where expressions contain no side-effects. \\
    \kw{SimplLocals} & \kw{cc\_inj} & \kw{cc\_inj\_triangle} &
      Pulling non-adressable scalar local variables out of memory. \\
    \kw{Cshmgen} & \kw{cc\_id} & \kw{cc\_id} &
      Simplification of control structures;
      explication of type-dependent computations. \\
    \textbf{Csharpminor} & \kw{\bf li\_c} & \kw{\bf li\_c} &
      Low-level structured language. \\
    \kw{Cminorgen} & \kw{cc\_ext} & \kw{cc\_ext\_triangle} &
      Stack allocation of local variables whose address is taken;
      simplification of switch statements. \\
    \textbf{Cminor} & \kw{\bf li\_c} & \kw{\bf li\_c} &
      Low-level structured language,
      with explicit stack allocation of certain local variables. \\
    \kw{Selection} & \kw{cc\_ext} & \kw{cc\_ext\_triangle} &
      Recognition of operators and addressing modes. \\
    \textbf{Cminorsel} & \kw{\bf li\_c} & \kw{\bf li\_c} &
      Like Cminor, with machine-specific operators and addressing modes. \\
    \kw{RTLgen} & \kw{cc\_ext} & \kw{cc\_ext\_triangle} &
      Construction of the CFG, 3-address code generation. \\
    \textbf{RTL} & \kw{\bf li\_c} & \kw{\bf li\_c} &
      Register transfer language
      (3-address code, control-flow graph, infinitely many pseudo-registers). \\
    \kw{Tailcall} & \kw{cc\_ext} & \kw{cc\_ext\_triangle} &
      Recognition of tail calls. \\
    \kw{Inlining} & \kw{cc\_inj} & \kw{cc\_inj\_triangle} &
      Function inlining. \\
    \kw{Renumber} & \kw{cc\_id} & \kw{cc\_id} &
      Postorder renumbering of the CFG. \\
    \kw{Constprop} & \kw{cc\_ext} & \kw{cc\_ext\_triangle} &
      Constant propagation. \\
    \kw{CSE} & \kw{cc\_ext} & \kw{cc\_ext\_triangle} &
      Common subexpression elimination \\
    \kw{Deadcode} & \kw{cc\_ext} & \kw{cc\_ext\_triangle} &
      Redundancy elimination \\
    \kw{Unusedglob} & \kw{cc\_inj} & \kw{cc\_inj\_triangle} &
      Removal of unused static globals \\
    \kw{Allocation} & \kw{cc\_ext} & \kw{cc\_alloc} &
      Register allocation \\
    \textbf{LTL} & \kw{\bf li\_c} & \kw{\bf li\_locset} &
      Location transfer language
      (3-address code, control-flow graph of basic blocks,
      finitely many physical registers, infinitely many stack slots). \\
    \kw{Tunneling} & \kw{cc\_ext} & \kw{cc\_ext\_ltl} &
      Branch tunneling \\
    \kw{Linearize} & \kw{cc\_id} & \kw{cc\_id} &
      Linearization of the CFG \\
    \textbf{Linear} & \kw{\bf li\_c} & \kw{\bf li\_locset} &
      Like LTL, but the CFG is replaced by
      a linear list of instructions with explicit branches and labels \\
    \kw{Cleanuplabels} & \kw{cc\_id} & \kw{cc\_id} &
      Removal of unreferenced labels \\
    \kw{Debugvar} & \kw{cc\_id} & \kw{cc\_id} &
      Synthesis of debugging information \\
    \kw{Stacking} & \kw{cc\_inj} & \kw{cc\_stacking} &
      Laying out the activation records \\
    \textbf{Mach} & \kw{\bf li\_c} & \kw{\bf li\_mach} &
      Like Linear, with a more concrete view of the activation record \\
    \kw{Asmgen} & \kw{cc\_compcert\_ext} & \kw{cc\_asmgen} &
      Emission of assembly code \\
    \textbf{Asm} & \kw{\bf li\_asm} & \kw{\bf li\_asm} &
      Assembly language for x86 machines \\
    \hline
  \end{tabular}
  \caption{%
    Intermediate languages and compiler passes
    (descriptions from Compcert's documentation).}
  \label{tbl:passes}
\end{table*}
%}}}

Table~\ref{tbl:passes} shows the passes of Composable Compcert,
together with the calling conventions for external calls and module interaction
used at each pass.
The calling conventions for each pass are chosen for convenience:
they reflect most closely the way the proof was written
in Compcert and CompCertX,
rather than a particularly useful or meaningful theorem for that pass.
In particular,
note that for most passes
the calling convention used for external calls is different from
that used for the module's outer interface,
preventing horizontal compositionality.
This section explains how the passes can nonetheless be composed
and how a satisfactory theorem can be derived for the whole compiler.



As a first step,




[Define composition of calling conventions,
show that alternating simulations compose accordingly,
-> our refinement is transitive too]

Also, show how to define $\mathbb{C}(-)$
for transition systems
and relationship to refinement by $\mathbb{C}$.

%}}}

\subsection{Relation to Compcert semantics} %{{{

[If we forget extcall events,
set $\tau = (\kw{unit}, \kw{int})$ and $\mathbb{C} = \kw{id}$,
and consider only receptive semantics
(that have every possible environment half-steps),
then everything boils down to the original Compcert framework.]

%}}}

\subsection{Per-Module Compiler correctness} %{{{

Changes to Compcert:
\begin{itemize}
\item Update the LTS framework (\kw{Smallstep.v})
  in the way we have indicated
\item Update \kw{extcall\_properties} to take into account
  refinement of events.
\item Connect queries/replies
  with the simulation relations in each pass
  (for initial/final states, and for external call boundaries
  following the new \kw{extcall\_properties})
\end{itemize}  

%}}}

\subsection{Composition of transition systems} %{{{

[Need to express domain of modules and discriminate
internal from external calls.
Store in the module type / language interface?
Provide as a parameter of composition?
We can also simply check whether there's at least
one state for the query,
though this may introduce some non-monotonicity.
Or modify $I$ in transition systems
to be a partial function $V \rightharpoonup \mathcal{P}(S)$
identifying which queries are supported.
Or just leave the extcall events there even when
they are resolved,
though the consequences of that are unclear.]

[NB: our transition systems could be indexed by two language interfaces,
one for the top-level interaction, and one for nested external calls]

\paragraph{Flat composition} %{{{

Flat composition
is a first-order approximation of horizontal composition
where two transition system $\sigma_1$ and $\sigma_2$
are laid out side by side,
but cannot interact with one another.
An execution of the resulting machine $\sigma_1 + \sigma_2$
will nondeterministically proceed,
either as an execution of $\sigma_1$,
or as an execution of $\sigma_2$.
If the two transition systems
handle disjoint sets of queries,
then $+$ will nonetheless preserve determinacy.

\begin{definition}[Flat composition]
Given two labeled transition systems
$\sigma_1 = (S_1, \rightarrow_1, I_1, F_1)$ and
$\sigma_2 = (S_2, \rightarrow_2, I_2, F_2)$
for a common language interface $\tau = (Q, R)$,
their flat composition is defined as
the labeled transition system
$\sigma_1 + \sigma_2 = (S, \rightarrow, I, F)$
where:
\begin{align*}
  S &:= S_1 + S_2 \\
  {\rightarrow} &:= {\rightarrow_1} + {\rightarrow_2} \\
  I &:= \{ (q, \iota_1(s_1)) : (q, s_1) \in I_1 \}
   \cup \{ (q, \iota_2(s_2)) : (q, s_2) \in I_2 \} \\
  F &:= \{ (\iota_1(s_1'), r) : (s_1', r) \in F_1 \}
   \cup \{ (\iota_2(s_2'), r) : (s_2', r) \in F_2 \}
\end{align*}
\end{definition}

To go from flat composition to vertical composition,
we will need to introduce a resolution operator $\mathcal{R}(\sigma)$
which allows $\sigma$ to call back into itself.
To illustrate the concepts involved,
we first introduce vertical composition.

%}}}

\paragraph{Vertical composition} %{{{

[It seemed like a good idea to take things one step at a time,
but $\mathcal{R}$ is simple enough (actually more simple than $\circ$)
that we probably don't need to do that and could skip to it directly.
Maybe a section with more explanations about continuations would
be a better fit here.]

In the vertical composition of transition systems,
external calls performed by a transition system
$\sigma_1 = (S_1, \rightarrow_1, I_1, F_1)$
are replaced by executions of a second transition system
$\sigma_2 = (S_2, \rightarrow_2, I_2, F_2)$.
The transition system
$\sigma_1 \circ \sigma_2 = (S, \rightarrow, I, F)$
will have two execution modes:
In the first,
it will execute $\sigma_1$ normally and
operate on states of type $S_1$.
When $\sigma_1$ would perform an external call,
$\sigma_1 \circ \sigma_2$ will switch to a second mode,
performing a nested execution of $\sigma_2$ instead.
In addition to the state of $\sigma_2$,
in this mode the machine will store a \emph{continuation}
$\kappa \subseteq R \times S_1$
of $\sigma_1$,
associating to each possible reply of $\sigma_2$
a set of resumption states for $\sigma_1$.

Accordingly,
the states of the composite LTS are:
\[
  S := S_1 + \mathcal{P}(R \times S_1) \times S_2
\]
Replies and queries
correspond to the top-level interaction of $\sigma_1$ with the environment:
\begin{align*}
  I &:= \{ (q, \iota_1(s_1)) : (q, s_1) \in I_1 \} \\
  F &:= \{ (\iota_1(s_1), r) : (s_1, r) \in I_1 \}
\end{align*}
During normal execution,
steps of $\sigma_1$ are used as-is:
\[
  \AxiomC{$s_1 \stackrel{e}{\rightarrow_1} s_1'$}
  \AxiomC{$e \notin \kw{extcall}$}
  \BinaryInfC{$\iota_1(s_1) \stackrel{e}{\rightarrow} \iota_1(s_1')$}
  \DisplayProof
\]
To express the switch to nested execution of $\sigma_2$,
we first give the set of continuations associated with a state $s$ of $\sigma_1$
about to perform an external call with the query $q$:
\[
  K(s, q) =
    \{ (r, s') : s \stackrel{e}{\rightarrow_1} s',
                     e = \kw{extcall}(q, r) \}
\]
The switch is triggered when \emph{at least one} external call event
can occur at the current point in the execution:
\[
  \AxiomC{$K(s_1, q) \ne \varnothing$}
  \AxiomC{$(q, s_2) \in I_2$}
  \BinaryInfC{$\iota_1(s_1) \rightarrow \iota_2(K(s_1, q), s_2)$}
  \DisplayProof
\]
Once the machine is in the second mode,
execution proceeds according to $\sigma_2$,
leaving the continuation unchanged:
\[
  \AxiomC{$s_2 \stackrel{t}{\rightarrow_2} s_2'$}
  \UnaryInfC{$
    \iota_2(\kappa, s_2)
    \stackrel{t}{\rightarrow}
    \iota_2(\kappa, s_2')$}
  \DisplayProof
\]
When a final state of $\sigma_2$ is reached,
the machine uses the continuation to switch back
to normal execution:
\[
  \AxiomC{$(s_2, r) \in F_2$}
  \AxiomC{$(r, s_1') \in \kappa$}
  \BinaryInfC{$\iota_2(\kappa, s_2) \rightarrow \iota_1(s_1')$}
  \DisplayProof
\]

%}}}

\paragraph{Resolution} %{{{

Horizontal composition may be understood as the infinite composition:
\[
  \mathcal{R}(\sigma_1 + \sigma_2) =
    (\sigma_1 + \sigma_2) \circ (\sigma_1 + \sigma_2) \circ \cdots
\]
In the following
we define the resolution operator $\mathcal{R}$ explicitely,
and show that it computes a fixpoint of $\sigma \circ -$.

The transition system $\mathcal{R}(\sigma)$
works similarly to vertical composition,
however instead of just two modes,
the machine will contain a stack of continuations,
allowing an arbitrary depth of calls.
We use the same definition of continuation $K(s, v)$
as for vertical composition.

\begin{definition}[Resolution operator]
Given a transition system $\sigma = (S, \rightarrow, I, F)$,
the closure [or whatever] of $\sigma$ is the transition system
$\mathcal{R}(\sigma) :=
  (S_\mathcal{R}, \rightarrow_\mathcal{R}, I_\mathcal{R}, F_\mathcal{R})$,
where:
\begin{align*}
  S_\mathcal{R} &:= S \times \mathcal{P}(L_F \times S)^* \\
  I_\mathcal{R} &:= \{ (q, s, \kw{nil}) : (q, s) \in I \} \\
  F_\mathcal{R} &:= \{ (s', \kw{nil}, r) : (s', r) \in F \} \,,
\end{align*}
and where $\rightarrow_\mathcal{R}$ is defined
by the following rules.
Normal execution operates on the top-level state:
\[
  \AxiomC{$s \stackrel{e}{\rightarrow} s'$}
  \AxiomC{$e \notin \kw{extcall}$}
  \BinaryInfC{$(s, \vec{\kappa}) \rightarrow_\mathcal{R} (s', \vec{\kappa})$}
  \DisplayProof
\]
Function calls are handled by pushing the current continuation
and starting a new top-level execution:
\[
  \AxiomC{$K(s, q) \ne \varnothing$}
  \AxiomC{$(q, s') \in I$}
  \BinaryInfC{$(s, \vec{\kappa}) \rightarrow_\mathcal{R} (s', K(s, q) :: \vec{\kappa})$}
  \DisplayProof
\]
Conversely,
whenever we reach a final state
and the stack is non-empty,
we resume the topmost continuation:
\[
  \AxiomC{$(s, r) \in F$}
  \AxiomC{$(r, s') \in \kappa$}
  \BinaryInfC{$(s, \kappa :: \vec{\kappa}) \rightarrow_\mathcal{R} (s', \vec{\kappa})$}
  \DisplayProof
\]
\end{definition}

\begin{theorem}[$\mathcal{R}(\sigma)$ is a fixed point]
$\sigma \circ R(\sigma) \equiv R(\sigma)$.
It is true and reassuring but do we care?
\end{theorem}

%}}}

\paragraph{Horizontal composition} %{{{

Now that we have defined $\mathcal{R}$,
we can define horizontal composition as:
\[
  \sigma_1 \bullet \sigma_2 := \mathcal{R}(\sigma_1 + \sigma_2)
\]

%}}}

%}}}

\subsection{Separate Compilation} %{{{

[Show the SepCompCert theorem
from lemmas that will have been introduced earlier]
\[
  \mathbb{C}(\llbracket M_1 + M_2 + \cdots \rrbracket) \sqsupseteq
  \llbracket C(M_1) + C(M_2) + \cdots \rrbracket
\]
We will need:
\begin{itemize}
\item compositionality:
  $\llbracket M_1 + M_2 \rrbracket \equiv
   \llbracket M_1 \rrbracket \bullet \llbracket M_2 \rrbracket$
  for both C and assembly
\item monotonicity of $\mathbb{C} : {\sqsupseteq} \rightarrow {\sqsupseteq}$
\item monotonicity of $\bullet : {\sqsupseteq} \times {\sqsupseteq} \rightarrow {\sqsupseteq}$
\item per-module correctness theorem $\mathbb{C}(\llbracket M_i \rrbracket) \sqsupseteq \llbracket C(M_i) \rrbracket$.
\end{itemize}

%}}}

\subsection{[Stuff to remove/redistribute]}

{ \color{gray}

Our analytical framework
yields a small number of changes
which can be applied to Compcert for
turning it into a compiler suitable for use
in the context of end-to-end verification:
\begin{enumerate}
\item Compcert models the interaction of programs
  with their environment in terms of event traces.
  However,
  these event traces are not expressive enough
  to model the interaction between modules in a satisfactory manner.
  Following \cite{cpp2015},
  the addition of \emph{external call events} to traces
  and the generalization of our program semantics
  to operate on a function-by-function basis
  bridges this gap in expressivity.
\item Because external calls are realized differently
  at the level of C and assembly modules,
  the source and target semantics
  will use different kinds of external call events.
  To account for this discrepancy,
  the formulation of compiler correctness
  will involve an explicit \emph{calling convention},
  relating external calls in the source and target languages.
\item 
  Open-system refinement: understand Compcert events
  as two actions: one by the system, one by then environment in reaction.
  Then correponding mixed-variance refinement of events.
  Follows the work on Interface Automata \cite{ia},
  avoiding many of the complications.
\item
  Then composition
\item
  Work out what is necessary to support this
  at the level of transition systems / give an operational account
  (generalized initial and final states,
  appropriate notion of simulation)
\end{enumerate}

}

%}}}

\section{A Richer Semantic Domain} %{{{

\subsection{Games}
\subsection{Strategies}


%}}}

\section{Applications} %{{{

\subsection{Non-Local Jumps}
\subsection{Context Switching}
\subsection{Thread library}
\subsection{File-System Interaction}

%}}}

\section{Future Work} %{{{

\subsection{Signals}
\subsection{Concurrency}
\subsection{Relaxed Memory Models}
\subsection{Abstraction of Values} %parametricity? can use pointers + empty mem block?

%}}}

\section{Related Work} %{{{

\begin{table*}
  \begin{tabular}{lcccccc}
    \hline
    & Expressivity & Abstraction & Refinement & Compositionality & Open systems & Resources \\
    \hline
    Compcert \cite{compcert}
      &           &           & $\bullet$ &           &           & \\
    CompCertX \cite{popl2015}
      &           & $\circ$   & $\bullet$ & $\circ$   &           & \\
    Compositional CompCert \cite{compcompcert}
      & $\circ$   &           & $\bullet$ & $\circ$   & $\bullet$ & \\
    Ramananandro et al. \cite{cpp2015}
      & $\circ$   &           & $\bullet$ & $\bullet$ & $\bullet$ & \\
    QompCert \cite{qompcert}
      &           &           & $\bullet$ &           &           & $\bullet$ \\
    SepCompCert \cite{lwsc}
      &           &           & $\bullet$ & $\circ$   &           & \\
    This work
      & $\circ$   & $\bullet$ & $\bullet$ & $\bullet$ & $\bullet$ & \\
    \hline
  \end{tabular}
\end{table*}

%}}}

\bibliography{lwcc}

\end{document}
