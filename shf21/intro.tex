\section{Introduction}
\label{sec:intro}

Over the past decade, researchers have been able to formally verify
various key components of computer systems, including compilers
\cite{compcert,cakeml,vellvm}, OS kernels \cite{sel4,dscal15,certikos-osdi16},
file systems \cite{fscq} and processor designs \cite{safe,kami}.
Building on these successes, the research community is attempting to
construct large-scale, heterogeneous certified systems by using formal
specifications as interfaces between the correctness proofs of various
components \cite{deepspec}.  The ongoing design of suitable semantic
frameworks is an important step towards this goal.  However,
incorporating certified compilers into frameworks of this kind
presents a number of difficulties.

\subsection{Compositional Compiler Correctness}
\label{ssec:intro-ccc}

Compiler correctness is often formulated as a \emph{semantics
preservation} property, asserting that the semantics of the compiled
program $\kw{C}(p)$ are related in some particular way to the
semantics of the source program $p$:
\begin{equation} \label{eqn:semp}
  \llbracket p \rrbracket_\kw{S} \sim
  \llbracket \kw{C}(p) \rrbracket_\kw{T}
  \,.
\end{equation}
For whole-program compilers, semantics preservation is straightforward
enough.  In CompCert~\cite{compcert}, the semantics of the source and
target programs (denoted as $\llbracket \cdot \rrbracket_\kw{S}$
and $\llbracket \cdot \rrbracket_\kw{T}$)
are given as labeled transition systems, and the
relation $\sim$ is a simulation property.

However, practical applications involve program \emph{components}
which we want to compile and verify separately from each other.  In
principle, the use of a compositional semantics enables the
formulation of (\ref{eqn:semp}) at the level of individual components.
Unfortunately, traditional approaches to compositional semantics fare
poorly in the presence of advanced language features, or of the kind
of abstraction involved in the compilation process.  For CompCert,
early attempts along these lines have proven challenging
\cite{cpp15,compcompcert}.

As a result, common wisdom holds semantics preservation to be a lost
cause for compositional compiler correctness \cite{next700}.  Instead,
research has focused on compositional reasoning methods based on
contextual refinement, side-stepping the need for compositional
semantics preservation \cite{sepcompcert,compcertm}.

\subsection{Decomposing Heterogeneous Systems}
\label{ssec:intro-dhs}

Unfortunately, these methods share an intrinsic limitation: they
presuppose the existence of a completed system to be proven correct,
and compositionality only operates within its boundary.  This becomes
a serious impediment in the context of large-scale heterogeneous
systems.

\begin{example} \label{ex:nicdriver} 
Consider the problem of verifying a network interface card (NIC)
driver.  The NIC and its driver are closely coupled, but the details
of their interaction are irrelevant to the rest of the system; these
details should not leak into our large-scale reasoning.  Instead, we
wish to treat the NIC and its driver as a unit, and establish a direct
relationship between C calls into the driver and network
communication.  Together, the NIC and driver implement a specification
$\sigma : \li{Net} \rightarrow \mathcal{C}$, meaning they \emph{use}
the interface $\li{Net}$ modeling the network, and \emph{provide} the
interface $\mathcal{C}$ modeling C function calls.

The driver code could be specified ($\sigma_\kw{drv}$) and verified at
the level of CompCert semantics, whereas device I/O primitives
($\sigma_\kw{io}$) and the NIC itself ($\sigma_\kw{NIC}$) would be
specified as additional components in the context of a richer model:
\[
  \sigma_\kw{NIC} : \li{Net} \rightarrow \li{IO}
  \qquad
  \sigma_\kw{io} : \li{IO} \rightarrow \mathcal{C}
  \qquad
  \sigma_\kw{drv} : \mathcal{C} \rightarrow \mathcal{C}
\]
By reasoning about their interaction, it would be possible to
establish a relationship between the overall specification $\sigma :
\li{Net} \rightarrow \mathcal{C}$ and the composition $\sigma_\kw{drv}
\circ \sigma_\kw{io} \circ \sigma_\kw{NIC}$.  Then a \emph{compiler of
certified components} should help us transport specifications and
proofs obtained at the C level %with respect to the driver's C code to
the compiled code operating at the level of assembly ($\sigma' :
\li{Net} \rightarrow \mathcal{A}$).
\end{example}

Under existing contextual approaches, the NIC driver can only be
specified and verified in terms of its interactions at the boundary of
the C program code.  Since abstracting away from these interactions is
the role of a driver in the first place, this is a serious limitation.
To be sure, existing techniques could be extended to address this
specific problem.  For example, the NIC hardware model could be
brought within the scope of the ``whole program'' being considered,
and the exchange of Ethernet packets modeled as part of its observable
behavior.  However, this approach does not scale.

Example~\ref{ex:nicdriver} is by no means a contrived corner case. In
fact, patterns of this kind are pervasive even in more mundane
situations.  Programmers often use libraries which mediate access to
external resources (network services, file systems, user interfaces).
Proper high-level specifications for software components of this kind
must model these resources.  It would rapidly become burdensome to
expect the verification framework to fix in advance the dozens or
hundreds of kinds of resources which may be involved in the course of
verifying a large-scale system.

Fortunately, advances in compositional semantics offer a realistic
path to tackling problems of this kind.
Game semantics
(\S\ref{sec:gamesem}) provides a general and expressive framework to
model interactions between typed components.
Yet work on compositional semantics in general,
and game semantics in particular,
is often oriented towards theoretical understanding,
while practitioners of formal methods and verification
tend to rely on more concrete operational models.

\subsection{Research Direction}

Our ambition is to show that %beyond theoretical interest,
game semantics
can serve as the foundation
for a rich and compositional framework
suitable for the end-to-end verification of
large-scale, heterogeneous systems.
This framework would
bring together strands of research
which to date have only been considered separately,
and would enable
the verification of large-scale heterogeneous systems.

In recent work, we proposed
integrating dual nondeterminism and refinement into game semantics,
extending it with powerful mechanisms to account for abstraction
\cite{koenig20,layered22}.
On a more practical level,
we have developed CompCertO \cite{compcerto},
a version of CompCert which
%borrows ideas from game semantics and certified abstraction layers
provides a correctness theorem for CompCert
stated in terms of a compositional semantics.
This work points in the direction of a two-dimensional algebra 
of systems and abstraction, and
provides preliminary evidence
for the thesis outlined above.
%for the suitability of game semantics for the problem at hand.

\subsection{Challenges}

Nonetheless,
There remains many theoretical and practical challenges
in bringing to life
our vision of end-to-end, heterogeneous verification.
The situation described in Example~\ref{ex:nicdriver}
is fairly specific, but it already illustrates many of these challenges:
\begin{itemize}
  \item the interfaces involved in different parts of the system
    are very different in nature;
  \item a system composed of a NIC and CPU
    is inherently concurrent;
  \item the NIC carries persistent state
    which is isolated from the rest of the system;
  \item it must be possible to reason at different levels of abstraction---%
    in terms of network connections and C function calls
    but also ethernet frames and device I/O, and
    ideally all the way down to logic gates and machine code;
  \item the example relies on general categorical structures for composition $\circ$,
    rather than ad-hoc composition principles tailored to a particular application;
  \item it is not only a theoretical but also an engineering problem---%
    the mathematics involved in solving it must be
    amenable to mechanization in a proof assistant.
    %and must integrate with a certified compiler.
\end{itemize}
There has of course been
extensive research
addressing each of these challenges independently.
Yet designing a compositional framework tackling all of them
is not simply a matter of juxtaposing existing solutions.
For example,
to support both concurrency and abstraction,
it is not sufficient to separately borrow
a theory of concurrent traces and
another theory to describe
how interactions at different abstraction levels
correspond to one another.
We must also work out how the structures
of the former
fit into the latter's methodology.

Our interest in game semantics
stems in part from this fact:
not only has existing work in the field
addressed many of the issues above,
it has done so in a context where games and strategies
provide a unifying point of articulation
between these different strands of research.
This has allowed researchers
to establish \emph{semantic cubes}
encompassing certain combinations of features.

Likewise,
our focus on verified compilation
is not just a matter of the practical utility of compilers
in the construction of certified systems.
Certified compilers constitute a nexus where
many of the challenges above either appear organically
(for example,
a compiler's \emph{calling convention} describes an abstraction relationship
between the operation of input and output programs),
or must be taken into account
(a compiler which is correct for sequential code
does not necessarily remain so in the presence of concurrency).

\subsection{Intellectual Merit}
\label{ssec:intro-itm}

In this context,
our proposal seeks to build on existing research
on the certified compiler CompCert
to consolidate and extend its capabilities in various directions,
focusing in particular on the interactions between
compositionality,
the management of \emph{state},
modeling of low-level interfaces and mechanisms, and
the preservation of information security.
%
%In addition to these deficiencies, the current CompCert is not end-to-end
%in that it can only produce assembly code but not actual binary
%machine code. There are still no certified linker and loader that can
%work directly with ELF binaries.  CompCert also does not support secure
%compilation: source program that is provably information-flow secure
%can still be compiled into target code that contains information leaks.
%
Concretely,
we propose to develop a novel verified compilation
toolchain that would tackle these challenges simultaneously. Our
proposed research consists of the following five components:
\begin{itemize}
%%%%%%%%%%%%%%%
\item First, we will contribute new technologies for supporting {\em
  compositional verified compilation}.
  We will build on CompCertO's model of
  game-semantic {\em language interfaces} and {\em calling conventions}
  by elucidating the underlying categorical structures
  and incorporating support for {\em encapsulated state}.
%%%%%%%%%%%%%%%
\item To overcome challenges which arise
  in a compositional treatment of state,
  we will then address existing inflexibilities
  in CompCert's block-based memory model.
  Our approach is based on \emph{nominal
  techniques}~\cite{pitts-nominal,gabby2002}. By generalizing block
  ids to {\em atomic names}, and valid blocks to {\em supports}, and by
  eliminating global constraints via {\em supports}, we will develop a
  novel {\em nominal memory model} that enables flexible memory
  structures for open and concurrent programs.
%%%%%%%%%%%%%%%  
\item Third, we will develop an {\em end-to-end and compositional
  verified compiler} that can compile C components all the way into
  ELF object files. We will compile open programs and threads with
  nominal memory models into those with concrete machine-level memory
  layout. We will also build verified compositional assembler,
  linker, and loader that can work directly with ELF binaries.
%%%%%%%%%%%%%%%    
\item Fourth, basing upon our prior work on compositional semantics
  for certified abstraction layers~\cite{dscal15,ccal18,koenig20,layered22},
  we will support {\em verified security-preserving
  compilation}~\cite{costanzo16} by developing a general framework
  for the specification, abstraction, and refinement of heterogeneous
  components.
%%%%%%%%%%%%%%%  
\item Fifth, to demonstrate the power and real-world applicability of
  our new verified compiler, we will apply it to build more advanced
  certified concurrent OS kernels and hypervisors (e.g., CertiKOS~\cite{certikos-osdi16}
  and SeKVM~\cite{sekvm21a,sekvm21b,tao21}) and certified programming tools
    (e.g., DeepSEA~\cite{deepsea19} and VST~\cite{appel11:vst}).
\end{itemize}
