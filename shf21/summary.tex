\noindent{\bf Project Summary}

{\bf Overview:} In the last 50 years, the C programming language and
its associated toolchain (e.g., compiler, assembler, linker, loader,
memory model, and application binary interface or ABI) have served as
the primary buiding blocks in the development of today's mainstream
system software stack. The formally verified C compiler CompCert is a
recent breakthrough that holds the promise to become the bedrock of
future {\em certified} heterogeneous system stack.  Indeed,
during the last decade, researchers have been refining the CompCert
language semantics and correctness theorem, and used them as
components in various software verification efforts. Artifacts such as
OS kernels and hypervisors, processor designs, file systems, and
network protocols have been successfuly verified. The significance of
CompCert rests not only on its verified compiler but also on the full
formalization of the ANSI C memory model and ABIs as well as the
operational semantics for all of its source, intermediate, target
languages.

Unfortunately, the CompCert ecosystem today still suffers from the
following major shortcomings. First, it does not support compositional
compilation and linking of heterogeneous C and assembly components.
Second, it uses a restricted memory model that has a rigid name space
and is incompatible with multithreaded or multicore programs.  Third,
it is not end-to-end in that CompCert can only produce assembly code
but not actually binary machine code; there are still no certified
linker and loader that can work directly with ELF (Executable and
Linkable Format) binaries.  Fourth, it does not support secure
compilation; source program that is provably information-flow secure
may be compiled into target code that contains information leaks.

{\bf Keywords:} Compositional Compiler Correctness; Verified C Compiler;
Compositional Semantics; Formal Specification and Verification;
Nominal Techniques; Secure Compilation.

{\bf Intellectual Merit:} In this effort, the PIs propose to
develop a novel verified compilation toolchain that would address
all of the above shortcomings. More specifically,
\begin{itemize}
%%%%%%%%%%%%%%%
\item by using game semantics techniques and richer language interfaces,
they propose to develop a novel {\bf compositional verified compiler} that
can establish a truly compositional compiler correctness theorem for
open heterogeneous components;
%by relating the behaviors of source and target components directly;
%%%%%%%%%%%%%%%
\item they propose to develop a novel {\bf nominal memory model}---an
enhancement to CompCert's block-based memory model with nominal
techniques---to remove the global constraints for managing memory
blocks, and enable flexible memory structures for open and concurrent
programs;
%%%%%%%%%%%%%%%
\item basing upon their prior work on CompCertELF, they will develop an
{\bf end-to-end and compositional verified
compiler} that can compile C components all the way into ELF
object files; they will also build {\em verified compositional linker
and loader} that can work directly with ELF binaries;
%%%%%%%%%%%%%%%
\item they will develop a general
framework for specification, abstraction, and refinement in
compositional semantics, and apply this framework to connect
certified abstraction layer with verified compiler and support
{\bf verified security-preserving compilation};
%%%%%%%%%%%%%%%
\item they will evaluate the effectiveness of the new verified compiler
toolchain in two case studies: one is to use it to build more sophisticated
certified concurrent OS kernels and hypervisors; another is to
use it as a compiler backend for the DeepSEA certified programming tool.
\end{itemize}

{\bf Broader Impact:} The technology for simplifying distributed
system reasoning and allowing for verification of distributed system
composition will have a profound impact on the software industry and
the society in general. It will dramatically improve the reliability
and security of large-scale software infrastructures, such as the
cloud, and applications that run on top of the infrastructure.  The
atomic distributed object specification and the verification framework
will make distributed infrastructures easier to understand and verify.
The applicability of the research outcome can be easily extended to
relevant fields such as cyber physical systems or internet of things
that use multiple sensors and devices over the network.  On the
educational side, this project will push new courses on distributed
system design and verification and will broaden the participation of
underrepresented groups.

