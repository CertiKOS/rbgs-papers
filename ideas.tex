\section{Main ideas}

\subsection{Principles for system construction}

The goal of certified system design is
to create a formal description of
the system to be constructed (the program),
while ensuring through careful analysis that the system
will behave properly.

To carry out this analysis,
we need a model
which assigns to each possible system description $p \in P$
a mathematical object $\llbracket p \rrbracket \in \mathbb{D}$
representing its behavior.
We will call the set $\mathbb{D}$ a \emph{semantic domain}.
In this section we elucidate
the structure and properties of $\mathbb{D}$
necessary to the process of builing
large-scale certified systems.

\subsubsection{Specifications and refinement}

System design starts with a set of requirements
that constrain the behavior of the system to be constructed
(the specification).
These requirements may not capture every detail
of the behavior of the eventual system,
but instead delineate the range of acceptable behaviors
from the point of view of its environment.

In the context of refinement-based methods,
the specifications are themselves elements of
the semantic domain $\mathbb{D}$,
which is equipped with a \emph{refinement} preorder
${\sqsubseteq} \subseteq \mathbb{D} \times \mathbb{D}$.
The proposition $\sigma_1 \sqsubseteq \sigma_2$
assert that $\sigma_2$ is a less restrictive specification than $\sigma_1$,
and in particular a system description $p \in P$ is a correct implementation
of $\sigma \in \mathbb{D}$ when:
\[ \llbracket p \rrbracket \sqsubseteq \sigma \]

\subsubsection{Compositionality}

Complex systems are built by assembling components
whose behavior is understood,
such that their interaction achieves a desired effect.
The syntactic constructions of
the language used to describe systems
correspond to the ways in which they can be composed.

To enable compositional reasoning,
a suitable model must provide an account of
the behavior of the composite system
in terms of the behavior of its parts.
For instance,
if the language contains a binary operator
${+} : P \times P \rightarrow P$,
then the semantic domain should be equipped with
a corresponding operation
${\bullet} : \mathbb{D} \times \mathbb{D} \rightarrow \mathbb{D}$
such that:
\[ \llbracket p_1 + p_2 \rrbracket =
   \llbracket p_1 \rrbracket \bullet \llbracket p_2 \rrbracket \,. \]

We can use this property
to show that a composite system
satisfies a given specification,
for instance
$\llbracket p_1 + p_2 \rrbracket \sqsubseteq \sigma$.
Once this has been established,
we will want to abstract the composite system as a ``black box''
which can in turn be used as a primitive component in a larger system.
Further reasoning can be done in terms of
the new component's specification $\sigma$ rather than
its concrete behavior $\llbracket p_1 + p_2 \rrbracket$.
To support this,
we must establish that semantic composition operators
are compatible with refinement in the following sense:
\[ \sigma_1 \sqsubseteq \sigma_1' \wedge
   \sigma_2 \sqsubseteq \sigma_2' \Rightarrow
   \sigma_1 \bullet \sigma_2 \sqsubseteq \sigma_1' \bullet \sigma_2' \,. \]
Should $p_1 + p_2$ be used as a component in a larger system,
this property will allow us to establish that:
\[ \llbracket (p_1 + p_2) + p_3 \rrbracket \sqsubseteq
   \sigma \bullet \llbracket p_3 \rrbracket \,. \]

\subsubsection{Abstraction}

Large-scale systems operate across many layers of abstraction.
Each abstraction layer defines its own understanding of the interaction
between the system and its environment.
To relate abstraction layers we will need to give an explicit account
of how their formulations of the interaction correspond to one another.

For example,
at the physical level,
communication over a wire may involve a series of voltages through time,
but at a higher level of abstraction
we will only be concerned with the sequence of bytes
being transmitted.
Serial communication hardware (for instance a UART device)
serves as a bridge between these two views,
implementing a byte-oriented communication channel
in a voltage-oriented world;
to formally verify such a component we will need to
express the correspondance between these two
layers of abstraction.

This can be done by defining an embedding
$\mathbb{C} : \mathbb{D}_s \rightarrow \mathbb{D}_t$
between the semantic domains
used to reason at different levels of abstraction.

[...]

\subsubsection{Compilers}


\subsubsection{Heterogeneity}

[What happens to $\mathbb{D}$ in the context of typed languages,
how this can be used to gain expressivity and construct heterogenous systems.]


\subsection{Game semantics}

[introductory remarks]

Types are interpreted as two-player games,
which specify the form of valid interactions
between the system and the environment.
Terms are interpreted as strategies for these games,
which for any position in the game
specify the next move to be played by the system.

\subsubsection{Games}

A game is usually defined by giving a set of moves $M$
that players can choose from,
as well as a specification of which
sequences of moves are considered valid.
For chess,
moves will be taken in the set $(\{a, \ldots, h\} \times \{1, \ldots, 8\})^2$,
and a sequence of moves may look like:
\[ e2e4 \cdot \underline{c7c5} \cdot c2c3 \cdot \underline{e7d5} \cdots \]
For a program expected to produce a natural number,
the possible moves may be a request to evaluate ($\kw{q}$)
and primitive values ($42$),
so that an interaction between the expression $21 \times 2 : \kw{nat}$
and its evaluation context will proceed as:
\[ \kw{q} \cdot \underline{42} \]
Note that we underline the moves of the second player,
namely the system.

We will focus on two-player, alternating games
where the environment and the system each contribute every other move.
The environment plays first.
Positions in the game can be given
as sequences of moves;
even-length sequences correpond to positions
where the environment is expected to move,
and odd-length sequences correspond to positions
where the system is expected to move.

\subsubsection{Strategies}

In this context,
it is natural to think of system strategies
as functions from odd-length positions to moves:
\[ \sigma : \bigcup_n M^{2n+1} \rightharpoonup M \]
For example,
the strategy $\llbracket 21 \times 2 \rrbracket$
will be the partial function with a single mapping $\kw{q} \mapsto 21$,
whereas the black player in the chess play above
has used a strategy $\sigma$ containing:
\[
  \sigma(e2e4) = c7c5 , \quad
  \sigma(e2e4 \cdot c7c5 \cdot c2c3) = e7d5 , \quad
  \ldots
\]

This is suitable to express the behavior of a concrete system.
However, for specifications allowing a range of behavior,
we must generalize strategies to allow nondeterminism:
\[ \sigma : \bigcup_n M^{2n+1} \rightarrow \mathcal{P}(M) \]
This is isomorphic to
$\mathcal{P}(\bigcup_n M^{2n+2})$
and corresponds to the usual encoding of strategies
as sets of traces.

Equivalently,
a strategy can be given as a
nonbranching
\emph{alternating transition system},
with environment moves performing transitions from
a set of continuations $K$ to a set of states $S$,
and conversely
transitions from a state $S$ to a continuation $K$
emitting a system move.
We obtain a strategy by
specifying an initial continuation and
abstracting over $K$ and $S$:
\[ \sigma : \exists \, K S \,.\, K \times
      (K \times M \rightharpoonup S) \times
      (S \times M \rightharpoonup K) \]
Two strategies will be equivalent
when simulations can be established between them.

Any strategy given as a transition system
defines a partial mapping between the positions in the game
where the system is to play
and the set of states $S$ used by the strategy,
which can then be queries for the set of possible
system moves associated with the position.
The transition-system presentation of strategies
is less standard in existing game semantics literature
but is easier to relate to operational semantics
and may be easier for formalize.

\subsubsection{Compositionality}

While the game for $\kw{nat}$ given above
is extremely simple,
the expressive power of game semantics
comes from the way in which complex games can be derived
from simple ones to interpret compound types.

For instance,
given two games $A$ and $B$,
the game $A \otimes B$ is traditionally defined
to allow $A$ and $B$ to be played side by side.
The set of moves will be $M_{A \otimes B} = M_A + M_B$,
and for any valid position of $A \otimes B$,
the subsequence consisting of the moves of a constituent game
is expected to be valid in that game.
An interaction in the game
$\llbracket \kw{nat} \rrbracket \otimes
 \llbracket \kw{nat} \rrbracket$ could be:
\[ i_2(q) \cdot \underline{i_2(42)} \cdot
   i_1(q) \cdot \underline{i_1(7)} \]

There are two other important constructions on games.
In the game $A \multimap B$,
we play the games $A$ and $B$ simultaneously,
but in the game $A$ we play the role of the environment.
In other words,
a strategy for $A \multimap B$
primarily implements the game $B$,
but can also rely on an implementation of $A$.
Finally,
the game $!A$
consists of multiple copies of the game $A$,
which are instantiated at the discretion of the environment.

These constructions can be used together
to express the structure of various kinds of interactions.
For instance,
the type $!A \multimap B$ is traditionally used
to model the behavior of a $\lambda$-term of type $A \rightarrow B$,
which can access its argument multiple times.
In the context of CompCert,
the game $!C \multimap C$
represents the way a C module behaves in response to an activation
(as specified by the game $C$),
while being able to perform any number of external calls ($!C$),
and corresponds to the \emph{interaction semantics} defined in
\cite{compcompcert}.
In this work,
we will extend this to the game $!C \multimap !C$,
which will allow components to maintain
persitent, hidden state across activations
and express the behavior of reentrant calls.

\subsubsection{Refinement}

[alternating refinement, $\lightning$, etc]

\subsubsection{Abstraction}

This concept of refinement can be extended to account for
different levels of abstraction.


[etc]

The polarisation inherent in game semantics
can be seen to naturally encode the rely-guarantee aspects
of the C calling convention.

\subsection{Logical relations}

Given an algebraic structure $\mathcal{S}$
involving a number of operations over a carrier set,
a \emph{logical relation}
between two instances $S_1, S_2$ of $\mathcal{S}$
will be a relation $R \subseteq |S_1| \times |S_2|$
between their carrier sets,
such that the operations of $\mathcal{S}$
take related arguments to related results.
We write $R : \mathcal{R}(S_1, S_2)$.

\begin{example}[Logical relation of monoids]
\label{ex:monoid}
A \emph{monoid} is a set $A$ equipped with
an associative binary operation $\cdot$ and
an identity element $\epsilon$.
A \emph{logical relation of monoids} between
a monoid $\langle A, \cdot_A, \epsilon_A \rangle$ and
a monoid $\langle B, \cdot_B, \epsilon_B \rangle$
is a relation $R \subseteq A \times B$
such that:
\begin{gather*}
u \ifr{R} u' \wedge v \ifr{R} v' \Rightarrow u \cdot_A v \ifr{R} u' \cdot_B v' \\
\epsilon_A \ifr{R} \epsilon_B
\end{gather*}
\end{example}

Logical relations between multisorted structures
will include one relation for each sort,
between the corresponding carrier sets.
In the case of structures which include type operators,
we can associate to each base type $A$
a relation over its carrier set $\llbracket A \rrbracket$,
and to each type operator $T(A_1, \ldots, A_n)$
a corresponding \emph{relator}:
given relations $R_1, \ldots, R_n$ over
the carrier sets $\llbracket A_1 \rrbracket, \ldots, \llbracket A_n \rrbracket$,
the relator for $T$
will construct a relation $T(R_1, \ldots, R_n)$
over $\llbracket T(A_1, \ldots, A_n) \rrbracket$.

\begin{figure} % fig:relators {{{
  {\small
  \begin{align*}
    x \ifr{R_1 \times R_2} y \ \Leftrightarrow\  &
      \pi_1(x) \ifr{R_1} \pi_1(y) \wedge
      \pi_2(x) \ifr{R_2} \pi_2(y) \\
    x \ifr{R_1 + R_2} y \ \Leftrightarrow\  &
      (\exists \, x_1 \, y_1 \,.\,
        x_1 \ifr{R_1} y_1 \wedge
        x = i_1(x_1) \wedge
        y = i_1(y_1)) \\ \vee\ &
      (\exists \, x_2 \, y_2 \,.\,
        x_2 \ifr{R_2} y_2 \wedge
        x = i_2(x_2) \wedge
        y = i_2(y_2)) \\
    f \ifr{R_1 \rightarrow R_2} g \ \Leftrightarrow\  &
      \forall \, x \, y \,.\,
        x \ifr{R_1} y \Rightarrow
        f(x) \ifr{R_2} g(y) \\
    A \ifr{\mathcal{P}^+(R)} B \ \Leftrightarrow\  &
      \forall \, x \in A \,.\,
      \exists \, y \in B \,.\,
      x \ifr{R} y \\
    A \ifr{\mathcal{P}^-(R)} B \ \Leftrightarrow\  &
      \forall \, y \in B \,.\,
      \exists \, x \in A \,.\,
      x \ifr{R} y
  \end{align*}
  }%
  \caption{A selection of relators}
  \label{fig:relators}
\end{figure}
%}}}

Relators for some common constructions are shown in Fig.~\ref{fig:relators}.
Note that the first requirement given in Ex.~\ref{ex:monoid}
can be expressed as:
\[
  \cdot_A \ifr{R \times R \rightarrow R} \cdot_B
\]

Logical relations used to establish contextual equivalence
are often partial equivalence relations (PER);
by contrast, our focus is refinement,
so that most of the relations we consider will not be symmetric.

%}}}

\subsection{Kripke logical relations} %{{{
\label{sec:klr}

The ways in which the components of a complex structure should be related
are not always independent.
To preserve compositionality while ensuring that
components are related in a consistent way,
we can parametrize a logical relation
over a set $W$ of \emph{possible worlds}.
Components related at the same world will be related
in compatible ways.

\begin{definition}
For a given set $W$,
a \emph{Kripke logical relation} is
$W$-indexed family of logical relations $(R_w)_{w \in W}$.
We write $R : \mathcal{R}_W(S_1, S_2)$
for a Kripke logical relation between structures $S_1$ and $S_2$,
and define the following relations:
\begin{align*}
  x \ifr{w \Vdash R} y &\Leftrightarrow x \ifr{R_w} y \\
  x \ifr{\Vdash R} y &\Leftrightarrow \forall w \,.\, x \ifr{R_w} y \,.
\end{align*}
\end{definition}

In the remainder of this section,
we introduce some useful constructions on
Kripke logical relations.

\subsubsection{Kripke relators}

A logical relation $R : \mathcal{R}(A, B)$
can be promoted to a $W$-indexed Kripke logical relation $\lceil R \rceil$
which ignores the index, so that $\lceil R \rceil_w = R$.
Likewise,
a relator
  $F : \mathcal{R}(A_1, B_1) \,\times\,\cdots\,\times\,\mathcal{R}(A_n, B_n) \rightarrow \mathcal{R}(A, B)$
can be promoted to its Kripke version
by pointwise extension over the set of possible worlds:
\begin{gather*}
  \lceil F \rceil : \mathcal{R}_W(A_1, B_1) \times \cdots \times \mathcal{R}_W(A_n, B_n) \rightarrow \mathcal{R}_W(A, B) \\
  \lceil F \rceil (R_1, \ldots, R_n)_w = F(R_{1,w}, \ldots, R_{n,w})
\end{gather*}
We use $\lceil - \rceil$ implicitly
when a relator appears in a context where
a Kripke logical relation is expected.

\subsubsection{Modalities}

Next we define Kripke relators
allowing us to [move between possible worlds].

\begin{definition}
A \emph{Kripke frame}
is a labelled transition system
$\langle W, (\stackrel{l}{\leadsto})_{l \in \Lambda} \rangle$, where
$W$ is a set of \emph{possible worlds},
$\Lambda$ is a set of labels, and
$(\stackrel{l}{\leadsto})_{l \in \Lambda}$ is a family of
binary \emph{accessibility relations} over $W$.
\end{definition}

For a Kripke frame
$\langle W, (\stackrel{l}{\leadsto})_{l \in \Lambda} \rangle$,
we define the Kripke relators $\langle l \rangle$, $[l]$ as follows:
\begin{align*}
  x \ifr{w \Vdash \langle l \rangle R} y & \: \Leftrightarrow \:
    \exists \, w' \,.\, w \stackrel{l}{\leadsto} w' \wedge
      x \ifr{w' \Vdash R} y \\
  x \ifr{w \Vdash [ l ] R} y & \: \Leftrightarrow \:
    \forall \, w' \,.\, w \stackrel{l}{\leadsto} w' \Rightarrow
      x \ifr{w' \Vdash R} y
\end{align*}
In the context of an unlabelled Kripke frame ($\Lambda = \{ * \}$),
we will write $\langle * \rangle$ as $\Diamond$ and
$[ * ]$ as $\Box$.

\begin{example}[Simulation diagram]
\label{ex:sim}
Consider a Kripke logical relation of sets $R : \mathcal{R}_W(A, B)$,
and two transition relations $\alpha : A \rightarrow \mathcal{P}(A)$
and $\beta : B \rightarrow \mathcal{P}(B)$.
The simulation diagram:
\[
  \begin{tikzcd}
    s_1 \arrow[r, "\alpha"]
        \arrow[d, dash, "R_w"'] &
    s_1' \arrow[d, dotted, dash, "R_{w'} \quad (w \leadsto w')"] \\
    s_2 \arrow[r, dotted, "\beta"] &
    s_2'
  \end{tikzcd}
\]
can be written as:
\[
  \alpha \ifr{\Vdash R \rightarrow \mathcal{P}^+(\Diamond R)} \beta \,.
\]
\end{example}

\subsubsection{Using labels}
\label{sec:klrlabels}

A frame with labels in $\Lambda$
can naturally be extended to a frame with labels in $\Lambda^*$.
For $s = l_1 \cdots l_n$, we define:
\[
    {\stackrel{s}{\leadsto}} =
    {\stackrel{l_1}{\leadsto}} \, ; \cdots ; {\stackrel{l_n}{\leadsto}}
\]
Note that $\langle s \rangle R$ is equivalent to
$\langle l_1 \rangle \cdots \langle l_n \rangle R$
and similarly $[s] R$ is equivalent to
$[ l_1 ] \cdots [ l_n ] R$.

For frames labelled by pairs
($\Lambda = \Lambda_1 \times \Lambda_2$),
we define variants of $\Box, \Diamond$ which
allow world transitions to interact with the components
being related.
The relator
$\Diamond \times - : \mathcal{R}_W(A, B) \rightarrow
            \mathcal{R}_W(\Lambda_1 \times A, \, \Lambda_2 \times B)$
is defined as follows:
\[
  (l_1, a) \ifr{w \Vdash \Diamond \times R} (l_2, b) \Leftrightarrow
    a \ifr{w \Vdash \langle l_1, l_2 \rangle R} b
\]
$\Box \rightarrow - : \mathcal{R}_W(A, B) \rightarrow
        \mathcal{R}_W(\Lambda_1 \rightarrow A, \, \Lambda_2 \rightarrow B)$
is defined as:
\[
  f \ifr{w \Vdash \Box \rightarrow R} g \Leftrightarrow
    \forall \, l_1 l_2 \,.\, f(l_1) \ifr{w \Vdash [l_1, l_2] R} g(l_2)
\]

%\subsection{CompCert}

\endinput

\section*{Before}

\subsection{Languages} %{{{

Formally,
a programming language $L$ is understood as
a set of programs $p$
which are assigned a meaning $\llbracket p \rrbracket$
in a set $\mathbb{D}$.
We call \emph{programs} or \emph{modules} the elements of $L$,
preferring \emph{module} when
the language supports
a notion of horizontal composition (see Sec.~\ref{sec:cccomp}).
We call \emph{behaviors} or \emph{specifications}
the elements of the \emph{semantic domain} $\mathbb{D}$,
preferring \emph{specification} when
the semantic domain is equipped with
a notion of refinement,
and the specification under consideration
may be refined by more specific behaviors.

[I was hoping the examples below could provide a way to illustrate
the concepts,
but now I'm not sure if it's worth the space
and reader's mental energy.
Maybe use Compcert languages instead,
two birds with one stone?]

{\color{gray} %{{{

As a running example,
we present two simple languages
whose programs define single-argument integer functions.

\begin{example}[$\kw{AlgExp}$] %{{{
We consider algebraic expressions
built out of integer constants, $+$, $\times$,
and a single variable $x$.
This language $\kw{AlgExp}$ is defined by the following grammar:
\[
  e \in \kw{AlgExp} ::= c \:|\: x \:|\: (e + e) \:|\: (e \times e) \,,
\]
where $c \in \mathbb{Z}$ is any constant,
and $x$ is a terminal symbol.
One ``program'' in this language is the following expression:
\[
  e_a := ((x \times (3 + x)) + 2)
\]
An expression $e$ in \kw{AlgExp} is assigned a meaning
$\llbracket e \rrbracket : \mathbb{Z} \rightarrow \mathbb{Z}$
as follows:
to compute $\llbracket e \rrbracket(n)$,
substitute $n$ for $x$ in $e$,
then evaluate the resulting integer expression.
For example:
\[
  \llbracket e_a \rrbracket (n) = n^2 + 3n + 2 \,.
\]
\end{example}
%}}}

\begin{example}[$\kw{RegProg}$] %{{{
Consider a machine with an infinite number of registers,
which can perform elementary algebraic operations.
The grammar of programs is:
\begin{align*}
  r \in \kw{RegName} &::= \kw{r1} \:|\: \kw{r2} \:|\: \cdots \\
  e \in \kw{RegExpr} &::= c \:|\: r \:|\: r + r \:|\: r \times r \\
  p \in \kw{RegProg} &::= r \leftarrow e; \, p \:|\: \bullet \,,
\end{align*}
where $\bullet$ denotes the empty program.
An example is:
\[
  p_a :=
  \kw{r2} \leftarrow 1; \,
  \kw{r2} \leftarrow \kw{r1} + \kw{r2}; \,
  \kw{r3} \leftarrow \kw{r2} \times \kw{r2}; \,
  \kw{r1} \leftarrow \kw{r2} + \kw{r3};
\]
Each assignment $r \leftarrow e$ evaluates the computation $e$,
then stores the result in register $r$.
To interpret programs as functions,
we initialize $\kw{r1}$ with the value of the argument,
execute the program's assignments in sequence,
then read out the answer from the new contents of $\kw{r1}$.
The reader is invited to check that
the behavior $\llbracket p_a \rrbracket$ associated to the program above
is the same as that of $e_a$.
\end{example}
%}}}

The $\kw{AlgExp}$ and $\kw{RegOps}$ languages
are sufficient to illustrate a number of interesting phenomena.
Because of their simplicity,
it will be possible to do so with some degree of formality.
Concurrently,
we will discuss in a more casual manner
the way in which these phenomena play out
in the context of the compilation of C to assembly languages.

} %}}}

%}}}

\subsection{Compilers} %{{{

Given a source language $L_s$
and a target language $L_t$,
a compiler can be understood as a function
$C : L_s \rightarrow L_t$
which transforms a program $p \in L_s$
into a program $C(p) \in L_t$.
When the two languages are interpreted into
a common semantic domain,
the correctness of the compiler can be stated as:
\[
  \llbracket p \rrbracket_s = \llbracket C(p) \rrbracket_t \,.
\]

{\color{gray} %{{{

\begin{example}[\kw{AlgExp} to \kw{RegOps}] %{{{
To illustrate this definition,
we define a simple compiler $C_a : \kw{AlgExp} \rightarrow \kw{RegOps}$.
Compiling simple expressions is straightforward:
\[
  C_a(c) := \kw{r1} \leftarrow c; \qquad
  C_a(x) := \bullet
\]
Compiling binary operations is more involved,
because we need to evaluate each operand,
making sure that the first computation does not overwrite
the input value,
and that the second computation does not overwrite
the result of the first.
To this end,
we define a \emph{shift} operator ${\uparrow} p$,
which replaces every register name in $p$ by its successor,
so that for example:
\[
  {\uparrow} p_a =
  \kw{r3} \leftarrow 1; \,
  \kw{r3} \leftarrow \kw{r2} + \kw{r3}; \,
  \kw{r4} \leftarrow \kw{r3} \times \kw{r3}; \,
  \kw{r2} \leftarrow \kw{r3} + \kw{r4};
\]
We can now define for each binary operation $* \in \{+, \times\}$:
\begin{align*}
  C(e_1 * e_2) = \quad  % XXX overloading e_1
    &\kw{r2} \leftarrow \kw{r1}; \, % XXX copy not allowed
    {\uparrow} C(e_1); \\
    &\kw{r3} \leftarrow \kw{r1}; \,
    {\uparrow\uparrow} C(e_2); \\
    &\kw{r1} \leftarrow \kw{r2} * \kw{r3};
\end{align*}
The subprogram ${\uparrow} C(e_1)$
will use $\kw{r2}$ for its input and output,
and use registers $\kw{r3}$ and above for its intermediate results,
leaving the contents of $\kw{r1}$ unchanged.
Likewise,
${\uparrow\uparrow} C(e_2)$
will operate on registers $\kw{r3}$ and above,
leaving both $\kw{r1}$ and $\kw{r2}$ unchanged.
The last instruction in the program performs
the top-level operation and stores the result
in the output register $\kw{r1}$.
\end{example}
%}}}

To formally establish the correctness of $C_a$,
we seek to prove that
$\llbracket C_a(e) \rrbracket = \llbracket e \rrbracket$
by structural induction on $e$.
It is easy enough to check that:
\[
  \llbracket \bullet \rrbracket = \llbracket x \rrbracket \qquad
  \llbracket \kw{r1} := c \rrbracket = \llbracket c \rrbracket
\]
However,
the inductive cases for $e_1 + e_2$ and $e_1 \times e_2$
are less obvious to handle.
To articulate why,
it is useful [to be overly pedantic:]

When compiling $(e_1 * e_2)$,
$C_a$ constructs a $\kw{RegProg}$ system
in terms of the simpler components $C_a(e_1)$ and $C_a(e_2)$.
As we try to understand the behavior of the resulting artefact,
the mathematical theory we use to specify and analyse
the behavior of these components,
namely the semantic domain $\mathbb{Z} \rightarrow \mathbb{Z}$,
should help us connect
the behavior of the components to
the behavior of the whole,
ultimately allowing us to prove
the conclusion $\llbracket C_a(e_1 * e_2) \rrbracket = \llbracket e_1 * e_2 \rrbracket$
from our induction hypotheses
$\llbracket C_a(e_1) \rrbracket = \llbracket e_1 \rrbracket$ and
$\llbracket C_a(e_2) \rrbracket = \llbracket e_2 \rrbracket$.
However,
our theory is not rich enough to support this process:
$\mathbb{Z} \rightarrow \mathbb{Z}$
is not the right semantic domain
to describe $\kw{RegProg}$ modules.

%This is because while the program $C(e_1 * e_2)$
%was built by stitching together more elementary components,
%we have not yet defined a corresponding notion of \emph{composition}
%at the level of our semantic domain (Sec.~\ref{sec:cccomp}).
%[Condense the following tease]
%Moreover,
%the semantic domain $\mathbb{Z} \rightarrow \mathbb{Z}$
%is not \emph{expressive} enough to account for the behavior of $\uparrow$:
%using our convention for the meaning of $\kw{RegOps}$ programs,
%$\llbracket {\uparrow}p \rrbracket$ is always the identity function!
%This is addressed in Sec.~\ref{sec:ccexpr} by defining
%a richer semantics for $\kw{RegOps}$.
%Because this richer semantics no longer matches
%the domain used to interpret the source language $\kw{AlgExp}$,
%we then need to account for the \emph{abstraction} relationship
%between the behaviors of $\kw{AlgExp}$ programs
%and the behaviors of $\kw{RegOps}$ ones (Sec.~\ref{sec:ccabs}).
%[refinement, open system whatever that means in this context].

} %}}}

%}}}

{\color{gray} %{{{

\subsection{Expressivity} %{{{

The expressivity of our theories
should be assessed
[real-world,
from the point of view of the outside.]

The first problem we encounter when we try to understand $C_a(e_1 * e_2)$
is the lack of expressivity of our semantic domain.
For instance,
$\mathbb{Z} \rightarrow \mathbb{Z}$
fails to even explain the effect of the shift operator $\uparrow$:
in fact, for any $\kw{RegProg}$ program $p$,
the program ${\uparrow}p$ leaves $\kw{r1}$ unchanged,
so that it is indistinguishable from the empty program!
Note that this problem did not appear
when defining our notion of compiler correctness.
In fact,
given a sufficiently precise semantics of $\kw{RegProg}$,
there is no doubt we could work around the problem:
bite the bullet, treat $C_a(e_1 * e_2)$ as a whole,
and prove our compiler correct.
However,
the situation illustrates an important point:
by overfitting our choice of semantics to the problem at hand,
we have failed to account for important ways in which
$\kw{RegProg}$ programs can interact with their environments
in ways that $\kw{AlgExp}$ programs cannot.
This limits the usefulness of our target semantics,
and as such that of the compiler correctness theorem
(or the induction hypotheses in this case).

A better approach would have been to
assess the expressivity of our semantics,
not in terms of formulating the problem at hand,
but in terms of the ways in which our system
could be used.
What is a $\kw{RegProg}$ machine good for?
With a different convention,
it could be used to compute function of several variables.
It could be a component in a handheld calculator,
or the control system of an airplane.

[it seems like pandora's box,
but maximal expressivity in how system communicates with its environment
+ open system = everything you want]

Likewise, C programs are used to do all kind of things,
but we don't need to know what:
only the basic interaction principles
between the C program and its environment that are involved
in those things.
Although communication model between program
and the underlying system is simple and uniform
(system calls / external function invocation),
this protocol is general enough that
when we link with the outside world,
the source/target machine models are enough to
implement all kinds of stuff:
network services, GUIs, drivers, control software,
operating systems, distributed computations, \ldots
The same compiler is used in all of these contexts.

%}}}

} %}}}

\subsection{Abstraction} %{{{

The assumption that the source and target programs
can be naturally assigned meanings in the same semantic domain
is reasonable for compiler passes
where the source and target languages are fairly similar.
It can also hold when observable behaviors are simple:
if we are only interested in the final result produced by a program,
then the corresponding notion of behavior
can be fairly language-independent.
However,
in most practical cases we are interested in
the program's interaction with its environment
as well as its ultimate outcome,
and this interaction is often understood very differently
in the context of the source and target languages.

For instance,
in the C programming language
the memory is understood in terms of independent objects.
Each object corresponds to a variable declared in the program,
or to a chunck of heap-allocated memory.
In C, a function call is performed
by allocating and initializing new objects
corresponding to the callee's arguments and local variables.
By contrast,
an assembly program
operates in a single address space:
the memory is essentially seen as a large array of bytes;
the very notion of a function call in assembly
is largely conventional as opposed to a primitive notion,
and their mechanics are understood in very different terms.
Consequently,
semantic domains that can accurately account
for module interaction will necessarily be distinct in C and assembly.

This underscore importance of \emph{abstraction}:
C compilers operate in the context of a given \emph{calling convention},
which establishes a relationship between the behaviors of C modules
and that of assembly modules.
This calling convention can be modelled as a function
$\mathbb{C} : \mathbb{D}_s \rightarrow \mathbb{D}_t$,
which is in some sense the semantic counterpart to the compiler $C$.
Our correctness criterion becomes:
\[
  \mathbb{C}(\llbracket p \rrbracket_s) =
  \llbracket C(p) \rrbracket_t
\]

[Compcert goes to great length to ensure $\mathbb{D}_s = \mathbb{D}_t$,
defining unified memory model etc.
Much compositional Compcert works keeps with this approach
but this creates problems.
In fact, even when $\mathbb{D}_s = \mathbb{D}_t$ formally,
the source and target behaviors may be distinct
and it can be important/useful to define
$\mathbb{C} : \mathbb{D} \rightarrow \mathbb{D}$.
In Sec.~\ref{sec:callconv} we show how taking abstraction seriously
solves the extcall\_args problem.]

%}}}

\subsection{Refinement} %{{{

In and of itself,
abstraction is insufficient to reflect
the relationship between the behaviors of C and assembly modules.
This is because there is more than one way to realize
a given C function call at the level of assembly.
For instance,
a typical calling convention specifies a classification of machine registers
into \emph{callee-save} registers,
which are guaranteed to be left unchanged by the function being invoked,
and \emph{caller-save} registers,
which the function being invoked may modify at will.
Two assembly functions
which modify the caller-save registers differently
may still implement the same C behavior;
however, they will be observationally distinct at the level of assembly.

To account for this situation,
the target semantic domain $\mathbb{D}_t$
should contain specifications
allowing a range of possible behaviors,
and be equipped with a notion of refinement
in the form of a transitive relation $\sqsupseteq$.
The target behavior $\mathbb{C}(\sigma_s)$
corresponding to the source behavior $\sigma_s$
can then be broad enough to state,
for instance,
that the callee-save registers
may contain any value after a function
specified in $\sigma_s$ returns.
Target programs
which leave specific values in these registers
but otherwise agree with $\mathbb{C}(\sigma_s)$
will be considered valid implementations
because their behavior will refine that specification.
Taking this into account,
the correctness statement becomes:
\[
  \mathbb{C}(\llbracket p \rrbracket_s) \sqsupseteq
  \llbracket C(p) \rrbracket_t
\]

Note that while abstraction and refinement are distinct concepts,
it can sometimes be advantageous to unify them
in the form of a single, heterogenous relation
${\sqsupseteq_\mathbb{C}} = {\sqsupseteq} \circ {\mathbb{C}}$.
[Reference popl15's abstraction relations]
[Forward reference to where we do that in this work].
[Explain that confusing the two is the root of some limitation
in existing work].

[Role of refinement/abstraction in permitting optimizations?]

%}}}

\subsection{Open systems} %{{{

Using powerset of behaviors is not good enough for refinement,
we need to take distinction between system and environment seriously.
-> this is how we define a notion of refinement in Sec.~3
that solves some of the issues

Discuss contextual refinement,
which is not enough \emph{a priori}, and \emph{practically},
because we don't want to limit ourselves to a set of systems we're gonna connect with.
But also contextual refinement might be enough
if the interaction of all the environments we would ever want to connect with
can be "coobservationally equivalent" to a context in our set
from the point of view of the program (aka oracle).

Specs need to be able to express constraints on the environment.

[Fit somewhere:]
This calls into question
the centrality of contextual refinement and contextual equivalence
in standard approaches to compositionality.
[Use game semantics and a smarter refinement instead;
you'll get contextual refinement for free
for whatever that's worth.]
[There is no completed system.
At the very least the context itself
should have facilities to communicate with the larger world
that are expressive enough.]

%}}}

\subsection{Compositionality} %{{{

[Large programs are split into compilation units,
which are compiled independently,
then linked to produce the final artefact.]

Syntactic composition
(the way we stitch together components to build a system in the real world)
should have corresponding notion
in the semantics
(the theory we use to analyse systems).

%}}}

\subsection{Resources} %{{{

[The source model is usually much more idealized than target.
Example: infinite stack vs. finite address space.]

%}}}
