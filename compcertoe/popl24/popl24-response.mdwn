## Summary

We are grateful to the reviewers for their hard work.
We have found the reviews to be extremely fair, useful and constructive,
and to be candid our proposed change list below is for the most part a summary
of the suggestions they have offered.

Below this, we address the reviewers' "official" questions, as well as some
observations and questions which appeared across multiple reviews.
Finally we provide a point-by-point response for the remaining contents of
individual reviews.

## Change list

To address the reviewer's feedback, we will make the following changes:

 1. *Fix the issues with the introduction* noted by Reviewers A and B.
    We will explain $\circ$ and $\sqsubseteq$ in §1.1,
    strive to make our points more precisely,
    and include a summary of the paper's structure
    at the end of §1.2. We will be sure to incorporate additional "signposts"
    throughout the paper and especially at the beginning of each section.

       1.a. Signposts should include a motivation for our use of lenses
            at the beginning of the paragraph l.498.

 2. *Provide definitions for relevant categorical concepts* (monoidal category,
    double category, etc) as they apply to our particular cases.
    We will make sure to provide "inference rule" style
    versions for every composition property provided by the framework,
    since our audience is more likely to be comfortable with this formulation.
 3. *Explain and illustrate our use of string diagrams* in more depth
    (see below and our response to Reviewer A).
 4. *Include more material regarding memory separation, ClightP* semantics,
    and the ClightP composition proof in the main body of the paper.
    (This will also contribute toward #3, as we used string diagrams
    extensively in working out this proof.)
 5. *Provide references for lenses and double categories, and expand the Related Work section*,
    in particular we will include a more detailed comparison of our work with
    interaction trees and with recent work on certified abstraction layers.

More generally, we have found the reviewers' observations, suggestions and
questions to be excellent, and where it makes sense, we will try to incorporate
our detailed comments below as much as possible.

## Common issues and key questions

We now address the most salient point from the reviews and
answer the questions submitted by the reviewers.

### Conceptual novelty vs. prior work

**Reviewer D** asks:
> What conceptual contributions does this work bring over the previous
> theoretical work by Koenig and Shao [LICS 2020] and Oliveira Vale et al.
> [POPL 2022]? For instance, are the layered composition operator or any of the
> spatial composition operators new to the current submission?

First, let's spell out the commonalities between these two papers
and our submission:

  * All of them propose a model of Certified Abstraction Layers,
    among other contributions.
  * In all of them, a type of the form $A \rightarrow B$ is used for
    a component which accepts incoming calls in $B$ and performs
    outgoing calls in $A$, and all use a composition of the form $g \odot f$
    which lets $f$ and $g$ interact by having the outgoing calls of $g$
    handled as incoming calls of $f$.
    This convention is very commonly used in game semantics.
    In that sense the layer composition
    operator is not new to the current submission.

However, both these papers differ from our submission in the following ways:

  * They use trace-based semantics, whereas we are repurposing the
    transition systems of CompCertO.
  * They are pen-and-paper models only whereas our work has been mechanized in
    the Coq proof assistant.
  * The model in our submission supports (an extended version of) CompCertO's
    simulation conventions, whereas each of these two papers
    have their own mechanisms for data abstraction. These mechanisms only apply to
    component states, but not to the form of function calls and returns
    (as defined by effect signatures $\simeq$ language interfaces):

      + in the POPL paper, the specification model supports encapsulated state,
        and as such includes representation indepdence facilities.
      + in the LICS paper, a relation $R \subseteq U \times V$ can be used to
        induce a formal adjunction of type
        $A \mathbin@ U \rightleftarrows A \mathbin@ V$
        but there are is no way to express relationships between the
        different effect signatures (language interfaces) $A$ and $B$

On that last point, the $\mathbin@$ construction used in the LICS paper
is only a very restricted version of our spatial composition operator.
It consists only of a unary functor ${-} \mathbin@ U$ operating in the context
of a fixed set $U$, similarly to the special case we describe on ll. 480--490
to introduce our own version. The ambition is only simply to transparently
"pass through" the state used in an underlay interface, and perhaps transform
it through simple relational abstraction as described above
(through that happens through a construction distinct from $\mathbin@$).

However, in our case the construction extends to full-blown, binary spatial
composition operator, which can act on every kind of object listed in Table 1
(subject to the restriction that language interfaces and transition systems
can only appear on the left whereas for interfaces and behaviors, the
right-hand side must consist of sets and lenses).

### The role of category theory

Several reviewers express understandable skepticism regarding the use of
category theory and string diagrams in presenting the work, especially since
the we do not rely on any very advanced category theory results.
Our rationale for choosing this approach is the following.

Category theory was a crucial structural tool in investigating and developing
the framework presented in the paper. Whenever we would figure out how to
incorporate a new aspect, we would use a categorical lens to help us elucidate the underlying
structures and put them in a form which would provide a solid foundation for
further work. For example:

  * Very little of the work would have worked without first replacing CompCertO's
    $\oplus$ composition with the layered composition operator $\odot$
    as the main form of horizontal composition, which is
    better-behaved and in our estimation is more fundamental.

  * Analyzing the construction $A \mathbin@ U$ found in Koenig & Shao [2020]
    with a higher-categorical perspective is what allowed us to perform the
    generalization we have described above, 
    and prompted us to introduce lenses into our framework
    in order to make this possible.

We believe from this experience that, given the overall complexity of the
framework, making the underlying organizing principles explicit is important
to help the reader grasp the ways in which the many ingredients listed in
Table 1 fit with one another. At the same time, we wanted to do this in a way
that did not assume the reader was already familiar with higher or double
category theory (but that would still mention them for the benefit
of the readers who were).

This is admittedly a tight rope to walk, in part because of the "double bind"
noted by Reviewer A, and we acknowledge that despite our efforts,
the paper remains difficult and obscure in places.
However, the reviewers' input lead us to believe that we did get some
of the way there, and we are optimistic that by taking into account
their observations and advice we would be able to walk it in a revised version.

### Use of string diagrams

On a related note, the reviewers also express uncertainty as to the usefulness
of string diagrams, and whether introducing them brings benefits in excess of
their complexity and unfamiliarity.

**Reviewer B** asks:
> In your experience, do you believe that string diagrams in the context of
> realistic refinement proofs as presented here can be a useful tool to the
> practitioner, or are they merely an interesting oddity?

There again, we included string diagrams because we found them to be necessary
in carrying out the work. The three-dimensional diagrams in particular, although
they are complex, are an incredible resource when constructing refinement
proofs which involve all three composition principles in intertwined ways.
As an example, we do not believe we could have written (or frankly, could read
back) the proof term given at the end of §3.4 (l.652) without using 3D diagrams,
at least as a mental visualization tool for the underlying structure.

In fact, the mechanics of the 3D diagrams essentially capture the entirety of the
framework's compositional structure and its associated rules and equivalences.
Figuring out how to
draw them and how they worked was a watershed moment in wrapping our own minds
around that compositional structure, and we would like to provide the same
level of insight to the reader.

At the same time, we acknowledge that while Example 3.9 gives a taste of the
mechanics of such refinement cubes, the paper currently does a poor job of
explaining how they work, and that this would need to be addressed in a final
version (as a starting point we provide some additional illustration and
rationale for their use in our answer to Reviewer A).
On the other hand, 2D string diagrams for simulation proofs
(as opposed to those which denote transition systems and simulation conventions)
could be deemphasized --- while they were intended as a stepping stone,
it seems the reviewers did not get much out of them.

### Representation Independence

**Reviewer A** asks:
> Please explain how the "fundamental property" results in representation
> independence in terms of program equivalences.

Suppose we have two components
$f_1, f_2 : A \twoheadrightarrow B$.
The first is defined using an internal state of type $U$
as $f_1 := [ u \rangle \odot L_1$,
where $u \in U$ is the initial state
and $L_1 : A \twoheadrightarrow B \mathbin@ U$
describes the behavior of each activation
in terms of this internal state.
Likewise $f_2 := [ v \rangle \odot L_2$ with
$v \in V$ and
$L_2 : A \twoheadrightarrow B \mathbin@ V$.
Components of this kind may result, for example,
from interpreting two ClightP program
which use different sets of private variables
to store their internal state.

To show that $f_1, f_2$ have the same externally observable behavior,
we can exhibit a relation $R \subseteq U \times V$
such that:

  1. $\zeta : u \mathbin{R} v$ holds for initial states;
  2. If $L_1$ and $L_2$ are invoked with related states,
     they will exhibit the same behavior and
     their updated states will again be related by $R$.

The latter can be expressed by the properties
$\phi : L_1 \le_{A \twoheadrightarrow B \mathbin@ R} L_2$ and
$\phi' : L_2 \le_{A \twoheadrightarrow B \mathbin@ R^\mathsf{op}} L_1$.
From there we can pre-compose the property shown on l.710
to derive the mutual refinements
$[\zeta \rangle \odot \phi : f_1 \le f_2$ and
$[\zeta^\mathsf{op} \rangle \cdot \phi' : f_2 \le f_1$.

This shows $f_1$ and $f_2$ are essentially interchangeable
for the purposes of our framework.
One concrete instance of this could consist of
components $f_1, f_2$ obtained as the semantics of two ClightP programs,
where the relation $R$ would relate the environments storing the values
for their private variables.

### Unexplained conventions

As noted by **Reviewer A**,
in several places in the paper we use
the unexplained notation $L_1 \le L_2$
to mean $L_1 \le_{\mathsf{id}_A \twoheadrightarrow \mathsf{id}_B} L_2$,
ie. a simulation property where both conventions are identities,
since in that case simulation properties reduces to a more traditional
preorder among objects of type $L_1, L_2 : A \twoheadrightarrow B$.
This is similar in spirit to the relation $R \sqsubseteq S$ defined for
simulation conventions
as $\mathsf{id}_A \le_{R \twoheadrightarrow S} \mathsf{id}_B$ on l.936.

We make use of this convention in the following.
We will make sure it is properly introduced in the paper before its first use.

### Conclusion

We believe this addresses the most salient points raised by the reviewers,
however below we also provide point-by-point responses to each review.
For the sake of transparency we have kept the full text of each one,
even when we did not directly respond to a particular observation or comment.

## Review #357A

> Summary of the paper
> --------------------
> The paper presents compositional extension of the CompCert certified compiler which supports state encapsulation.
> The framework is presented in a generalized setting of double categories which allow concise representation of high-level correctness proofs of refinement underlying correct compilation.
> 
> Assessment of the paper
> -----------------------
> The core contributions of the paper, in my opinion, i.e., enabling better compositionality of refinement proofs of correct compilation and preserving state encapsulation, are important and interesting subjects to study, particularly in the context of the already very successful the CompCert compiler.
> However, the paper focuses mostly on presenting double categories and constructions in that settings instead of focusing on the aforementioned core contributions.

> I believe that this paper would have been much better if it had focused on presenting the ideas at a more concrete level, e.g., discussing in detail how separation of memory and data encapsulation work in the concrete settings of CompCert, and then afterwards, discussed how these ideas can be abstracted and generalized in the more general settings of category theory.
> (I could imagine that I would argue for accepting such a paper.)
> I believe most of the theory presented in this paper is not very helpful for those who do not know (double) category theory.
> On the other hand, those who know will find most of it unsurprising.

We acknowledge this is a potential issue.
We hope that our discussion above
can provide some context as to our reasoning, and that our proposed changes
could address this tension to some extent.

> Also, I found string diagrams not very helpful for my understanding in this paper.
> (I appreciate and understand that these beautiful diagrams must have taken a lot of time and effort to draw.) 
> String diagrams for monoidal categories, or double categories, are often useful not just because they pictorially show the relation between objects and morphisms, they are most helpful in simplifying proofs of equations by turning them into simple manipulations of the string diagrams.
> This is not the case here, as we are never interested in showing equivalence/equality of refinement proofs themselves.

This is true for string diagrams which denote refinement proofs,
but not for those which denote
transition systems or simulation conventions,
including the constituent diagrams which form the faces of
our refinement cubes.

For example,
considering transition systems of a given type
under simple refinement $\le$,
we could reason in the traditional way
by writing refinement sequences such as:

$L = [\text{diagram 1}] \le \cdots \le [\text{diagram n}] \le L' \qquad (1)$

As usual,
the diagrams would capture geometrically the identities
arising from the categorical structure,
and the congruence properties of $\le$ would allow us to
apply local refinements.
A similar story holds for simulation conventions of a given type
under the relation $\sqsubseteq$ defined on l.936.
However,
when both kinds of refinements are intertwined
or when the refinement properties involve both non-trivial
transition systems and refinement conventions,
this approach is no longer sufficient,
and this is where our 3-dimensional diagrams come in.

In the context of our 3D refinement cubes,
a refinement of the form $L_1 \le L_2$
corresponds to a cube where only
the top ($L_1$) and bottom ($L_2$) faces
have non-trivial contents.
A refinement sequence such as (1)
corresponds to stacking such cubes together vertically,
where [diagram 1] ... [diagram n] would be the
contents of the top, bottom, and intermediate horizontal faces.
Likewise,
a refinement sequence
$\textbf{R} = [\text{diagram 1}]
 \sqsubseteq \cdots \sqsubseteq
 [\text{diagram n}] = \mathbf{S}$
would correspond to stacking cubes sideways,
with the diagrams 1..n occupying the
left, right and intermediate faces.

But as illustrated by Example 3.9,
our framework also makes it possible
to go beyond this kind of equational reasoning
and to use refinement cubes where all four faces are non-trivial,
composing them in the three possible directions.
As before,
it is possible in some situations to "paste a cube"
to only a subsection of another's face,
and intuitive topological deformations
correspond to the transformations afforded by the categorical structure.

> (I write the above as a person who is very comfortable with category theory but my research does not directly involve category theory.)
> 
> Detailed comments for authors
> -----------------------------
> The Introduction, especially 1.1, is extremely vague at points.
> For instance, mathematical-like notation, e.g., $\circ, \sqsubseteq$ is used without any explanation.

We acknowledge this should be improved and will address it per #1.

> In some cases, a symbol/concept is used but then defined later, e.g., on line 109 $\le$ is used but it is only defined on line 120.
> 
> On line 423: there are missing subscripts on $\le$. Also, on line 943.

Thank you for pointing out this oversight.
We hope "**Unexplained conventions**" above clarifies this
and we will be sure to address it in the paper.

> Remark 3.2: This remark comes a bit too late as this convention seems to be already used before.

Thank you for pointing this out, indeed l.413 has an instance of this
convention being used before the remark explains it.
We will triple-check the rest of the paper and address this either by using
"id" everywhere up to that point, or by moving up Remark 3.2.

> Related to this, it might be helpful to have a version of Table 1, at this point and explain how composition operations are lifted to higher dimensions.

Thank you, we will consider this carefully and do our best to accomplish this.

> On line 664 it is explained that "... memory operations ensure that CompCert semantics satisfy a frame property, meaning that they are insensitive to additional memory."
> This might be true for Clight semantics but it does not hold for Assembly, does it?

We believe this should be true for CompCertO's Asm language as well,
as it is closely related to the parametricity property established in
Theorem 4.3 of the CompCertO paper (and proved in `x86/Asmrel.v`).
But we have not proved it.

> As also mentioned in the paper, encapsulated state is often shown through representation independence.
> Representation independence is often formulated as equivalence of programs (with different internal states).
> Does the "fundamental property" referred to on line 707 result in such program equivalences?
> This is not discussed in the paper.

We hope our answer above can shed some light and we will incorporate it into any
revision. Perhaps "fundamental property" is not the best name and we will find
a more descriptive one ("hidden-state refinement property" or something such).

> On line 986, the wrong arrow is used for lens $f$.

Thank you for pointing this out, we will fix it.

> The language ClightP is only mentioned towards the end of the paper.
> ClightP seems to be an interesting result which deserves more attention and a presentation in more detail.

We agree with this assessment.
Per #4 we hope to use some extra space to discuss ClightP in more
detail, including some of the material touched on in Appendix C. The ClightP
composition proof is also an additional example of a property which would have
been difficult for us to prove and wrap our head around without the use of
string diagrams and we hope to use it to further demonstrate their mechanics.

> In the "related and future work" section, interaction trees are only mentioned in passing: "Interaction trees [...] provide another framework for compositional semantics formalized in the Coq proof assistant which presents similarities with our own."
> This is not really a comparison.
> Please expand on this.

We will provide a more detailed comparison, as we did to address Reviewer D's
question above.

A short answer is that interaction trees model computations
which in some sense have a similar shape to our own, and like our own design
they successfully use categorical ideas to structure their framework.
However unlike our work, they are
geared towards computable processes, and as a result embedding CompCertO semantics
(defined using relations in $\mathsf{Prop}$) would be more difficult.
This is probably even more true when it comes to the abstraction facilities provided by
CompCertO's simulation conventions, which we believe would be difficult to
adapt to the setting of ITrees.

> Questions to be addressed by author response
> --------------------------------------------
> - Please explain how the "fundamental property" results in representation independence in terms of program equivalences.

(Please see our answer in the common section above.)

## Review #357B

> Summary of the paper
> --------------------
> A long span of work has sought to improve the simulation techniques used in certified compilation.
> In particular, compositionality---vertical to chain proofs of refinements, and horizontal to link
> open components---  has been the subject of significant attention during the last decade.
> 
> In this work, the authors builds upon one of the main state of the art, CompCertO, and argue for improving
> its proof techniques in two dimensions. First, by generalizing the notion of horizontal composition:
> in CompCertO as hinted at in the orginal CompCertO paper (Sec. 3.5), all layers had to agree on a single
> common language interface, a fundamentally close world hypothesis;
> the authors generalize it to compose over compatible language interfaces.
> Second by generalizing the treatment of state, introducing a notion of spatial composition. This novel notion enables
> both a clean composition of components specified with respect to distinct abstract states, as well as to support
> state encapsulation.
> 
> On the concrete side, the authors have implemented the new structures as an extension to CompCertO,
> and illustrated its use to prove correct their ring buffer running example, to illustrate the definition
> of a language supporting private variables, and to provide a very clean reconstruction of the Certified
> Abstraction Layer methodology from [Gu et al].
> 
> On the abstract side, the authors investigate and describe this work under a very categorical lens, giving
> a quite unusual presentation to the structures involved, shedding an original light on existing work,
> its short comings, and the rationals for their contributions.
> 
> Assessment of the paper
> -----------------------
> **Pros**
> * The running example is an unvaluable lifeline: it crucially illustrates most concepts introduced all along the paper.
> * The categorical perspective provides interesting novel insights to the question at hand. I am not yet convinced that
>   the string diagrams brings much value and clarity in practical proofs, but it is certainly an interesting take,
>   worth experimenting with.
> * The contributions are significant. The layered composition is a relatively expected extension, but a very clean one.
>   The further spatial composition is impressive. In particular, results such as theorems 3.7 are very elegant.
> * Although some aspects of the presentation of the paper are quite difficult, a lot of work and care has visibly be put
>   in the writing. I have found close to no typo, the running example is well chosen, the typesetting and pictures quite
>   beautiful.
> 
> **Cons**
> * While very interesting, I have not found this to be an easy paper. I believe that I can consider myself as an expert
>   and in the core target of this work, and have still struggled significantly to cover it all. I believe that two main
>   shortcomings makes the paper less accessible than it could be.
>   1. First, during my first read, I have often found myself lost as to what was the overall structure and point of the technical material I was currently parsing.
>   I would recommend providing in the introduction, after the contributions, a quite detailed explanation of the structure of the paper, section by section.
>   Similarly, headers of each section are very short and dry. I would recommend expanding on them to hammer clearly the narrative into the reader mind, before asking
>   of them to parse heavy technical material.

Thank you for pointing this out.
We acknowledge the paper would benefit significantly from improved "signposting",
and we will work towards that end per change #1.

>   2. Second, the authors have made overall a great effort to introduce cleanly most concepts. I find it unfortunate to assume just a little bit too much category theory
>   from the reader. I suspect that simply including definition of a monoidal category first, and then later of a double category would withhold a few more readers. But
>   more importantly, laying plainly and explicitly the instances at play would really help. For instance, with my modest categorical background, it is not plain obvious
>   to me when we reach l246 what is the bifunctor considered in the monoidal structure. Even more so, having not worked with double categories before, having completely
>   spelled out who's who in section 5 at least (if not already around l384) would have helped me I believe

Thank you for this feedback. We hope change #2 will be helpful towards that end.

>   3. 5.2 and 5.3 are significantly harder than the remaining of the paper with a light categorical background. It is deep enough in the paper to be acceptable though.

We acknowledge this and would do our best to use any extra space to improve
these sections in the final version.

> * The related work, and in general citations, are quite insufficient! The authors make heavy use of lenses, but do not cite a single work about them for instance!
>   In the related work, some comparisons are quite devoid of content (Interaction Trees notably).

This is true. Please see the common part for a more in-depth comparison with prior CAL work,
and the end of our answer to Reviewer A for a brief comparison with ITrees.
Per change #5 we would polish and incorporate those in the Related Work section
of our final version.

> * Part of me wonders if there should have been two papers, one presenting plainly the concrete constructions to the layered composition operator and the spatial composition,
>   and one presenting the view of the problem under the categorical lense, and advocating for string diagrams as a useful representation for these proofs.

Thank you for sharing this sentiment; we hope our discussion above
can shed light on why we did not want to separate these two aspects of the work.

> Despite the presentation issues that I believe this paper suffers from, the
> strength and the novelty of its contributions lead me to support its acceptance.
> 
> Detailed comments for authors
> -----------------------------
> # Comments
> 
> I am still hesitant as to whether the 2D diagrams really help, but, as beautiful as they are, the 3D are really a bit much :)
> 
> - l70: "the well-known structure of a double category" -> A reference should be provided, and I would recommend to remove the term "well-known" to cater to your "ignorant" readers such as myself.

Yes, our apologies for this oversight and faux pas;
we will provide a textbook reference per change #5.

> - l97: are -> is
> - Paragraph Simulations (l107). This brushed me slightly the wrong way. I am sure the authors are well aware, but it is full of imprecision, some covered with the footnote, but some not.
>   Most importantly, the correctness theorem of CompCert is NOT the one given! It is a backward simulation, and relies fundamentally on determinism to reduce the problem to a forward. This should
>   be explicitly acknowledge. The second bullet is very imprecise: (1) the source typically challenges with a single step, not with ->star, (2) permitting simply an answer by ->star would be unsound, 
>   a measure is necessary to prevent infinite stuttering. In the third bullet, s2 can still step silently to reach F.

Yes! You are right that this is incorrect. We will find a way for the paper to remain truthful
while still avoiding as much complexity as possible in our exposition.

> - l176: transition systemS
> - l246: I have found this too abrupt. It would help the reader to define at least briefly what is a monoidal category, and to spell out the instance at play (you explicit the morphisms, but not the
>   bifunctor)

Thank you, we will address those.

> - l292: It would have been interesting to see the definition of Am, although you do not use it later.

It is not very complex so we will include it.
Reviewer C also points out that the paper at this stage
provides few details about simulation conventions,
so we may want to use this opportunity to discuss the
simulation convention
$\mathbb{C} : \mathcal{C}_\mathsf{m} \leftrightarrow \mathcal{A}_\mathsf{m}$
use in CompCertO's correctness theorem
to help the reader build some intuition at this point.

> - l303: spelling out how to read the square would help the reader I beleive.

We will explain how source- and target-level function calls propagate through
the square and could use the convention $\mathbb{C}$ as an example here as well.

> - l380: in contrast to the translation unit linking, the layered composition operator is completely asymmetric. It is sensible, but may warrant a comment.

We will try to add something to that effect in the paragraph 372--374.

> - l383: Again, I would have liked a definition if possible, and more importantly a spelling out of the instance.

Yes, we will address this per #2.

> - l454: what is * in "*@qv"?

It is meant to denote the unit value returned by `void enq(int v)`.
This convention is used elsewhere and we will be sure to spell it out.

> - l498: please cite at least one paper on lenses.
> - l631: impressive!
> - l707: Notations are piling up at this point, some textual help in reading the fundamental property would have been welcome

We will incorporate some version of the explanation we wrote
in response to Reviewer A's question.

> - l764: please spell out in more details the content of the section
> - l772: please define ι1/ι2! It took me some time to understand that not only did you mean by that the injections, but that you cast them implicitly into the relation {(a, ι1(a)) | a € Ao}!

Thank you for pointing this out, we will address it!

> - l775: an call -> a call
> - l794: what is simple about two abstract transition systems?

We meant as simple the *kind* of transition systems they are,
by comparison with say Def. 2.3, but we will clarify.

> - l924: what is a "thin" double category?

It means the 2-cells (refinement proofs) of a given type are all equal (proof irrelevant).
We will incorporate this as we spell out categorical definitions (#2).

> - l958: "well-known": unnecessary, and please add a citation

Yes, thank you! We will per #5.

> - l994: "as captured in the string diagram notations:" -> Am I confused or are these precisely not string diagram notations?

We meant that the properties listed here
*enable* the soundness of
the topological transformations which string diagrams permit.
But this sentence is indeed confusing and we will rephrase it.

> Questions to be addressed by author response
> --------------------------------------------
> - In your experience, do you believe that string diagrams in the context of realistic refinement proofs as presented here can be a useful tool to the practitioner, or are they merely an interesting oddity?

(See our answer in the common part above.)

## Review #357C

> Summary of the paper
> --------------------
> This paper presents a semantic framework for compositional verification, extending the existing such framework CompCertO, to support state encapsulation. In addition, the authors uncover the high-level categorical structures over (the extended version of) CompCertO.
> 
> From a technical standpoint, the authors introduce a more flexible horizontal linking operator which they call "layered composition" and "spatial composition", a method for composing a program's state which also forms the basis for state encapsulation.
> 
> Assessment of the paper
> -----------------------
> Strengths
> ----------
> - A double category structure showcases a nice, multi-dimensional compositionality with a potential for genericity.
> - State encapsulation is indeed challenging to do compositionally.
> - The spatial composition is powerful and certainly one of the highlights of the paper.
> - Few but convincing examples.
> 
> Weaknesses
> -----------
> - Relatively modest advances compared to CompCertO.
> - Sole focus on compositionality and reliance to manual correctness proofs for individual blocks.
> - So far the main application is restricted to CompCert and there are no arguments that promote the presentation of compositionality in terms of double categories and bifunctors from simply a local "observation" to something all-encompassing. The authors go on to say that that they believe that they have uncovered "an elegant conceptual framework with applications beyond the present work", but currently that is hard to justify.
> - Concerns regarding the categorical developments and overall readability (see below for more details).
> - Lack of insight on the proofs in the main paper; beyond that, the proofs are only accessible if the reader has proficiency in Coq.
> 
> Various comments
> --------
> 
> A big question mark for me is what the language of category theory really brought to the table.  Is it just that things are "less ad-hoc", as the authors state, and more systematic? That is nice, but I would love to see more tangible advantages in terms of making the task of verification faster and more efficient; for example, in Turi and Plotkin's categorical framework for operational semantics [1], one gets compositionality proofs for free as a consequence of naturality.

We hope our discussion above provided elements of an answer.
To sum up, the categorical structures provide an organizing principle
to understand and manage the interactions between 3x dimensions of compositionality
acting on 7x different kinds of objects! (cf Table 1).

> There is a substantial notational overhead that, in combination with the overhead associated to category theory, makes reading this dense paper a challenge. I feel like by 5.2 the complexity has grown to very high levels, which is reflected in the section's result. Presenting spatial composition as a double bifunctor between TSC and LSC (the latter being largely a mathematical artifact?) has buried the useful properties of spatial composition under a sea of definitions that have to be unfolded. Moreover, there is no effort to help the reader in that regard whatsoever.

We acknowledge this is an issue and will do our best to address this.

> 
> But I do not want to be too harsh at this point. The authors have overall presented a good, promising and yet uneven work and I hope that in time they answer my concerns.
> 
> [1] Towards a Mathematical Operational Semantics
> 
> Detailed comments for authors
> -----------------------------
> - Lots of structures in section 2 are not introduced, for example simulation conventions and composition of simulation conventions. 

Giving a very precise definition of simulation convention at this stage
is a little tricky, especially because unlike transition systems, the
definition of simulation convention we use later in the paper is changed
compared with CompCertO.

However, one thing we could do here
is show the language interface $\mathcal{A}_\mathsf{m}$ (per B's request)
as well as $\mathcal{C}_\mathsf{m}$ and give at least a high-level description of
the simulation convention
$\mathbb{C} : \mathcal{C}_\mathsf{m} \leftrightarrow \mathcal{A}_\mathsf{m}$
which is used to establish CompCertO's correctness theorem.

This will fall short of giving a definition of simulation convention
but would equip the reader with more intuition about them than
the current text accomplishes.

> - l. 175: contain -> contains.

Thank you!

> - l. 279: Is B a language interface?

Yes! We will phrase this as:
a transition system $L : A \twoheadrightarrow B$ for the language interfaces $A, B$ is ...

> - l. 383: It is unfortunate that no details of the double category are provided at this point.

Yes! Per change #2 we will insert a definition here.

> - l.500: What exactly is a lense? Could you provide a reference? 
> - The role of the lenses in the big picture is not explained until about 400 lines forward.

Yes, we will give a reference (#5), and per #1a we will also describe our
motivation in introducing lenses at the beginning of this paragraph.

> - 3.3 : The fact that two different concepts can be used for the same thing is frightening and I did not manage to grasp how this is true. Also, at this point the reader has no idea what a simulation convention is and will not have until l. 834. 

Using the relational language of §4.2,
think of a simulation square
$f \mathbin{[R \rightarrow S]} g$
involving the sets and functions
$f : A_1 \rightarrow B_1$,
$g : A_2 \rightarrow B_2$, and the relations
$R \subseteq A_1 \times A_2$,
$S \subseteq B_1 \times B_2$.
In general,
relations cannot play the role of functions,
but given a function we can take its graph
to obtain a relation of a similar type.
In our case this means the property can be state equivalently as:

$f \mathbin{R \rightarrow S} g \quad \Leftrightarrow \quad
 \mathsf{id} \mathbin{R \rightarrow S \circ \mathsf{graph}(f)} g$

that is to say, we slid $f$ to sit vertically as a relation above $S$
in the simulation square.

This is one example of conjoint/companion relationships,
and these notions allow us to do something similar with
(some) transition systems or lenses, and (some) simulation conventions.

> - l.589 (Table 1): SC, TSC and Lens have not been introduced. 
> - l.968: If Lens^op is that well-known, then surely you can refer out-of-the-loop readers to a textbook.

This is a good point.
We will add references for lenses (#5),
introduce their categorical structure in the paragraph l.500,
and add forward reference in the table's caption
to where SC and TSC will be defined later in the paper.

> - l. 1077: What is \vdash? Is it notation for the pair of transition systems?

This notation is just meant to convey that $\Gamma$ is a parameter of a certain type.
It can be read as an entailment: if $\Gamma$ has type such-and-such, then
$\mathsf{Clight}_\Gamma[M]$ will be defined and have the same type.

> - 6.2: Where are the semantics of ClightP?

They are a modified version of the Clight semantics
and can be found in the Coq artifact. However,
per change #4 we will incorporate more details
into the paper.

## Review #357D

> Summary of the paper
> --------------------
> This paper addresses the compositionality problem of verified compilation, by
> building a more general algebra of composition operations on top of
> CompCertO. To do so, the paper introduces a layered composition operation, which
> generalizes CompCertO's semantic linking and allows for composing components
> with different language interfaces. It then generalizes CompCertO's language
> interfaces to allow the use of state with data abstraction and state
> encapsulation (framing). The authors observe that the new structures they define
> form a thin double category.
> 
> This is implemented in the Coq proof assistant as an extension to CompCertO.
> The authors discuss two main applications: a theory of certified abstraction
> layers similar to the one used in CompCertX; and a variant of CompCert's Clight
> language supporting encapsulated component state. These pieces are tried out on
> a simple running example of a bounded queue implemented using a ring buffer,
> apparently taken from previous work [Koenig and Shao, LICS 2020].
> 
> Assessment of the paper
> -----------------------
> ## Positive
> 
> + The paper addresses a real practical need for more compositional semantics in
>   verification and certified compilation.
> 
> + The proposed compositional semantic framework seems general, elegant, and
>   practically useful. In particular, the paper generalizes CompCertO with the
>   ability to compose languages with different language interfaces. It also adds
>   data abstraction and state encapsulation to CompCertO using a family of
>   spatial composition combinators working at various levels (language
>   interfaces, transition systems, simulations).
> 
> + The proposed framework was used to simplify and put on stronger foundations
>   the theory of certified abstraction layers from CompCertX. In a sequential
>   setting (so without concurrency) the proposed extension of CompCertO seems
>   in fact like a good replacement for CompCertX?
> 
> + This was all implemented in Coq as an extension of CompCertO and was provided
>   as a supplementary material. I was able to build this Coq development and it
>   seems to match the claims of the paper. The development seems elegant and
>   relatively small, but still seems a nontrivial amount of work.
> 
> + The paper is reasonably accessible even for someone who knows little about
>   category theory. In particular the use of the simple but concrete running
>   example in Sections 2 and 3 helps a lot, and the introduced concepts are well
>   motivated by this example, at least until right after Example 3.4 on pg 11.
> 
> ## Negative
> 
> - It is unclear from the submission whether it brings significant conceptual
>   contributions over a previous theoretical work by Koenig and Shao [LICS 2020]
>   and maybe also more recent work by Oliveira Vale et al. [POPL 2022]. While
>   there is definitely value in mechanizing previous theoretical ideas in Coq and
>   bringing them to CompCert, the paper should be clearer about the relation to
>   such previous work and more explicit about any new conceptual contributions.
>   For instance, is the layered composition operator new to the current work?
>   And is any of the spatial composition operators new?
> 
> - The simple running example of Sections 2 and 3 is definitely nice for
>   exposition purposes, but it would be even better to also apply the framework
>   of this paper for verifying larger and/or more interesting programs.
> 
> - While until Example 3.4 the paper used the running example very nicely to
>   motivate upfront the need for the introduced abstract concepts, starting with
>   the lenses on page 11 the new concepts are introduced without any motivation
>   and the running example is only used after the fact. This makes pages 11-16
>   harder to follow for someone motivated more by practical applications than by
>   the beauty of category theory. More generally, it would be good if the paper
>   would more often practically motivate upfront the need for abstract category
>   theory concepts.
> 
> ## Score
> 
> I'm generally positive about this work, but I'm not knowledgeable about
> category theory or the previous theoretical work this paper uses. For now I went
> with B, but my final score will also depend on how the rebuttal clarifies the
> relation with the previous theoretical work of Koenig and Shao [LICS 2020] and
> Oliveira Vale et al. [POPL 2022], and more generally whether the current
> submission brings new conceptual contributions with respect to previous work.
> 
> Detailed comments for authors
> -----------------------------
> ## New conceptual contributions over prior work
> 
> To add to my first negative point above, even in the places mentioning the
> previous work on which the current work builds it is still unclear what the
> precise connection is:
> - The very beginning of section 3.2 mentions that the `A @ U` construction is
>   Following Koenig and Shao [2020], but then it's unclear what else in this
>   section is taken from such prior work vs what is new. For instance on line 476
>   the paper mentions "we turn @ into a proper composition principle by
>   establishing its action on transition systems, simulation conventions and
>   simulations", but it's unclear whether this was already proposed in prior work.
> - Section 7 mentions this: "There exist more recent and abstract treatments of
>   CAL which, like our work, attempt to streamline the theory underlying the CAL
>   framework [Oliveira Vale et al. 2022]. In particular a version of the @
>   construction appears in Koenig and Shao [2020]. However this work has not been
>   mechanized or interfaced with CompCert." This text is very low on details and
>   it could be interpreted as this work being just a Coq formalization of
>   existing theoretical work. Also the reference to the "@ construction" is
>   imprecise, since there are 4 different "@" constructors in Section 3 (one for
>   each layer). Were they all already introduced in previous work?
> - The first line of Section 4 promises to start "with our extension of
>   CompCertO’s model", but then Section 4.2 talks about Kripke Relators as if
>   they were taken directly from CompCertO. So maybe the first line of Section 4
>   sets the wrong expectations?
> 
> ## Explaining category theory to outsiders
> 
> It would be great if the paper could explain what one gains in practice from
> viewing transition systems as a double category. For instance could you reuse
> any standard theorems from that area?
> 
> Then, while drawing 2-dimensional string diagrams seems nice and intuitive even
> for non-category theorists, that seems less the case for 3-dimensional diagrams,
> which seem much harder to understand intuitively or even to draw precisely. So
> what is the practical gain of seeing these objects as 3-dimensional structures?
> 
> Section 5 is not at all understandable for someone without knowledge about
> category theory ("horizontal part of LSC", "well-know category", "full
> subcategory", "double bifunctor"), but maybe that's okay.
> 
> ## Relation to CompCertX
> 
> Did I understand correctly that this paper has re-implemented a version of
> CompCertX on top of the current framework, and for sequential programs that's
> good enough to replace CompCertX?
> 
> ## ClightP component model details
> 
> The component model of ClightP could be explained in a bit more detail. For
> instance can components pass pointers to their private state around, and if so
> does that make that state accessible to other components?
> 
> Then I'm not so sure whether simply erasing the private declarations from
> variables when compiling ClightP to Clight will be a good idea going forward. If
> one wanted to link with verified ASM code then these annotations will maybe need
> to be preserved during compilation?
> 
> ## Smaller comments
> 
> - If the paper is accepted the authors will probably get a bit more space to
>   address reviewer comments, and that's great because the paper was a bit too
>   compressed, starting with the intro. It would be great if the intro and
>   related work could more clearly identify what the new conceptual contributions
>   are compared to previous work. Then in Section 3, it would be great to give
>   more upfront practical motivation for the introduced concepts. In general, it
>   would be good to add more intuitive explanations, not more technical details.
> 
> - The abstract apparently already introduces on ln 15 the concepts numbered
>   1.1.1, 1.1.2, 1.1.3 in the intro, but under different names? If that's the
>   case it would be good for the flow to refer to these things by the same name.
>   Also 1.1.4 Certified Compilation is not at all mentioned in the abstract,
>   which seems like a loss.
> 
> - Fig 1. The running example seems taken verbatim from Koenig and Shao [LICS
>   2020], so a citation seems needed.
> 
> - Refinement ⊆ symbol is in the wrong direction compared to standard notations.
>   The authors use A ⊆ B to mean "B refines A", instead of the opposite. This is
>   understandable in the context of CompCertO where refinement is proved with
>   forward simulations ("B refines A" is proved by showing that there is a
>   forward simulation from A to B, A ≤ B), but it would be helpful to use
>   standard notations, and mention (just like in the original CompCertO paper)
>   that forward simulations are used in the context of CompCert to prove
>   refinements.
> 
> - In Example 3.4 the subscripts on simulations are suddenly gone, but no
>   explanation is given for that.
> 
> - When Example 3.5 I didn't even expect Example 3.4 didn't already solve the
>   problem and what was left to solve. In fact it came as a surprise to me that
>   the whole rest of section 3 is needed just to finish this example. I think
>   this could be explained in a more upfront way, which would also help motivate
>   the introduction of the new concepts like lenses and so on.
> 
> - I generally found it confusing that there are 4 different "@" operators at
>   different levels but denoted in exactly the same way. Some of them are in fact
>   very different: If I understood right @ on language interfaces seems to
>   abstractly model internal state and thus works very differently than @ on
>   transition systems which model external state added by a form of framing.
> 
> - Quite often the figures are not referenced from the text, which is a big
>   loss. For instance the "Geometric Analogy" of ln 133-143 makes more sense when
>   looking at Fig 2(a), which is otherwise never referenced from the text.
>   Figure 3(a) is also not discussed, and Figure 4(a) discussed before 3(c).
>   Figure 3(c) could be referenced from ln 371?
> 
> # Typos, grammar, etc.
> 
> - Remark 3.2 (end of page 9): should end the last math block with a comma
>   instead, and use a lowercase "or", since it seems the same sentence.
> 
> - line 357: "abstraction" -> "data abstraction"
> 
> - The `:⇔` symbol the paper uses for equal by definition seem non-standard to me
>    so I was even parsing this wrong at first; so I would suggest either changing
>    to something more standard like `≜`, or at least explain any non-standard
>    notation the first time it's used.
> 
> - "two component" -> "two components"
> 
> Questions to be addressed by author response
> --------------------------------------------
> What conceptual contributions does this work bring over the previous theoretical
> work by Koenig and Shao [LICS 2020] and Oliveira Vale et al. [POPL 2022]?
> 
> For instance, are the layered composition operator or any of the spatial
> composition operators new to the current submission?
