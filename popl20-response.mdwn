# Response

*Presentation issues.*
We acknowledge the issues raised by the reviewers regarding the
paper's presentation and will address all of them in the ways
suggested unless stated otherwise below. In addition, some
specific ones are discussed in the extended part of this
response. Given these issues we are particularly grateful for the
excellent quality of the reviews that we have received. 

## Coq formalization

*Availability of the development.*
To address the reviewers' concerns about the availability of the
code, we provide our Coq formalization of §3 on an anonymized
[website](https://sites.google.com/view/compcert-rbgs/home).

*Mechanization of §4.*
Adequately incorporating refinement and nondeterminism into game
semantics and formalizing the result in a proof assistant is a
challenging and open problem. Past iterations of our game
framework (and our embedding of CompCert into them) have been
formalized in Coq, however their design was too complex for us to
carry out non-trivial proofs. Building on Morris and Tyrrell's
line of work on dual nondeterminism represented a major
breakthrough in addressing this. However it was a fairly recent
realization on our part and we did not complete the mechanization
of the resulting framework.

*Relationship to separate compilation.*
As pointed out by Reviewer 68#D, our submission fails to address
the relationship between our compositional semantics on one hand,
and on the other hand the syntactic program linking used to
define separate compilation in modern versions of CompCert. While
we believe semantic linking must primarily be addressed within
the game framework, our development also contains a small-step
version of our operator (`common/SmallstepLinking.v`), as well as
a proof that the semantics of assembly programs obtained through
CompCert's syntactic linking operator refines the composed
semantics of the components ([[p1]] ⊕ [[p2]] ⊑ [[p1 + p2]],
`x86/AsmLinking.v`). This is the property required for the
construction of composite assembly programs verified against a
high-level specification. In previous iterations of our game
framework we also used this proof as an intermediate step for
establishing an equivalent property at the level of strategies.

## Problems with §4

The game model presented in §4 is [really cool and important for
reasons X Y Z], however we agree with the reviewers that our
exposition is severely lacking. We propose to address this in the
following ways.

*Properties of the FCD.*

*Determinacy vs. determinism*

*Related work.*
Our work draws from a wide array of existing research and the
paper's Related Work section is not up to the task. ACK interface
automata (R68#B), Ahmed's work (R68#D)


*Low quality of §4.*
Something along the lines of: We have solved nondeterminism in
game semantics and this is a big deal. However the novelty of
this approach in the context of game semantics make it difficult
to articulate in a satisfactory manner. We hope that our changes
will address some of the reviewers' concerns and we believe that
the work sketched in §4 will be critical to the construction of
large-scale, heterogeneous verified systems. The ability to do
that is what distinguishes our approach from other things (esp.
Gil Hur line of work that refers to the whole program when
expressing refinement and composition). However the introduction
of composition at the level of small-step semantics means we
could scrap the section given the amount of ground already
covered in the rest of the paper.

(XXX: With linking done at the small-step level the rest of the
paper could stand on its own so it would be possible to scrap §4
or frame it as a more speculative "future work" / sketch type of
section. We could ask reviewers who recommend acceptance whether
this would be acceptable to them.)

## Conclusion

We were very encouraged by the enthusiasm expressed by the
reviewers regarding the direction of our work. Our goal in
writing this response was to demonstrate that the serious
shortcomings of the paper can be addressed in the coming weeks,
and that the final submission will be substantiated by a strong
artifact.

In the extended portion of our response below,
to be used at the reviewers' discretion,
we answer specific questions from the reviewers
and flesh out how we will address some of the problems
for which a straightforward solution is not
immediately obvious.

---

# Additional comments

## Review #68A

> > elementary game with a similarly simple structure [l. 327]
> 
> Similar to what?

This is meant as "as simple as the game $\mathcal{C}$" in the
sense that the structure of the interaction is the same although
the set of questions and answers can vary. We will clarify.

> > This gain in expressivity allows us to side-step a number of
> > issues that have plagued previous work on CompCert
> > compositionality. [l. 347]
> 
> It would be good to say what those are.

> > In addition, simulation conventions of a given type are
> > equipped with a notion of refinement ⪯, and for
> > “endo-conventions” of type $\mathbb{R} : E ⇔ E$, a
> > corresponding notion of Kleene star $\mathbb{R}^*$. [l. 371]
> 
> Unclear what they mean.

We will explain that the conventions used by simulations can be
substituted with a refined convention, and include a forward
reference to §3.4 where these things are formally stated.

> By the time I got to §3.3, I had forgotten what the notations
> $M^Q$ and $M^A$ meant.  What are $A$ and $B$ in that paragraph?
> Also, the variable $F$ is used with two different meanings
> there (an elementary game and the set of final states).

Yes, sorry, this is a mess. $A$ and $B$ should be $E$ and $F$,
and we will be sure to distinguish notations between the final
state predicate and the codomain game.

> Are initial, final, resumption and interacting states disjoint?
> [Definition 3.1]

The CompCert definition of a determinate semantics is updated to
enforce that at most one of →/final/external applies to any state,
but this is not a general restriction. Initial and resumption
states can always terminate or interact immediately.

> Is there a difference between "simulation" and "refinement
> conventions" (l. 602 vs. l. 607)?

No, thank you for pointing this out. They are both meant to read
"simulation convention".

> What does the $≼^Q_F$ relation mean on l. 627? My guess is that
> it is the $R^Q$ relation in Definition 3.2, but I am not sure
> (it doesn't look like it could be the refinement relation of l.
> 371).  Similar comment for l. 634.

Yes you are right. We will rename $R$ to $\preceq$ in Definition
3.2 and throughout, and reserve $R$ for the simulation relation.

> L. 627 also seems to be identifying predicates $I ⊆ M^Q × S$
> (as given in Definition 3.1) with functions $M^Q → \mathcal{P}(S)$,
> which is not obvious to me on a first reading. Consider
> replacing that with $I(q, -)$ or some other notation. A similar
> comment holds for $Y$ on l. 631.

Thank you for this suggestion; in addition we should define what
$\exists i \,.\, R_i$ means as a relation.

> Should $W_E$ on l. 632 be $W_F$?
> 
> It is not intuitive what the $w'$ on l. 634 does not need to be
> related to $w$, or that the world is only allowed to evolved on
> external calls. Some explanation would help.

We will rename $w'$ to $w_E$ and $w$ to $w_F$.

In a component of type $E \rightarrow F$, the game $E$ and $F$
are played with opposite polarities: in $F$ the environment asks
the questions and the component produces an answer (this
corresponds to initial and final states); in $E$ the component
gets to ask questions, and receive corresponding answers from the
environment (this corresponds to external calls). This is what we
means by the outgoing/incoming language interfaces and simulation
conventions.

Adding to the confusion is that contrary to what happens once we
introduce CKLRs (and traditionally in Kripke models), until §3.6
our sets of worlds are very "flat" and worlds do not evolve.
Every time the components perform external calls (matching
questions of $E_1$ and $E_2$), the simulation gets to choose a
world $w' \in W_E$ to relate them, and is guaranteed that the
corresponding returns (answers of $E_1$ and $E_2$) will be
related at the *exact same* world $w'$. Conversely, when the
environment initially invokes the components (matching questions
of $F_1$ and $F_2$), the simulation is provided with a world
$w \in W_F$ relating the questions, and any answers eventually
generated by final states must be shown to be related at the
same world $w$.

> What is the $·$ operator on relations on l. 655? It cannot be
> just relation composition, since the relations are ternary and
> have different indices...

You are right. We will explain we can extend the basic relation
composition $\cdot$ to KLRs as follows:

$[(w_1, w_2) \Vdash R \cdot S] = [w_1 \Vdash R] \cdot [w_2 \Vdash S]$

> The definition of `inject_incr` is only indirectly given (l.
> 778). Also, what is $\mathsf{option}^{≤}$?

We will use $\subseteq$ in Fig. 4 rather than `inject_incr`,
and define $\mathsf{option}^{\le}$ in Fig. 2 alongside the other
relators (it corresponds to $\mathcal{P}^{\le}$ when option
values are interpreted as sets of cardinality $\le 1$).

> Shouldn't the injection component of `ext` be $* ↦ (b ↦ (b, 0))$?
> [l. 770] Also, what are `Mem.extends` and `Mem.inject`?

You are right about `ext`, and while defining `Mem.extends` and
`Mem.inject` is not possible in reasonable space, we will mention
them by name in §3.5 and refer the reader to reference [37] for
more details.

> > In particular, an external function acting on the memory state
> > should not
> > synthesize block identifiers and pointers, but can only follow
> > pointers passed
> > as arguments or fetched from the memory itself. [l. 793]
> 
> I imagine that your framework would still allow external
> functions to allocate
> memory, so I do not understand what you are trying to say here.

The sentence is missing allocation as a valid way to obtain block
numbers. By "synthesize" here, we mean forge block numbers
arbitrarily rather than obtaining them through the memory model's
operations (including allocation).

> Shouldn't $W$ in l. 804 be `meminj`?
> 
> Definition 3.8 is hard to grasp.  I expected more intuition
> about the meaning of the two memory components in the worlds
> (e.g. I don't know what a "newly allocated block" is (l. 808)).
> What is the difference between $⇝_{\mathsf{injp}}$ (l. 804) and
> $⇝_{\mathsf{meminj}}$ (l. 812)?

You are right that $W$ should be meminj, and
$\leadsto_{\mathsf{meminj}}$ should read $\leadsto_{\mathsf{injp}}$.

The world's memory components are just a way we can remember a
copy of the memory states being related (per l.816). This is done
so that the accessibility relation can formulate constraints
relating the old pair of memory states to the new one,
contraining the ways in which the memory states can be conjointly
modified.

Because the accessibility relation is transitive, these
contraints will end up holding between the initial and final
memory states of a call. This allows us to formulate the
constraints that CompCert places on external calls
(`extcall_properties` from `common/Events.v`, and in particular
`ec_mem_inject`) within the relational framework of CKLRs.

> How do you define the composition of two CKLRs? [l. 822]

Thank you for pointing out the missing definition. The worlds are
pairs and the accessibility relation acts component-wise. The
memory injections are composed according to CompCert's
`meminj_compose`
($f(b) = (b', \delta_1) \wedge
g(b') = (b'', \delta_2) \Rightarrow
(f;g)(b) = (b'', \delta_1 + \delta_2)$).

> > the semantics of CompCert languages are expected to be
> > well-behaved with respect to invariance properties of the
> > memory model [l. 824]
> 
> Unclear.
> 
> > our final correctness theorem [l. 829]
> 
> Not clear what this is.
> 
> > it suffices to show that the incoming and outgoing simulations
> > can be
> > reconciled... [l. 844]
> 
> Unclear. I can see how the convention in l. 842 is related to
> Table 2, but I
> don't understand what the "incoming and outgoing simulations"
> are.
> 
> > The work presented in this section has been fully implemented
> > in the Coq proof
> > assistant [l. 852]
> 
> It would have been interesting to know this earlier!
> 
> > Plays already constitute a monad, however we emulate the
> > approach taken in [?]
> > [l. 873]
> 
> Broken citation.
> 
> In the definition of $⊑$ (l. 886), don't you need to include the
> answers of the
> environment as well?
> 
> > Instead, we adapt the approach used in [?] [l. 911]
> 
> Broken citation.
> 
> The equations $⊥ = \bigsqcup ∅$ and $⊤ = \bigsqcap ∅$ are not
> very helpful; I
> think $⊥ = \mathcal{S}_E(A)$ and $⊤ = ∅$ would be better to
> clarify what is
> going on.  (Also, I am a little bit confused because these seem
> to contradict
> the explanations given in that paragraph: with $⊥$, the
> environment can choose
> any strategy for the component; with $⊤$, the environment cannot
> choose
> anything).
> 
> > an monotonic operator [l. 961]
> 
> "a monotonic operator".
> 
> I do not understand the definition of $\mathbf{I}_E$ [l. 985]
> because $n$ is
> free [l. 985].  I imagine that the real meaning would be to
> promote individual
> strategies that contain plays of this form to elements of
> $\mathcal{I}_E(M_E^A)$ -- maybe $\{ S ∣ ∀n. mnn ∈ S \}$? But I am
> not sure.
> 
> > the value returns [l. 987]
> 
> "returned"
> 
> Is the join in l. 1096 taken pointwise?
> 
> I imagine that the interesting aspect of the horizontal
> composition operator of
> l. 1102 is that it allows to reason about refinement
> compositionally, but the
> text does not mention that.
> 
> Broken reference on l. 1132.
> 
> 
> 
> Review #68B
> ===========================================================================
> 
> Overall merit
> -------------
> B. Weak Accept
> 
> Reviewer expertise
> ------------------
> Y. Knowledgeable
> 
> Paper summary
> -------------
> The paper draws on intuitions and terminology from game-based
> theories (for programming language semantics and software
> verification) to classify the developments within the CompCert
> project and subsequent extensions.
> 
> It also proposes a new methodology for proving the CompCert
> soundness theorem based on a variety of techniques from game
> semantics (to capture the shape of environmental interactions),
> alternating refinement (to capture refinement of components),
> simulations and logical relations.
> 
> The method has been formalised in Coq and leads to an arguably
> cleaner correctness proof than previous attempts.
> 
> The paper concludes with a proposal for a game-based framework to
> facilitate compositional verification. Its novel feature with
> respect to existing game models is the integration of angelic and
> demonic nondeterminism. In particular, the capability to model
> two-way interactions between components is related explicitly to
> strategy composition.
> 
> Strengths
> ---------
> The proposed approach is an interesting synthesis of ideas from
> various game-based theories, geared towards establishing compiler
> correctness in a compositional way.
> 
> Weaknesses
> ----------
> While the paper is quite precise about its use of game semantics,
> the relationship to interface automata is discussed only in
> passing. It would be desirable to include a more detailed account
> of what ingredients you borrow from the theory of interfaces and
> which are claimed to be your contribution.
> 
> Comments for author
> -------------------
> The paper badly needs a proof-reading/spell-checking pass. There
> were far too many typos and broken links. Here are a few places
> that need to be fixed.
> 
> 159: correspond the interaction
> 300: requres
> 301: esablished
> 345/349/459: correspondance
> 438/874/911/1132: broken reference
> 537: retreived
> 600: missing period
> 916: containement
> 
> Questions for authors’ response
> ---------------------------------
> Please comment in more detail on the relationship of your
> framework to related work on compositional software verification
> and interface automata in particular. That strand of research
> involves similar concepts and it would be desirable to identify
> the precise nature of your contribution in this context.
> 
> 
> 
> Review #68C
> ===========================================================================
> 
> Overall merit
> -------------
> A. Strong Accept
> 
> Reviewer expertise
> ------------------
> X. Expert
> 
> Paper summary
> -------------
> This submission is part of a line of research: the formal
> verification of large software made of several components,
> represented at different layers of abstraction. The challenge is
> to reduce the proof of the complete software to the proof of each
> individual component. The submission reports on a first step in
> this direction: a semantic framework based on game semantics and
> refinement methodology. 
> 
> The submission details how to apply this framework to the
> CompCert verified compiler. This work was formally verified using
> the Coq proof assistant, but the formal development is not
> available. A limitation of CompCert is that its correctness
> theorem only applies to a complete program. The presented
> framework is a general solution to overcome this limitation.
> CompCert accomplishes a series of compilation passes from C to
> assembly using several intermediate languages, and each pass is
> proved correct using a simulation diagram. The different
> simulation diagrams range from standard diagrams to advanced
> diagrams involving well-founded measures (required to avoid
> stuttering issues in diverging executions) and/or memory mappings
> (required to model how a pass transformed memory). 
> 
> The last part of the submission presents a composition
> infrastructure and explains how to define the semantics of
> programs made of several modules. The semantics relies on an
> interaction monad and features both angelic and demonic
> nondeterminism. The submission explains how to apply this
> infrastructure to the modified CompCert.
> 
> Strengths
> ---------
> - The submission presents a novel and general solution to solve a
>   difficult open problem.
> 
> - The approach is applied to a real case study, the CompCert
>   formally verified C compiler.
> 
> Weaknesses
> ----------
> - The Coq development is not available.
> 
> - Some parts of the submission are difficult to read.
> 
> Comments for author
> -------------------
> Both the general problem and the end result of the submission are
> impressive. We get a new semantic framework for CompCert that
> enables modular verification and generalizes the existing one.
> That said, I found that some parts of the submission are
> difficult to read and should be better explained. 
> 
> - Some background information on Compositional CompCert
>   (including its semantic linking operator) is missing. Sentences
> such as "Following Compositional CompCert, we ..." are difficult
> to understand without reading the associated paper.
> 
> - Some notations are not introduced; other notations are
>   confusing. 
> * (189) A single notation should be used for this operator.
>   Another notation is used on line 602.
> * In Fig.1, what are i1() and i2()? Same question at line (650).
> * (422) What is [R] compared to R?
> * Definition 3.1 is confusing. What does E represent intuitively?
>   What is B (579)? The choice of A (581) is confusing because of
> the use of M^A_E and M^A_F, where A has a different meaning.
> * Why does \mathbb{R} (604) become \mathbb{C} (607)?
> 
> - Explanations of Table 2 are missing.
> * What are Eqn. (4) and Eqn. (5)?
> * The outgoing and incoming columns should be explained. For
>   example, what does "alloc" mean in these columns, and what does
> property (5) (line 832) mean?
> 
> - Fig.4 is difficult to read. At least one axiom should be
>   explained.
> What does "the component is given directly" (755) mean?
> 
> - Compiler correctness
> * Are properties (4) and (5) (see lines 831 and 832) two examples
>   of representative proved properties? Are the other proved
> properties similar?
> * I do not understand the simulation convention on line 842.
>   Where do the different components come from?
> 
> 
> Other remarks
> - (129) Why \sigma_1 and p_2, and not p_1 and \sigma_2?
> - (160) correspond TO
> - (568) labeled transition system (LTS)
> - (599) answers.
> - (607) "refinement conventions" should be "simulation
>   conventions"
> - (753) This line should introduce the KLR acronym.
> - (1021) denoteS
> - Several references to subsections and bibliographical
>   references are missing (and replaced by question marks): see
> lines 438, 874, 911 and 1132.
> - Capital letters are missing in many titles listed in the
>   reference section (see for example lines 1179, 1194 and 1210).
> 
> Questions for authors’ response
> ---------------------------------
> Contrary to Section 3, Section 4 does not seem to be formalized
> in Coq. Why?
> 
> 
> 
> Review #68D
> ===========================================================================
> 
> Overall merit
> -------------
> D. Strong Reject
> 
> Reviewer expertise
> ------------------
> Y. Knowledgeable
> 
> Paper summary
> -------------
> The paper introduces refinement-based game semantics, which
> synthesizes existing
> research on game semantics, refinement-based verification,
> logical relations,
> and certified abstraction layers. The authors promise that this
> theoretical
> framework for certified components is both more expressive and
> simpler than
> previous work in this space, such as Compositional CompCert. They
> use this
> framework to devise a compositional variant of CompCert (Section
> 3), which is
> the authors claim was "fully implemented in the Coq proof
> assistant", but then
> no Coq development or any proof whatsoever was sent in with this
> submission.
> 
> Strengths
> ---------
> + This is promising work that aims to solve a challenging problem
>   in the
>   compositional compiler correctness area. Several previous
> attempts have fallen
>   short because they were very complex (e.g, Compositional
> CompCert), and often
>   neither expressive nor scalable.
> 
> + As far as I could understand them, many of the ideas of the
>   paper seem elegant
>   and it is plausible they could indeed be effective. The key
> idea of the paper
>   is to use more interesting mathematics to raise the level of
> abstraction of
>   the definitions and proofs.
> 
> + Seems that a large amount of work went into this, especially if
>   the claims of
>   Section 3 were indeed backed by a complete Coq development.
> 
> + I would like to see a good version of this paper published as
>   soon as it's
>   ready, but unfortunately ...
> 
> Weaknesses
> ----------
> ... I think this paper needs a lot more work before it can be
> published.
> 
> - The submission comes with no Coq development and no proof
>   whatsoever. This is
>   very disappointing, given that the paper claims full Coq proofs
> for
>   Section 3. It is not clear if any Coq development or proofs
> exists at all.
> 
> - The paper is poorly written, which badly obscures the main
>   ideas. Publishing
>   this would only be useful if readers were able to actually
> understand the
>   results.  Unfortunately this is currently very hard, even for a
> careful
>   reader. Here are a few concrete problems (more below):
>   - Many concepts are introduced more than once, each time from
>     scratch, and it
>     is very hard to understand how the various pieces fit
> together.  For
>     instance "Compiler Correctness" is defined 3 times (in
> sections 2.1, 2.4,
>     and 3.7, each time from scratch), there are multiple sections
> with the same
>     name but between which no connection is made, etc.
>   - The main theorem of the paper seems to be the compiler
>     correctness statement
>     at the end of section 2.1.5, but the paper never mentions how
> this is
>     proved. It seems that the proof involves proving simulation
> (3.7) and
>     showing the soundness of simulation wrt refinement (4.3.4),
> but these two
>     pieces don't actually fit together (see below).
> 
> - The paper is very sloppy about the technical details: many
>   definitions and
>   even some informal theorem statements are full or typos,
> extremely incoherent
>   about notations, and even broken. This inspires no trust that
> the technical
>   details of this work have been actually worked out. For
> instance,
>   - one of the 2 main theorems (the one in 3.7) seems badly
>     stated: the theorem
>     says that the generated assembly code simulates the source
> code, but this
>     doesn't match what would be needed to prove compiler
> correctness (2.1.5)
>     together with the informal theorem in 4.3.4. It seems that
> the direction of
>     the simulation is wrong and should be swapped to also match
> equation 1 on
>     line 380. In general, the paper seems confused about
> backwards simulation vs
>     forwards simulation. It could be the case that the paper
> adopts the CompCert
>     technique of proving a backwards simulation from a forwards
> simulation, but
>     that's never properly explained (on the contrary, see line
> 590).
>   - (other examples below)
> 
> - The paper does not convince that the proposed technique is more
>   expressive or
>   more scalable than previous techniques. The paper talks very
> little about the
>   Coq development and in general about the proofs and the proof
> effort. In fact,
>   as far as I can tell from this submission, it's not clear
> whether any proofs
>   actually exist.
> 
> - Section 4 seems not fully done, and there are many lose ends:
>   - It's very unclear what the formal status of this section:
>     no formalization, no theorems, no appendix with proofs.
>   - The writing of this section is not understandable, even for a
>     careful reader
>     who does a few passes over the section.
> 
> - It is unclear how this work is related to CompCert's theorem,
>   both the
>   original one (for whole programs), and the current one (with
> separate
>   compilation). If this work is really more expressive than
> previous work,
>   shouldn't these old theorems follow formally?
> 
> Comments for author
> -------------------
> ### Poor writing
> 
> Section 2: I like the idea of starting with a section that
> explains the
> main ideas informally, and I particularly like sub-sections 2.1
> and 2.2. The
> explanations in this section should still be improved though:
> - This whole section is badly missing an outline that explains
>   upfront where this
>   section is trying to go. This is completely unclear at this
> point.
> - Section 2.3, seems an useless connoisseur-only detour, that's
>   not at all
>   understandable to mere mortals. (This also seems rather
> opinionated.) Can it
>   simply be merged into 4.1?
> - 2.4 Compiler Correctness, starting to get lost quite a lot.
>   Paper basically
>   switches to a lot of game semantics "jargon" that wasn't
> explained above (not
>   just words, but concepts). Neither Fig 1 nor the text is
> understandable, and
>   the connection between them even less (more details below).
> - The connection between Galois connection (of 2.1) and the
>   simulation
>   conventions of 2.4.5 should be properly explained in 2.4.5. I
> guess that
>   simulation conventions are a compositional way to define Galois
> connections,
>   and that doesn't come out until section 4.3.4.
> - 2.4.6 Compiler Correctness (again) – The connection to the
>   compiler
>   correctness definition from 2.1.5 should be explained.
> - 2.5 Logical relations – not properly explained what this is for
>   in the flow of
>   the paper - the monoid example better than nothing, but doesn't
> clarify the
>   connection to the rest of the paper either.
> - The examples in 2.6 do help, but it would help a lot to have
>   such examples
>   starting with 2.4.5 already.
> - It is sometimes unclear which parts of this section are just
>   reviewing
>   background material, and which things are new. Citations are
> often missing:
>   the whole of 2.1 new has 0 citations, 2.5 has 1 citation, and
> 2.6 zero again,
>   but I really don't think all this is new.
> 
> pg 3, 2.1.3 Monotonicity: Monotonicity is introduced in 2.1.3,
> but never
> mentioned again. Does the horizontal composition operator of
> section 4.4.2
> satisfy monoticity? The paper should answer this question one way
> or the
> other, otherwise there is no point in introducing monotonicity in
> 2.1.3.
> 
> pg 4, line 177: "Its plays are of the form: ..." – It's unclear
> from the
> explanation that all plays in C are formed of a single call and
> return, and this
> is not just and artifact of the example. This seems
> oversimplified if one thinks
> of real C, but it seems that what saves the day will be the
> composition
> operators from 2.2.3. So a forward pointer and better explanation
> seems needed.
> 
> pg 4, line 190: Please mention whether your plays are all finite,
> or also
> infinite. If they are all finite, please explain whether this
> gives you weaker
> guarantees than CompCert's current theorem, which also talks
> about infinite runs.
> 
> pg 5, line 207: "Innocence requires that the behavior of a
> strategy only depends
> on the most recent move as well as the chain of moves enabling
> it. This means
> the strategy is not allowed to maintain private state across
> successive but
> independent queries." – This explanation makes no sense and leads
> to bad a
> misunderstanding. In fact, the components/procedures can keep
> private state, as
> long as that is exposed in the moves. C components do keep
> private state!
> 
> pg 5, line 239: Composition seems important but only explained
> very much in
> passing. More details needed on how 2 strategies are combined. I
> guess it's
> choosing all common traces after flipping one of them ... and
> removing things
> that match from the trace?
> 
> pg 6, line 247: Fig 1: should explain in the text what the
> turnstyle notation
> means, otherwise it's super hard to follow.
> 
> pg 6, 2.4.1 Whole-program semantics – Unclear what you mean by
> "original
> CompCert" semantics, since this is not only a "non-compositional"
> semantics, but
> also a semantics that CompCert itself no longer uses (e.g. the
> references to
> deterministic external functions seem completely dated, the only
> requirement
> CompCert makes today is determinacy and input totality of the
> semantics, not of
> the external functions). Also unclear why you use the same
> epsilon on both side
> of the turnstile, when things don't seem to be symmetric. Also
> unclear why the
> codomain of ε is C, and not just a return value. All this needs
> to be properly
> explained even for people without a game semantics background.
> 
> pg 7, 2.4.4 Unclear what's the difference between your C->C and
> Compositional
> CompCert's C->C, and why you use an asymmetric notation for ie
> (E->F). From what
> I can tell, the difference is that instead fixing a single C for
> the whole
> compilation chain, your C varies between the levels. If that's
> the difference
> the first paragraph of 2.4.4 should be a lot clearer about it (it
> does get
> better in the 2nd paragraph). If the asymmetry of E->F is also
> useful for
> anything, then you should actually explain for what.
> 
> pg 10, line 452, It would be nice to have a clean explanation of
> the
> meminj-indexed Kripke logical relation in p.10 -- one can see
> where they're
> going with it being familiar with memory injections, but it's
> still too dry. The
> remaining of the section 2.6 follows a similar pattern: many
> ideas introduced in
> rapid succession, seemingly straightforward, but short on
> context.
> 
> Sections 3.1-3.3 are decent, although the definition (3.1) in 3.3
> is a bit gory,
> and could be better explained, again an example could help.
> 
> Then the exposition becomes imprecise and unclear.  It is hard to
> follow the
> definitions given, mainly because of the big number of
> ambiguities and
> references to not or ill defined objects they contain (see list
> below).
> 
> pg 13, line 602: Definition 3.2 not explained at all. I guess
> that Q
> stands for question, A for answer, W for world?
> 
> pg 13, line 622: Definition 3.4. This complex definition given
> without any
> explanation.
> 
> The rest of 3.4 is only about math and no explanations
> whatsoever. It's also not
> clear what the connection to 2.4.5 is.
> 
> Section 3.5 talks only about changes in memory, but I that's
> anyway something
> previous approaches could for the most part also handle. I would
> have expected
> something about changes of games, which is the new thing here.
> 
> Section 3.6 has a number of definitions (3.7, 3.8) where knowing
> some CompCert
> one can see where they're going, but still don't leave the reader
> satisfied. Are
> they as straightforward as they seem, is there anything
> interesting hidden in
> them? I found the remark in p.16 that "We expect the remaining
> components to be
> consistent..." to be particularly perplexing. Are the authors
> assuming something
> else that we're not being told explicitly?
> 
> The uses of parametricity aren't given much attention, but given
> that they are
> publicized at the beginning I'd like to see those bits expanded
> (perhaps they
> aren't too surprising, but they are likely interesting).
> 
> Table 2 is impossible to understand at this point in the paper
> and is given with
> zero explanations. What do the *italic* lines mean? What does
> "Clight
> properties" mean? What does "RTL properties" mean? What does
> "Outgoing" and
> "Incoming" mean, and why are they in this order? And what are all
> the names in
> the "Outgoing" and "Incoming" columns (this last one becomes a
> bit clearer in
> the rest of this section, but not completely).
> 
> Section 4 – This section is badly missing an outline that
> explains how the
> pieces of these section fit together with each other and with the
> rest of the
> paper.
> 
> Section 4.1: It is unclear why the monad is defined this way. The
> arguments made
> in 2.3 and at the beginning of 4 are not clear. There are a lot
> of strong
> opinions on angelic and demonic nondeterminism, but what the
> authors mean by
> angelic and demonic nondeterminism is not explained. This
> distinction is not
> common at the operational semantics level, and it's unclear what
> the problem
> really is.
> 
> ## Sloppiness about technical details
> 
> pg 12, line 576: "for `E → F` is a tuple `L = ⟨S, →, I , X , Y ,
> F ⟩`" –
> big mess with notation, the two Fs are for different things
> 
> pg 12, line 579: "The handling of incoming calls is specified by
> I ⊆ M FQ × S,
> which assigns a set of initial states to each question of B" –
> what B?
> "question of A directed to the environment, and Y ⊆ S × M A × SE"
> – what A?
> This notation of A/B and E/F is a complete mess. A should only be
> used answers.
> This seems like a renaming (A->E, B->F, that was never finished),
> and which is super confusing.
> 
> pg 13, line 590: "The correctness of CompCert is established in
> terms of backward
> simulations" – this is not true, CompCert proves a forwards
> simulation and then
> uses a general result about determinacy and input totality to
> flip it
> 
> pg 13, line 602: Definition 3.2: The R doesn't respect the
> paper's notations
> (afterwards simulation conventions are written C)
> 
> pg 13, line 631-632, Definition 3.4:
> - "q1 [w' ⊩ ⪯Q E ] q2" – again, this should be m1 and m2, not q1
>   and q2
> - A₁ and A₂ (in the moves sets lines 631,632),
>   B₁ and B₂ (in the moves sets lines 638,639)
>   are used as games but never introduced,
>   probably they are F₁, F₂, E₁ and E₂.
> - I don't get the meaning of `≼_F^Q` (line 627), `≼_E^Q ≼_E^A`
>   (line 634),
>   `≼_F^A`.  It is not clear if they are "notions of refinement
> associated with
>   the simulation conventions `C_E` and `C_F`" (mentioned in line
> 371 and any
>   case defined only at page 14).
> - Is `W_E` just the first entry of the following
>   triple `C_E = (W_E, R_E^Q, R_E^A)`? Same for `W_F`.
> 
> pg 22, line 1066: The definition of γ has the wrong type. The
> types of the
> functions involved suggest that the definition of γ should be
> `S^* ∘ σ ∘ R^*`.
> 
> pg 22, line 1068: If this is a theorem, it should be stated as
> such.
> 
> In general, the main theorems should be stated as proper
> theorems, and since the
> results of Section 4 are not proved in Coq, one would also expect
> proofs, in an
> appendix, or somewhere.
> 
> # Missing related work
> 
> The paper is completely missing any citations to Amal Ahmed et
> al's work, even
> if some of it is very much related. The paper is building on the
> work of Amal
> Ahmed et al's and of various other groups on Kripke logical
> relations, without
> giving **any** citations. Then, even if it's to some extent
> concurrent work, the
> paper should also relate to "The Next 0 Compiler Correctness
> Theorems. A
> Functional Pearl" ICFP'19 paper of Daniel Patterson and Amal
> Ahmed, which
> introduces a framework for comparing compositional compiler
> correctness results.
> The current paper fails to answer even basic and very important
> questions such
> as "What components can one link with?", which fitting this work
> into the
> framework of Patterson and Ahmed would require making explicit.
> 
> The paper seems also related to the following paper, on game
> semantics for C:
> D. Ghica and N. Tzevelekos. A system-level game semantics. In
> MFPS’12:
> The 28th Conference on the Mathematical Foundations of
> Programming
> Semantics, 2012.
> https://www.cs.bham.ac.uk/~drg/papers/mfps12b.pdf
> 
> ### Small things
> 
> pg 3, line 104: We will call the set D a semantic domain. – this
> discussion gets
> abstract too quickly, and it would help to give some upfront
> examples about
> what this semantic domain (and the refinement preorder,
> composition operators,
> etc) could be in a simpler setting, say of sets of traces.
> 
> pg 3, line 123: In the example of monotonic reasoning it is not
> so natural the
> way composition and refinement are applied. To obtain
>    \sigma \ref [[p1 + p2]]
> I would expect to show something like
>    \sigma \ref \sigma1 \oplus \sigma2
> or
>    \sigma \ref [[p1]] \oplus [[p2]]
> I guess this has to do with the way the CertiKOS proof works, but
> not sure.
> 
> pf 4, line 173: the sequence of moves for the example about chess
> is not valid,
> in the second move of the black the pawn in e7 cannot move to d5,
> you probably
> mean e7e5.
> 
> pg 4, line 178: "using what signature sg" – typo: the signature
> 
> pg 6, line 242-244: The intuition for the encoding of arrows in
> terms of linear
> logic should be better explained.
> 
> pg 6, line 291: "and terminations carry the function’s return
> value and final
> memory state (C)" – by "terminations" you probably mean returns /
> answers
> 
> pg 7, line 300: "it requres [...] to be esablished" – 2 typos,
> please use a spellchecker
> 
> pg 7, line 316: "However, several passes of CompCert are
> challenging to fit into
> this framework." – were changed? need changing?
> 
> pg 8, line 349: Simulation diagrams introduced in 2.4.5 should
> take explain the
> horizontal vs. vertical relationships between "simulation
> conventions" and
> transition systems. I walked away unconvinced that 'convention'
> was the right
> word though, as the initial intuition that it is related to
> calling conventions
> quickly gives way to something much more general.
> 
> pg 8, line 355: "We write: ..." – there is an "iff" missing?
> 
> pg 8, line 360: "describes the type composite simulations" –
> typo, missing "of"?
> 
> pg 8, line 371: This last phrase comes out of nowhere, and I
> think could be
> safely left out for now.
> 
> pg 8, line 373: "interactive behaviors of types" – Didn't
> understand the sense
> in which the word "types" is used here. It might not be the right
> word here?
> 
> pg 9, line 437: "We apply this framework in our treatment of
> refinement and
> abstraction in the context of game semantics (§??)." – broken
> reference
> 
> pg 11, line 522: Section 3 is titled "Open modules for CompCert".
> I believe
> there is no mention of this until section 4.
> 
> pg 12, line 565: "Once we reach Asm (A), queries and replies
> simply specify the
> values of registers and the state of the memory." – seems that
> this works
> because the pc is also a register, might want to mention this
> 
> pg 12, line 570: "CompCert LTS support" – grammar
> 
> pg 12, line 576: "Definition 3.1, L = ..." – this is easy to
> misparse because
> the next sentence starts with a symbol "→", which should
> generally be avoided.
> 
> pg 13, line 607: "refinement conventions" – should be simulation
> conventions;
> same problem in Lemma 3.6 on line 656
> 
> pg 13, line 631: Definition 3.4 shows the extended (and
> rephrased) backward
> simulation.  It would be interesting to explain external calls in
> the text, are
> these are the main novelty with respect to the standard CompCert
> formulation.
> 
> pg 14, line 658, Lemma 3.6: what does it mean for a strategy to
> have the type
> `A^# ⇒ B^#`? Is it a strategy for which game?
> 
> pg 16, line 754: "The R mem component is given direcly." –
> directly
> 
> pg 16, line 770: What does * (star) stand for?
> 
> pg 18, line 874: "we emulate the approach taken in [? ]" – broken
> citation, not
> the only one – I guess you mean something like [39, 40]? – there
> are more such
> broken citations and references in the paper.
> 
> pg 20, line 960: typo "an monotonic", it should be "a monotonic".
> 
> pg 23, line 1094: "the flat composition of the behaviors: ... let
> the
> environment communicate" – typo: lets
> 
> pg 24, line 1147: "In particular, Damien Pous’ work on Kleene
> algebra with
> converse and extensive library of associated Coq tactics offer
> promising
> opportunities for proof automation." – proper citations missing
> 
