We are very grateful for the high quality and thoroughness of
the reviews we have received. The reviewers' prescriptions are
pertinent and we will apply them to any revision.

## Availability of the development

To address the reviewers' concerns about the availability of the
code, we provide our Coq formalization of §3 as well as some
additional material on an anonymized
[website](https://sites.google.com/view/compcert-rbgs/home).
The `compcert-rbgs.tar.bz` archive contains our developement where:

  * `README.md` is augmented with a short description and
    build instructions;
  * `common/LanguageInterface.v`
    formalizes elementary games and simulation conventions;
  * `common/CallconvAlgebra.v`
    formalizes operators on simulation conventions and their
    properties (Def 3.5, Lemma 3.6, ll. 643–672);
  * `common/Smallstep.v` is modified following the paper's
    description (§3.3–3.4);
  * The `cklr/` subdirectory contains our theory of
    CompCert Kripke logical relations (§3.6);
  * The `*/*rel.v` files contain our parametricity proof for
    Clight and RTL (Eqn. 4 & 5, l.830);
  * The main result (l.850) is proved in `driver/Compiler.v`.

## Comparison to other approaches

*Example: Stacking pass.*
To provide a more concrete discussion of how our approach differs
from previous work, we compare treatments of the Stacking pass,
which lays out the abstract locations of the Linear language into
a combination of machine registers and in-memory stack frames
used at the level of the Mach language.

The main challenge in Stacking is to establish the separation
properties of the target memory that the simulation proof relies
on, and to maintain them at external calls. A typical exemple
concerns the pathological case of initial states where the
arguments of the function being called point to protected regions
of the stack (esp. argument locations).

  * In CompCertX the initial memory states are identical, so an
    elaborate criterion is used to exclude pathological cases.
    A great deal of proof effort is spent using this criterion
    to establish Stacking's invariants (the mechanics of external
    calls are unchanged).

  * Compositional CompCert introduces a complex block ownership
    system to specify which blocks may be modified by the
    environment at any given time, and must track reachability
    properties about these blocks.

  * By contrast, our `stacking` simulation convention
    (`backend/Stackingproof.v:71) simply requires that argument
    values be mapped to a region of the target memory outside of
    the image of the source memory. Preservation of invariants at
    external calls follows from the original constraints CompCert
    places on the semantics of external functions, reframed as
    the CKLR `injp`.

While in both CompCertX and Compositional CompCert, the size of
the Stacking proof more than doubles, our approach increases it
by at most ~33%.

*Relationship to separate compilation.*
As noted, our submission fails to address the relationship
between our notion of semantic horizontal composition on one hand,
and on the other hand the notion of syntactic program linking used to
define separate compilation in modern versions of CompCert.
A different version of our development (`compcerto.tar.bz2`)
contains a small-step version of the composition operator
(`common/SmallstepLinking.v`).
We then prove that the semantics of assembly programs obtained
through CompCert's syntactic linking operator refines the
composed semantics of the components
([[p1]] ⊕ [[p2]] ⊑ [[p1 + p2]], `x86/AsmLinking.v`).

## Status of §4

Refinement-based game semantics is the horizon of the research
program that prompted our work on CompCert, as well as the
motivation behind its specific design. For example, in the
context of heterogenous verification, we need to decompose systems in
complicated ways: to specifying
the composition of a UART device and serial port driver (perhaps
as a component of type $\text{RS232} \rightarrow \mathcal{C}$),
we need to relate calls to the driver's C functions to activity on the
serial line. Such a goal precludes the approach to
compositionality taken in SepCompCert (which understands the
behavior of components only by reference to a whole-program
semantics), or the limitations of Compositional CompCert
(which uses a single type of interaction and simulation convention).

Since the small-step model of §3 is cumbersome for
compositional reasoning and its algebraic properties are very
limited, in §4 we outline a more general and denotational game
model, but this model has not been completely
mechanized yet. We believe the work described in §3
already demonstrates the benefits of a game approach
in the context of compositional compilation,
however the status of §4 as
preliminary work should perhaps have been made more explicit.

## Related work

Our work draws from a wide array of research and is situated
within a very active field.
The *Related work* section needs to be greatly
expanded and we are grateful for the reviewers' help
in pointing us towards relevant work.

---

Below we provide answers to reviewers' specific questions and
requests for clarifications, to be consulted at their discretion.

---

## Review #68A

> Are initial, final, resumption and interacting states disjoint?
> [Definition 3.1]

The CompCert definition of a determinate semantics is updated to
enforce that at most one of step/final/external applies to any state,
but this is not a general restriction. Initial and resumption
states can always terminate or interact immediately.

> Is there a difference between "simulation" and "refinement
> conventions" (l. 602 vs. l. 607)?

No, thank you for pointing this out. They are both meant to read
"simulation convention".

> What does the $≼^Q_F$ relation mean on l. 627? My guess is that
> it is the $R^Q$ relation in Definition 3.2, but I am not sure
> (it doesn't look like it could be the refinement relation of l.
> 371).  Similar comment for l. 634.

Yes you are right. We will rename both $R$ (Def. 2.3) and
$\preceq^Q_F$ etc. to a name that does not conflict with
the simulation relation or the refinement of simulation conventions.

> Should $W_E$ on l. 632 be $W_F$?
> 
> It is not intuitive what the $w'$ on l. 634 does not need to be
> related to $w$, or that the world is only allowed to evolved on
> external calls. Some explanation would help.

In a component of type $E \rightarrow F$, the game $E$ and $F$
are played with opposite polarities: in $F$ the environment asks
the questions and the system produces an answer (this corresponds
to initial and final states); in $E$ the system gets to ask
questions, and receive corresponding answers from the environment
(this corresponds to external calls). This is what we mean by the
incoming/outgoing language interfaces and simulation conventions.

Moreover, contrary to what happens in the context of
CKLRs (and traditionally in Kripke models), until §3.6
our sets of worlds are very "flat" and worlds do not evolve.
Every time the systems perform an external call (matching
questions of $E_1$ and $E_2$), the simulation gets to choose a
world $w' \in W_E$ to relate them, and corresponding returns
(answers of $E_1$ and $E_2$) are guaranteed to be related at the
*exact same* world $w'$. Conversely, when the environment
initially invokes the systems (matching questions of $F_1$ and
$F_2$), the simulation is provided with a world $w \in W_F$
relating the questions, and any answers eventually generated by
final states must be shown to be related at the same world $w$.

We will rename $w'$ to $w_E$ and $w$ to $w_F$.

> What is the $·$ operator on relations on l. 655? It cannot be
> just relation composition, since the relations are ternary and
> have different indices...

You are right. The basic relation composition $\cdot$ to KLRs as
follows:

$[(w_1, w_2) \Vdash R \cdot S] = [w_1 \Vdash R] \cdot [w_2 \Vdash S]$

> The definition of `inject_incr` is only indirectly given (l.
> 778). Also, what is $\mathsf{option}^{≤}$?

Fig. 4 should use $\subseteq$ rather than `inject_incr`,
and $\mathsf{option}^{\le}$ should have been defined in Fig. 2
alongside the other relators (it mirrors
$\mathcal{P}^{\le}$ when option values are interpreted as sets of
cardinality $\le 1$, and is defined as `option_le` in
`coqrel/OptionRel.v`).

> Shouldn't the injection component of `ext` be $* ↦ (b ↦ (b, 0))$?
> [l. 770] Also, what are `Mem.extends` and `Mem.inject`?

You are right about `ext`. Defining the CompCert memory model's
`Mem.extends` and `Mem.inject` relations on memory states is not
possible in reasonable space, but we should
mention them by name in §3.5 and refer the reader to reference
[37] for more details.

> > In particular, an external function acting on the memory
> > state should not synthesize block identifiers and pointers,
> > but can only follow pointers passed as arguments or fetched
> > from the memory itself. [l. 793]
> 
> I imagine that your framework would still allow external
> functions to allocate memory, so I do not understand what you
> are trying to say here.

Indeed, the sentence is missing allocation as a valid way to
obtain block numbers. By "synthesize" here, we mean forge block
numbers arbitrarily rather than obtaining them through the memory
model's operations (including allocation).

> Shouldn't $W$ in l. 804 be `meminj`?
> 
> Definition 3.8 is hard to grasp.  I expected more intuition
> about the meaning of the two memory components in the worlds
> (e.g. I don't know what a "newly allocated block" is (l. 808)).
> What is the difference between $⇝_{\mathsf{injp}}$ (l. 804) and
> $⇝_{\mathsf{meminj}}$ (l. 812)?

You are right that $W$ should be meminj, and
$\leadsto_{\mathsf{meminj}}$ should be $\leadsto_{\mathsf{injp}}$.

The world's memory components are just a way we can remember a
copy of the memory states being related (per l.816). This is done
so that the accessibility relation can formulate constraints
relating the old pair of memory states to the new one,
contraining the ways in which the memory states can be conjointly
modified.

Because the accessibility relation is transitive, these
contraints will end up holding between the initial and final
memory states of a call. This allows us to formulate the
constraints that CompCert places on external calls
(`extcall_properties` from `common/Events.v`, and in particular
`ec_mem_inject`) within the relational framework of CKLRs.

*Newly allocated blocks* are blocks that are valid in the new
memory states but invalid in the old ones. That is, they have
been obtained through `Mem.alloc` during the stretch of
execution covered by the world transition.

> How do you define the composition of two CKLRs? [l. 822]

Thank you for pointing out the missing definition. We take the
products of the sets of worlds and of accessibility relations.
The memory injections are composed according to CompCert's
`meminj_compose`
($f(b) = (b', \delta_1) \wedge
g(b') = (b'', \delta_2) \Rightarrow
(f;g)(b) = (b'', \delta_1 + \delta_2)$).
The memory relation uses the KLR composition discussed above.

> > it suffices to show that the incoming and outgoing simulations
> > can be reconciled... [l. 844]
> 
> Unclear. I can see how the convention in l. 842 is related to
> Table 2, but I don't understand what the "incoming and outgoing
> simulations" are.

Sorry, this is meant to read "the incoming and outgoing simultion
*conventions* can be reconciled".

The *incoming* simulation convention is the one that connects the
component's codomain games ($F$s, environment queries), whereas the
*outgoing* simulation convention is the one used for the domain
games ($E$s, external calls).

> In the definition of $⊑$ (l. 886), don't you need to include
> the answers of the environment as well?

You are right, the rightmost rule should use $mns \sqsubseteq mnt$
as its conclusion.

> > Instead, we adapt the approach used in [?] [l. 911]
> 
> Broken citation.

Apologies, we meant to cite the following paper:

M. Tyrrell, J. M. Morris, A. Butterfield, and A. Hughes.
A lattice-theoretic model for an algebra of communicating
sequential processes. In International Colloquium on Theoretical
Aspects of Computing, pages 123–137. Springer, 2006.

> I do not understand the definition of $\mathbf{I}_E$ [l. 985]
> because $n$ is free [l. 985].  I imagine that the real meaning
> would be to promote individual strategies that contain plays of
> this form to elements of $\mathcal{I}_E(M_E^A)$ --
> maybe $\{ S ∣ ∀n. mnn ∈ S \}$? But I am not sure.

You are right. This could also be written as:

    $I_E(m) := \bigsqcup_{n \in M_E^A} mnn$

> Is the join in l. 1096 taken pointwise?

Yes, thank you for pointing this out.

> I imagine that the interesting aspect of the horizontal
> composition operator of l. 1102 is that it allows to reason
> about refinement compositionally, but the text does not mention
> that.

You are right.

This operator models linking: while we do have a certified
compiler, we do not have a certified *linker*, but the horizontal
composition operator serves as a linker specification (similarly
to the semantic linking operator used in Compositional CompCert).
In fact,
as discussed in the initial portion of this response, in the
`compcerto.tar.gz` variant of our work where horizontal
composition is defined at the level of small-step semantics, we
show that the assembly program linking introduced by SepCompCert
is indeed a correct implementation of (that version of)
horizontal composition.

Compositional resoning is enabled by the fact that for
$D_1, D_2$ fixed, the horizontal composition operator is
monotonic, hence if we verify individual components we can prove
that the linked program will satisfy the composition of their
specifications.

---

## Review #68B

> Please comment in more detail on the relationship of your
> framework to related work on compositional software verification
> and interface automata in particular. That strand of research
> involves similar concepts and it would be desirable to identify
> the precise nature of your contribution in this context.

We have drawn inspiration from the literature on interface
automata. In particular the papers we cite [20–22] provide an
excellent discussion of alternating refinement and the need for a
game-theoretic approach to compositional verification.

However our approach differs from that line of work in at least
the following ways:

  * The framework of interface automata seeks automation and
    therefore focuses on finite automata, whereas we are looking
    for a very general framework able to embed a wide range of
    semantic models (at the cost of largely manual proofs).
    It is however plausible that more automated verification
    tools based on interface automata could be used for specific
    components, then integrated to a more heterogenous collection
    of verified components using an embedding into
    refinement-based game semantics.

  * The notion of simulation used in §3 is reminiscent of
    alternating refinement. Among other things, a traditional
    model of nondeterminism is used, then interpreted as system
    or environment choice depending on circumstances. In the
    approach used in §4 however, the algebraic structure used to
    encode nondeterminism already makes this distinction, which
    makes the model more uniform and (our preliminary work
    suggests) more amenable to formalization in a proof assistant
    such as Coq.

---

## Review #68C

> * In Fig.1, what are i1() and i2()? Same question at line (650).

$i_1 : A \rightarrow A + B$ and $i_2 : B \rightarrow A + B$
are the two injections into the sum type / discriminated set union
$A + B$.

> * (422) What is [R] compared to R?

We use $[R]$ as the infix notation for the relation $R$.

> * Definition 3.1 is confusing. What does E represent intuitively?
>   What is B (579)? The choice of A (581) is confusing because of
>   the use of M^A_E and M^A_F, where A has a different meaning.

Intuitively, $E$ is the protocol used by the component to perform
external calls, whereas $F$ is the protocol it accepts for
incoming calls.

The $A$ and $B$ you mention were their previous names and they
were left behind as an oversight, they should be replaced by $E$
and $F$ respectively. Unfortunately $F$ also conflicts with the
name of the final state predicate, which we will rename in any
revision. (Apologies, this is indeed very confusing.)

> - Explanations of Table 2 are missing.
> * What are Eqn. (4) and Eqn. (5)?

Those refer to the self-simulations mentioned in §3.6.5 (l.830).

> * The outgoing and incoming columns should be explained. For
>   example, what does "alloc" mean in these columns, and what does
>   property (5) (line 832) mean?

The outgoing and incoming columns refer to the domain and
codomain elementary games used by the semantics of the various
languages, and the domain and codomain simulation conventions
used by the simulation proofs of the various passes. In
particular, "alloc" is simulation convention used by the Alloc
pass (defined as `cc_alloc` at `backend/Conventions.v:216` in our
artifact).

> What does "the component is given directly" (755) mean?

The component $R^{mem}$ is given as part of the definition of a CKLR.
Relations for other types ($R^{val}, R^{block}, R^{ptr}) are derived
from the `meminj` component.

> * Are properties (4) and (5) (see lines 831 and 832) two examples
>   of representative proved properties? Are the other proved
>   properties similar?

These properties are the particular lemmas that we prove using
the relational parametricity of the Clight and RTL semantics,
because they are needed to prove our main result (l.851).

> * I do not understand the simulation convention on line 842.
>   Where do the different components come from?

By composing the "Outgoing" column of Table 2 from top to bottom
on one hand, and the "Incoming" column on the other hand, we
obtain the outgoing and incoming simulation conventions of the
composition of all passes. The $\mathbb{R}_{CompCert}$ simulation
convention is designed so that both sides can be reduced to it
using the simulation convention equivalence properties of l.835
and the properties of our simulation convention algebra.

### Questions for authors’ response

> Contrary to Section 3, Section 4 does not seem to be formalized
> in Coq. Why?

We have experimented with various models when attempting to
formalize refinement-based game semantics in a Coq-friendly way,
and the contents of §4 have largely been adapted from experiments
in the Coq proof assistant. Drawing from Morris and Tyrrell's
approach to dual nondeterminism makes formalization much easier,
because it allows us to factor out the nondeterminism used to
define strategies in an elegant, algebraic way, and largely
allows us to formulate our definitions and proofs regarding
strategies by operating at the level of simple, finite plays.

However, this was a recent breakthrough and we have not yet
implemented a complete formalization and connected it to our
modified version of CompCert.

---

##  Review #68D

> pg 3, 2.1.3 Monotonicity: Monotonicity is introduced in 2.1.3,
> but never mentioned again. Does the horizontal composition
> operator of section 4.4.2 satisfy monoticity? The paper should
> answer this question one way or the other, otherwise there is
> no point in introducing monotonicity in 2.1.3.

Assuming fixed $D_1, D_2$, the horizontal composition operator of
§4.4.1 is indeed monotonic.

> pg 4, line 190: Please mention whether your plays are all
> finite, or also infinite. If they are all finite, please
> explain whether this gives you weaker guarantees than
> CompCert's current theorem, which also talks about infinite
> runs.

The plays are all finite, but in the strategies associated with
programs that can generate infinite runs, prefixes of arbitrary
length can be generated at the angel/environment's discretion.
The finiteness of plays means that Coq formalizations do not need
to deal with the complexities associated with coinductive types.

One interesting aspect of dual nondeterminism in this context is
that the distinction between angelic and demonic nondeterminism
avoids the problems with unbounded nondeterminism that would
usually result from this. (This is in part why we believe dual
nondeterminism is key to modeling refinement and nondeterminism
in the context of game semantics.)

> pg 5, line 207: "Innocence requires that the behavior of a
> strategy only depends on the most recent move as well as the
> chain of moves enabling it. This means the strategy is not
> allowed to maintain private state across successive but
> independent queries." – This explanation makes no sense and
> leads to bad a misunderstanding. In fact, the
> components/procedures can keep private state, as long as that
> is exposed in the moves. C components do keep private state!

You are right, the word "private" is confusing in this context,
perhaps "unobservable" state would be a better descriptor.

> pg 5, line 239: Composition seems important but only explained
> very much in passing. More details needed on how 2 strategies
> are combined. I guess it's choosing all common traces after
> flipping one of them ... and removing things that match from
> the trace?


> pg 6, 2.4.1 Whole-program semantics – Unclear what you mean by
> "original CompCert" semantics, since this is not only a
> "non-compositional" semantics, but also a semantics that
> CompCert itself no longer uses (e.g. the references to
> deterministic external functions seem completely dated, the
> only requirement CompCert makes today is determinacy and input
> totality of the semantics, not of the external functions).

Sorry, l.287 should have used the word "determinate" rather than
"deterministic". Our reference is CompCert v3.5.

> Also unclear why you use the same epsilon on both side of the
> turnstile, when things don't seem to be symmetric. Also unclear
> why the codomain of ε is C, and not just a return value.

You are right this is poorly explained. Components on the left of
the turnstile represent global parameters: $\epsilon$ corresponds
to the parameter `external_functions_sem` defined in CompCert's
`common/Events.v` file. By contrast, the arrow denotes a strategy
with the game on the left being used for outgoing requests and
the game on the right being used for incoming requests.

The `external_functions_sem` parameter can be interpreted as
defining a strategy for a C function call "server" that performs
a series of interactions specified by CompCert `event`s
(understood as the elementary game $\mathcal{E}$).

Perhaps we should postpone much of this discussion to the
*Related Work* section, at which point much more of the necessary
background will have been articulated by the rest of the paper.

> pg 7, 2.4.4 Unclear what's the difference between your C->C and
> Compositional CompCert's C->C, and why you use an asymmetric
> notation for ie (E->F). From what I can tell, the difference is
> that instead fixing a single C for the whole compilation chain,
> your C varies between the levels.

Yes, that is correct.

> Section 3.6 has a number of definitions (3.7, 3.8) where
> knowing some CompCert one can see where they're going, but
> still don't leave the reader satisfied. Are they as
> straightforward as they seem, is there anything interesting
> hidden in them? I found the remark in p.16 that "We expect the
> remaining components to be consistent..." to be particularly
> perplexing. Are the authors assuming something else that we're
> not being told explicitly?

The other relations are interdependent:
the relation on values is determined by $R^{ptr}$ because we want
`Vptr` to take related pointers to related values, and similarly
for $R^{block}$ we expect $(-, 0)$ to take related blocks to
related pointers.

> Table 2 is impossible to understand at this point in the paper
> and is given with zero explanations. What do the *italic* lines
> mean? What does "Clight properties" mean? What does "RTL
> properties" mean? What does "Outgoing" and "Incoming" mean, and
> why are they in this order? And what are all the names in the
> "Outgoing" and "Incoming" columns (this last one becomes a bit
> clearer in the rest of this section, but not completely).

The italic lines are identity pseudo-passes: the program is not
modified at this point but we introduce the self-simulations
proved through relational parametricity and presented in §3.6.5
(where Eqn. 4,5 appear). They are crucial to the algebraic
manipulations used in §3.7 to reconcile the incoming and outgoing
simulation convention of the overall compiler.

One way to interpret this is: several of our simulation
passes have stronger assumptions on external calls that they
provide to their own caller (`injp` vs. `inj`). This prevents
compositionality at the level of these individual passes, but we
use the relational parametricity of Clight and RTL to show that
these assumptions will necessarily hold, and our simulation
convention algebra to glue them back into the overall proof.

It is subtle to understand the dynamics of this because for
instance, the assumptions of the Cminorgen pass end up being
satisfied through properties of the Clight source program
(the second line of Table 2).

### Sloppiness about technical details

> pg 12, line 579: "The handling of incoming calls is specified
> by I ⊆ M FQ × S, which assigns a set of initial states to each
> question of B" – what B? "question of A directed to the
> environment, and Y ⊆ S × M A × SE" – what A? This notation of
> A/B and E/F is a complete mess. A should only be used answers.
> This seems like a renaming (A->E, B->F, that was never finished),
> and which is super confusing.

Your impression is correct; A and B should have been renamed to E
and F.

> - I don't get the meaning of `≼_F^Q` (line 627), `≼_E^Q ≼_E^A`
>   (line 634), `≼_F^A`.  It is not clear if they are "notions of
>   refinement associated with the simulation conventions `C_E`
>   and `C_F`" (mentioned in line 371 and any case defined only
>   at page 14).

Sorry, they are meant to denote the components relations on
questions and answers defined in $\mathbb{C}_E$ and
$\mathbb{C}_F$.

We should have used consistent names here and in Def. 3.2, that
should be distinct from both the refinement of simulation
conventions which you mention, and R which is used for the
simulation relation.

> - Is `W_E` just the first entry of the following
>   triple `C_E = (W_E, R_E^Q, R_E^A)`? Same for `W_F`.

Yes; this should be written more explicitly.

### Small things

> pg 14, line 658, Lemma 3.6: what does it mean for a strategy to
> have the type `A^# ⇒ B^#`? Is it a strategy for which game?

Sorry, this lemma should have been updated to use the same
terminology of "small-step semantics $L_1 : E_1 \rightarrow F_1$
etc, rather than $\sigma^# : A^# \rightarrow B^#$.

> pg 16, line 770: What does * (star) stand for?

Here $*$ denotes the unique element of the set of world $\{*\}$
we use for this definition (`tt : unit`).

> pg 18, line 874: "we emulate the approach taken in [? ]" – broken
> citation, not the only one – I guess you mean something like
> [39, 40]? – there are more such broken citations and references
> in the paper.

Apologies, we meant to cite the following paper which is indeed
closely connected to [39,40]:

M. Tyrrell, J. M. Morris, A. Butterfield, and A. Hughes.
A lattice-theoretic model for an algebra of communicating
sequential processes. In International Colloquium on Theoretical
Aspects of Computing, pages 123–137. Springer, 2006.
