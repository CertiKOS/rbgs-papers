\documentclass{report}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{thmtools}
\usepackage{libertine}
\usepackage[varqu]{zi4}
\usepackage{cmll}
\usepackage{listings}
\usepackage[colorlinks=true]{hyperref}
\usepackage{tikz-cd}
\usepackage{ebproof}

\newtheorem{quest}{Research Question}
\newtheorem{task}{Task}[chapter]
%\newcommand\pfun{\mathrel{\ooalign{\hfil$\mapstochar$\hfil\cr$\to$\cr}}}
\newcommand\pfun{\mathrel{\ooalign{\hfil$\mapstochar\mkern5mu$\hfil\cr$\to$\cr}}}

\lstset{
  language=C,
  basicstyle=\ttfamily\small,
  basewidth=0.5em,
  frame=single,
  numbers=left}

\title{Re-verifying CertiKOS in a modular framework}
\author{J\'er\'emie Koenig}

\begin{document}

\maketitle

\begin{abstract} %{{{
The original CertiKOS proof of correctness
championed the methodology of certified abstraction layers,
but otherwise inherited many of CompCert's limitations.
Since then,
our group has developed methods and tools
which seek to overcome these limitations,
but these tools
have not yet been incorporated into the CertiKOS proof.
In this document I outline
a set of principles and
a concrete strategy
for developing a modern version of the CertiKOS proof
to serve as a solid foundation
for our future work.
\end{abstract}
%}}}

\tableofcontents

\listoftheorems[title={List of Tasks},swapnumber]

\chapter{Introduction} %{{{

This document presents an implementation plan
for a modernized version of the CertiKOS correctness proof.
Specifically,
we wish to improve on its previous iteration
along the following dimensions:
\begin{description}
  \item[Focus on usability and best practices.]
    The original CAL framework was a daring experiment
    carried out without the benefit of hindsight.
    Now that we have a better grasp of the underlying concepts
    and more experience working with CAL,
    it is easier to engineer a well-designed system.
  \item[CompCert as a mere component.]
    The existing proof uses CompCert as a framework.
    It is modified to enable CAL but otherwise remains fairly rigid.
    By contrast we would like CompCert to be a component among others,
    which we incorporate into a much more flexible framework.
  \item more flexible and fine-grained compositionality, as opposed to rigid notion of layer;
  \item as a result, open-ended and can accommodate future work.
\end{description}

\section{Principles}

\section{Overview}

%}}}

\chapter{Semantics Library} %{{{

\section{Mathematical foundations}

Role of categories, etc

\section{Categories as modules}

How we leverage the Coq module system

%}}}

\chapter{Sequential models} %{{{

\section{Motivation} %{{{

Consider the example programs shown in \autoref{fig:readwritehello}.
The shell script \textsf{run.sh}
executes the program \textsf{secret.c}
and feeds its output to \textsf{rot13.c}.
The two programs are algorithmically trivial,
but their combined output depends on their interaction with each other
within the context of a particular execution environment.

\begin{figure}[h] % fig:readwritehello {{{
\centering
\begin{minipage}{.40\textwidth}
\begin{lstlisting}[title={secret.c}]
#include <unistd.h>
char msg[] = "uryyb, jbeyq!\n";
int main()
{
        write(1, msg, sizeof msg - 1);
        return 0;
}
\end{lstlisting}
\vspace{1em}
\begin{lstlisting}[title={typescript},language=sh]
$ secret | rot13
hello, world!
$ secret > secret.txt
$ rot13 < secret.txt
hello, world!
\end{lstlisting}
\end{minipage}
\hspace{3em}
\begin{minipage}{.45\textwidth}
\begin{lstlisting}[title={rot13.c}]
#include <unistd.h>
char rot13(char c)
{
        return c < 'a' ? c :
               c > 'z' ? c :
               (c - 'a' + 13) % 26 + 'a';
}
int main()
{
        char buf[100];
        int n = read(0, buf, sizeof buf);
        for(int i = 0; i < n; i++)
                buf[i] = rot13(buf[i]);
        write(1, buf, n);
        return 0;
}
\end{lstlisting}
\end{minipage}
\caption{Two C programs made to interact with each other
  through a pipe.}
\label{fig:readwritehello}
\end{figure}
%}}}

Existing frameworks such as
VST, CAL, CompCertM, CompCertO, CCR, \ldots
make it possible to analyze the programs themselves
and prove correctness properties about them,
but they do not provide a solution for
modeling the programs' execution within the context of a larger system
once such properties have been established.
Therefore we want to develop
a compositional ``glue'' which can
incorporate correcntess properties of this kind
into a framework where this larger context can also be modeled.

%}}}

\section{Approach} %{{{

I will use the example shown above
to illustrate the principles behind our approach.
As a starting point, we can use
CompCertO semantics to assign a behavior
to the programs:
\[
  \mathsf{Clight}(\mathrm{secret.c}) :
    \mathcal{C} \twoheadrightarrow \mathcal{C} \,,
  \qquad
  \mathsf{Clight}(\mathrm{rot13.c}) :
    \mathcal{C} \twoheadrightarrow \mathcal{C} \,.
\]
However,
this semantics describes the programs' behaviors
as \emph{C translation units}
and does not say much about how they would behave
as \emph{processes}.

One disadvantage of this view
is that it involves low-level details of the C language
such as symbol tables and memory states,
which are important for describing internal function calls,
but are no longer relevant once the program is linked and loaded.
Therefore,
as we attempt to model processes and their interactions,
we will want to reinterpret he semantics to hide these internal details.

Moreover,
the language interfaces such as $\mathcal{C}$ used by CompCertO
are rather limited as they assume that every interaction
that a component has will take the same form
and expect a response of the same type.
To model the way various processes of the system interact with one another,
it will be preferable to use a more general model,
allowing us to follow a more ``strongly typed'' approach
when we describe the shape of these interactions.

At the same time,
language interfaces are sufficient and appropriate for CompCertO,
so we have no interest in supplanting them in that context.
Overall,
our strategy for dealing with this kind of situations
will rely on the following principles:
\begin{itemize}
  \item We should always be working in the simplest appropriate model
    for any particular task.
  \item Most tasks should take the form of defining semantics
    or proving a refinement relationship.
  \item When a task which requires a rich model
    relies on components and properties formulated in a simpler model,
    we can use a refinement-preserving embedding of the simple model into the rich one.
    This allows us to use the results obtained in the simpler model
    within the context of the richer one.
  \item Conversely,
    we should decompose tasks so that
    their constituents can be reformulated as embeddings from
    the simpler models.
    This ensures that the complexity of the sub-tasks can be reduced.
\end{itemize}
In this chapter I go over some core models
of sequential computation
which we could implement in our semantics library,
and will illustrate how these principles
can be applied to modeling Unix-style processes.

%}}}

\section{Features} %{{{

\subsection{Effect signatures}

To deal with a situation like this one,
we must first model the execution environment
processes have access to.
In a sufficiently rich model we could
model file descriptor access
to standard input and output as:
\[
  \mathcal{E} := \mathcal{F} \with \mathcal{F}
  \qquad \text{where} \qquad
  \mathcal{F} := 
    \{
      \mathsf{read}[n] : \Sigma^* , \:
      \mathsf{write}[s] : \mathbb{N} \mid
      n \in \mathbb{N}, \:
      s \in \Sigma^*
    \}
  \,.
\]
Meanwhile,
processes are invoked with argument lists and return an exit status:
\[ 
  \mathcal{P} \: := \:
    \{ \mathsf{run} : \mathbb{N} \}
\]
We must then specify \emph{loading} for C programs,
which interprets C components as processes:
\[
  \begin{prooftree}
    \hypo{L : \mathcal{C} \rightarrow \mathcal{C}}
    \infer1{\mathsf{load}(L) : \mathcal{E} \rightarrow \mathcal{P}}
  \end{prooftree}
\]
We can also define the shell operators on processes:
\[
  \begin{prooftree}
    \hypo{P : \mathcal{E} \rightarrow \mathcal{P}}
    \hypo{Q : \mathcal{E} \rightarrow \mathcal{P}}
    \infer2{P \mathbin\texttt{;} Q : \mathcal{E} \rightarrow \mathcal{P}}
  \end{prooftree}
  \qquad
  \begin{prooftree}
    \hypo{P : \mathcal{E} \rightarrow \mathcal{P}}
    \hypo{Q : \mathcal{E} \rightarrow \mathcal{P}}
    \infer2{P \mathbin\texttt{|} Q : \mathcal{E} \rightarrow \mathcal{P}}
  \end{prooftree}
  \qquad
  \begin{prooftree}
    \hypo{P : \mathcal{E} \rightarrow \mathcal{P}}
    \hypo{Q : \mathcal{E} \rightarrow \mathcal{P}}
    \infer2{P \mathbin\texttt{\&} Q : \mathcal{E} \rightarrow \mathcal{P}}
  \end{prooftree}
\]
This would allow us to state properties such as:
\[
  \mathsf{load}(\mathrm{secret.c})
  \mathbin{\texttt{|}}
  \mathsf{load}(\mathrm{rot13.c})
  \:\vDash\:
  \mathsf{run} \cdot
  \mathsf{write}_1[\text{``hello, world!''}] \cdot
  15 \cdot
  0
\]

To formulate the $\texttt{|}$ operator,
we can use a small component
$\mathsf{pipe} : \top \rightarrow \mathcal{F} \with \mathcal{F}$,
which acts as a buffer.
Whenever $\mathsf{write}$ is called in the first component,
the corresponding data is saved at the end of the buffer.
When $\mathsf{read}$ is called in the second component,
data is 

%three levels of things we can do:
%* ; and && || require very minimal stuff
%* | or some approximation need to store state
%* & requires concurrency

%}}}

\section{The models} %{{{

CompCertO introduces the notion of simulation convention.
Simulation conventions are a powerful abstraction mechanism
but they are not supported by more traditional models.
As some of our first tasks,
we will develop models which support various combinations of:
\begin{itemize}
  \item simulation conventions,
  \item effect signatures,
  \item state encapsulation, and
  \item dual nondeterminism.
\end{itemize}

Possible models are shown in \autoref{fig:core}.
On the left is the concrete model used in CompCertO.
To the right we find increasingly abstracted game semantics models.
Each model provides compositional state constructions, and
the $\dagger$ construction from our CompCertOE work
can be applied to obtain versions of the models with
state encapsulation.
Below I expand on the construction and features of each model.

\begin{figure} % fig:core {{{
  \centering
  \begin{tikzcd}
    \mathsf{CompCertOE} \ar[r] \ar[d,hookrightarrow] &
    \mathsf{OTS} \ar[r] \ar[d,hookrightarrow] &
    \mathsf{NTS} \ar[r] \ar[d,hookrightarrow] &
    \mathsf{NTree} \ar[r] \ar[d,hookrightarrow] &
    \mathsf{RBGS} \ar[d,hookrightarrow]
    \\
    \mathsf{CompCertOE}^\dagger \ar[r] &
    \mathsf{OTS}^\dagger \ar[r] &
    \mathsf{NTS}^\dagger \ar[r] &
    \mathsf{NTree}^\dagger \ar[r] &
    \mathsf{RBGS}^\dagger
  \end{tikzcd}
  \caption{Core models in the RBGS library.}
  \label{fig:core}
\end{figure}
%}}}

\subsection{CompCertO} %{{{

Our starting point is the model used in CompCertO \cite{compcerto}.
Interfaces are of the form $A = \langle A^\circ, A^\bullet \rangle$,
providing a set of questions and a set of answers.
A component $L : A \rightarrow B$
handles incoming calls in $B$ and performs outgoing calls in $A$.
A simulation convention $R : A \leftrightarrow A'$
defines an abstraction relationship between interfaces.
Simulations are given types such as:
\[
  \phi : L \le_{R_A \rightarrow R_B} L'
  \qquad \qquad
  \begin{tikzcd}[sep=tiny]
    A \ar[rr, "L"] \ar[dd, leftrightarrow, "R"'] & &
    B \ar[dd, leftrightarrow, "S"] \\
    & \phi & \\
    A' \ar[rr, "L'"'] & & B'
  \end{tikzcd}
\]

This model is specialized to the CompCert context.
As a result
it must account for silent divergence, and
it involves CompCert-specific aspects like
component domains and symbol tables.
Our approach will be to develop compatible but more flexible models
which retain the conceptual novelties of CompCertO
(namely simulation conventions)
but get rid of its more idiosyncratic aspects.

%}}}

\subsection{Open Transition Systems (OTS)} %{{{

The first step in ``cleaning up'' the CompCertO model
is to move to a more straightforward open transition system model
based on effect signatures.
The $\mathsf{OTS}$ model makes the following changes:
\begin{description}
\item[Use effect signatures]
  Instead of language interfaces,
  we would be using
  \emph{effect signatures} of the form $E = \{ m : N_m \mid m \in M \}$
  where for each question $m \in M$
  we can specify a different type for possible answers $n \in N_m$.
  A language interface $A$ corresponds to the signature
  $[A] := \{ q : A^\bullet \mid q \in A^\circ \}$.

\item[Silent divergence as undefined behavior]
  When establishing compiler correct with respect to the C standard,
  we need to show that silent divergence is preserved.
  But for our purposes,
  we can treat silent divergence as an undesirable behavior
  assimilated to $\bot$.
  This simplifies the model significantly
  because least fixed points can be obtained simply through
  Kleene-style iteration.

\item[No silent steps]
  Since we no longer need
  to distinguish silent divergence from undefined behaviors,
  it not necessary to include $\tau$ steps.
  Actions which become internal when hidden by composition
  can simply be skipped over directly;
  if there is no finite sequence of internal interactions
  which lead to an observable behavior,
  this will simply lead to an undefined behavior $\bot$.

\item[No CompCert-specific idiosyncrasies]
  The use of effect signatures make it possible to use
  a stronger approach to typing,
  where the list of methods provided by a given component
  are apparent in its type.
  As a result we no longer need to support
  the ``footprint'' or ``domain'' information
  which CompCertO includes in components so that $\oplus$
  can distinguish between cross-component and external calls.
  In the more strongly typed approach,
  the kind of mutual recursion expressed by $\oplus$
  is better controlled with trace operators, iteration theories,
  and similar approaches.

  In addition,
  in the OTS model we should make no provision for symbol tables.
  We can consider them a fixed external parameter,
  or include them in the way we embed CompCertO language interfaces
  as effect signatures,
  rather than tailoring the model to this aspect of CompCert.
\end{description}

As a result of these changes,
the new model should be much cleaner and
more amenable to theoretical analysis.
Roughly speaking,
a component of type $E \rightarrow F$
responding to a question $(q \mathbin: R) \in F$
will encode a behavior
as a coalgebra for an endofunctor:
\[
  \mathrm{F} : \mathbf{Rel} \rightarrow \mathbf{Rel}
  \qquad \text{defined as} \qquad
  \mathrm{F} X := R \oplus \bigoplus_{(m \mathbin: N) \in E} (N \pfun X)
  \,,
\]
that is a set $S$ of states together with the relation:
\[
  \sigma \: : \: S \: \rightarrow \: \mathcal{P}
    \Big( R \: + \sum_{(m \mathbin: N) \in E} \mathcal{P}(N \times S) \Big)
  \,.
\]

The notions of simulation convention and simulation
used in CompCertO
should be easy to adapt
to this new context.
Then we can embed
the language semantics and correctness properties of CompCertO
into the $\mathsf{OTS}$ model,
where they could be used as part of
larger and more heterogeneous
system descriptions and correctness proofs.

\begin{task}[Mechanize the OTS model in the RBGS library]
Formalizing the model should be straightforward.
We can use it as a case study to develop the interfaces of the RBGS library.
\end{task}

\begin{task}[Embed CompCertO semantics into OTS]
Given the similarity between CompCertO semantics and OTS,
it should be easy to embed CompCertO transition systems.
One challenge might be to deal with CompCertO-specific aspects
such as symbol environments and $\oplus$.
\end{task}

%}}}

\subsection{Dual non-determinism (NTS)} %{{{

The model presented in the previous section
should be enough to connect DeepSEA and CompCertO,
and to carry out other tasks of this kind.
However is should be fairly straightforward to extend it
to increase its expressiveness significantly
by factoring in dual nondeterminism
and formulating behaviors as:
\[
  \sigma \: : \: S \: \rightarrow \: \mathsf{FCD}
    \Big( R \: + \sum_{(m \mathbin: N) \in E}
        \big( N \rightarrow \mathsf{FCD}(S) \big) \Big)
  \,.
\]

%}}}

\subsection{Terminal coalgebra (NTree)}

\subsection{Refinement-based game semantics (RBGS)}

\subsection{Hidden state construction ($\dagger$)}

%}}}

\section{OOPSLA submission} %{{{

\subsection{Processes and Combinators}

We use the ``process environment'' example
outlined at the beginning of this chapter
as a running example.

\begin{task}[Model a rudimentary execution environment]
Next we would use the OTS model to describe a simple execution environment
including a toy file system model.
We will need to model a notion of process within the effect signature framework,
develop shell operators such as \texttt{;} etc, and
model the OS kernel as a distinct component that they access.
\end{task}

\noindent
Below I give definitions for the various moving parts.

\subsubsection{Loaders}

Recall that for a transition system
$L : \mathcal{C} \rightarrow \mathcal{C}$,
we want to define the process
$\mathsf{load}(L) : \mathcal{E} \rightarrow \mathcal{P}$.
There are several moving parts involved:
\begin{itemize}
  \item On the incoming side,
    we must prepare and execute the initial call to $\mathsf{main}$
    and interpret its return value.
    We do this by defining a transition system
    $\mathsf{init}_L : \mathcal{C} \rightarrow \mathcal{P}$.
  \item On the outgoing side,
    most calls will yield an undefined behavior,
    but appropriate calls to $\mathsf{read}$ and $\mathsf{write}$
    will trigger the corresponding system calls.
    This translation is performed by
    $\mathsf{sys} : \mathcal{E} \rightarrow \mathcal{C}$.
\end{itemize}
We can then define the overall loader as
\[
  \mathsf{load}_\mathcal{C}(L) \: := \:
  \mathsf{init}_L \odot L \odot \mathsf{sys} \: : \:
  \mathcal{E} \rightarrow \mathcal{P}
  \,.
\]
The component $\mathsf{init}_L$ is the one that will
compute and instantiate the symbol table and initial memory
from the CompCert program skeleton associated with $L$.
Based on this, it can be defined by the rules:
\[
  S := \mathbf{1} + \mathbb{N}
  \qquad \qquad
  \begin{prooftree}
    \hypo{\mathsf{init\_mem(L) = m}}
    \infer1{
      \mathsf{run}
      \mathrel{I}
      \iota_1({*})
      \mathrel{X}
      \mathsf{main}(\epsilon) @ m
    }
  \end{prooftree}
  \qquad \qquad
  \begin{prooftree}
    \infer0{
      \mathsf{Vint}(x)@m'
      \: \mathrel{Y}^{\iota_1(*)} \:
      \iota_2(x)
      \: \mathrel{F} \:
      x}
  \end{prooftree}
\]
The component $\mathsf{sys}$ can be defined by:
\[
  S ::= C^\circ + C^\bullet
  \qquad \qquad
  \begin{prooftree}
    \hypo{m : buf \mapsto {-}^n}
    \infer1{
      \mathsf{read}(i :: buf :: n)
      \mathrel{I}
      \iota_1({*})
      \mathrel{X}
      \mathsf{main}(\epsilon) @ m
    }
  \end{prooftree}
  \qquad \qquad
  \begin{prooftree}
    \infer0{
      \mathsf{Vint}(x)@m'
      \: \mathrel{Y}^{\iota_1(*)} \:
      \iota_2(x)
      \: \mathrel{F} \:
      x}
  \end{prooftree}
\]

%}}}

\section{Further Tasks} %{{{

\begin{itemize}
\item Interface with DeepSEA
\item Explore further models (NTS, NTree, RBGS)
\end{itemize}

%}}}


%}}}

\chapter{Verifying Sequential Layers} %{{{

\section{CompCertO}
\section{Memory Separation}
\section{Code Proofs}

\chapter{Architecture-level Code}
\section{Memory Management}
\section{Interrupts}
\section{Concrete Stacks}
\section{Binary Code}

\chapter{Concurrency}
\section{Scheduled Threads}
\section{Multi-processors}

%}}}

\chapter{External Resources}

\chapter{Plan}

\end{document}
