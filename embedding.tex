\documentclass[11pt]{article}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz-cd}
\usepackage{stmaryrd}
\usepackage{bussproofs}

\bibliographystyle{plain}

\newcommand{\kw}[1]{{\mathsf{#1}}}

\title{Game Semantics for Compcert}

\begin{document}

\maketitle

\section{Overview}

The distinguishing feature of game semantics
compared to usual trace models of process calculi (say)
is the assignment of a polarity to events \cite{cspgs},
classifying them into moves of the system
and moves of the environement.
Traditionally,
this distinction is reflected in the definition of a strategy,
which can determine the moves of the system
but has no control over the moves of the environment.
Strategies are the main object of interest.
A notion of refinement can be derived
to carry out domain-theoretic constructions,
but refinement in traditional game semantics
is usually defined in very extensional way.

By contrast,
I am pursuing a \emph{refinement-based approach} to game semantics,
where refinement plays a fundamental role,
and the main game-theoretic ingredient is the use of
\emph{alternating} refinement \cite{altref}.
Then
the distinction between game trees, specifications, and strategies
becomes less crucial,
in a way that is reminiscent of pure subtype systems \cite{pts}:
a specification is just a refinement of a game,
which restricts the possible moves of the players further.
A strategy can be defined as
a specification where the behavior of the system is deterministic,
however strategies no longer play a central role in the theory.

\subsection{Trees}

A game tree over a set of moves $M$
is a possibly infinite, rooted tree
with edges labelled by the moves in $M$.
Nodes denote positions in the game, and
paths from the root outward correspond to
possible executions.

In the traditional game semantics literature,
game trees are often given as prefix-closed sets of
execution traces.
However, in a refinement-centric context it is more tractable
to specify a tree $\tau$ by giving
a labelled transition system $\delta$ that generates it.
We can show that two trees are equal by
establishing a bisimulation between transition systems that generate them.
We can always find a transition system that generates $\tau$:
there is a most general transition system $d$
over the type of trees itself,
which has a transition
$\tau \stackrel{m}{\Longrightarrow} \tau'$
whenever the tree $\tau$ has an $m$-labelled edge
from its root to a subtree $\tau'$.
The transition system $d$ will generate back any
tree $\tau$ that is used as its initial state.

Trees will acquire their game-theoretic meaning
once we assign a polarity to each move.
Alternating simulations of transition systems
will correspond to the alternating refinement of
the game trees they generate

\subsection{Refinement}

Alternating refinement treats moves differently depending on
the polarity that is assigned to them.
For a polarity assignment $p : M \rightarrow \{ {+}, {-} \}$, we
write $\tau_1 \sqsubseteq_p \tau_2$ and
say that $\tau_1$ refines $\tau_2$ iff
any positive move possible in $\tau_1$
is also possible in $\tau_2$,
any negative move possible in $\tau_2$
is also possible in $\tau_1$,
and for any move possible in both trees,
the corresponding subtree in $\tau_1$ refines
the corresponding subtree in $\tau_2$.

Roughly speaking,
positive moves will correspond to outputs of the system being modelled,
whereas negative moves will correspond to inputs.
Thinking of trees as specifications,
the refinement $\tau_1 \sqsubseteq \tau_2$
expresses the idea that
$\tau_1$ has weaker requirements on inputs than $\tau_2$,
and stronger guarantees on outputs.
However we will benefit from
remaining conceptually and formally flexible
in our choice of $p$.

The refinement relation $\sqsubseteq_p$ is a partial order
equipped with the structure of a complete bounded lattice.
The tree $\bot_p$ has all negative moves, and is a minimal element.
The tree $\top_p$ has all positive moves, and is a maximal element.
The join $\bigsqcup^p_i \tau_i$ takes
the union of the positive moves possible in each tree,
and the intersection of the negative moves.
For each possible move in the resulting set,
we recursively take the join of the corresponding subtrees in each of the $(\tau_i)$.
The meet $\bigsqcap^p_i \tau_i$ is defined similarly but takes
the intersection of positive moves and
the union of negative moves.

Note that reversing the polarity of moves
reverses the order and
exchanges $\bot$ with $\top$ and $\sqcup$ with $\sqcap$.
Moreover, for $p = +$ (all events are considered positive moves),
we get the inclusion order
$\subseteq$, $\cup$, $\cap$, $\varnothing$, $1$, where
$\varnothing$ denotes the empty tree, and
$1$ denotes the full, infinite tree on $M$.

%\subsection{Players}
%
%We need to remain flexible in how
%moves are assigned to the system or the environment,
%because it may be useful to use different assignments
%depending on the context.
%Two examples illustrate this.
%
%First, there are situations where
%we want to split a system into a number of components,
%and focus on the behavior of an \emph{active set} $A$ of components.
%However, instead of limiting out attention to
%the boundary between $A$ and $\bar{A}$
%and hiding the internal behavior of the two subsystems,
%we want to consider ``global logs'' that include internal events.
%In that case,
%the types of traces and trees we manipulate will not depend on $A$,
%however the refinement order $\sqsubseteq_A$
%will interpret events as system moves or environment moves
%depending on whether the originating component belongs to $A$ or $\bar{A}$.
%
%Second, in our treatment of divergence,
%we will also want to interpret $\Uparrow$ as a system or environment move
%depending on the context.
%Encoding divergence as a system move
%leads to a notion of refinement that expresses \emph{total correctness},
%whereas
%encoding divergence as an environment move
%leads to a notion of refinement that expresses \emph{partial correctness}.
%For program verification,
%we want to show total correctness:
%a diverging program should not be regarded as
%a correct implementation of arbitrary specifications.
%However,
%domain-theoretic fixed points used to interpret recursion
%rely on an ordering which expresses partial correctness,
%with divergence as the bottom ``default''
%to which more and more behaviors are added
%as we construct the fixpoint.

\subsection{Compcert semantics}

Whereas Compcert only gives semantics to whole programs,
our goal is define define a compositional semantics
of open modules for Compcert languages.

The semantics of Compcert languages describe
the behavior of invoking a program's \texttt{main()} function
with no arguments,
in terms of a trace of events and a final, \texttt{int} return value.
To define a module semantics for the languages of Compcert,
we must first describe the ways in which a module can be invoked,
and the result that it may produce.
This will be captured by the notion of \emph{language interface}
which specifies a type of \emph{queries} $Q$ and a type of \emph{replies} $R$
used by a given language.

Next, we must intergrate queries and replies to
the definition of Compcert small-step semantics.
In Compcert, a small-step semantics is described as
a transition system $L = (S, I, \rightarrow, F)$, where
$S$ is a set of states,
$I \subseteq S$ is a set of initial states,
${\rightarrow} \subseteq S \times \mathbb{E}^* \times S$
is a transition relation labelled by lists of events, and
$F \subseteq S \times \kw{int}$ is a set of final states
and their associated integer results.
To make it possible for the transistion system to
interact with its environment
through a sequence of queries and replies,
we parametrize small-step semantics by
a language interface $\mathcal{L} = (Q, R)$,
and generalize the types of $I$ and $F$ to be:
\begin{align*}
  I &\subseteq Q \times S \\
  F &\subseteq S \times R \times \mathcal{P}(Q \times S)
\end{align*}
The ``initial state'' predicate
now takes a query $q \in Q$ as a parameter.
Conversely the ``final state'' predicate
provides a reply $r \in R$ as a generalized result,
but it also provides a continuation $k \subseteq Q \times S$,
which given a further query specifies how to resume the execution.
Note that continuations
have the same type as the ``initial state'' predicate.

\subsection{Language Interfaces}

The specific language interface $\kw{C}$
is used to describe the function calls in most high-level Compcert languages.
Its queries are $Q_\kw{C} = \{ f(\vec{v})@m \}$
where $f : \kw{ident}$ is a function identifier,
$\vec{v} : \kw{list}\ \kw{val}$ is a list of actual parameters, and
$m : \kw{mem}$ is the memory state at function entry;
the replies are $R_\kw{C} = \{ v'@m' \}$,
where $v' : \kw{val}$ is the value returned by $f$ and
$m' : \kw{mem}$ is the memory state at function exit.

To account for external calls,
given two language interfaces
$\mathcal{L}_E = (Q_E, R_E)$ and
$\mathcal{L}_I = (Q_I, R_I)$,
we can define the composite interface
$\mathcal{L}_E \multimap \mathcal{L}_I$
in the following way:
\begin{align*}
  Q_{\mathcal{L}_E \multimap \mathcal{L}_I} &:=
    Q_I + \{ \bar{r} \:|\: r \in R_E \} \\
  R_{\mathcal{L}_E \multimap \mathcal{L}_I} &:=
    R_I + \{ \bar{q} \:|\: q \in Q_E \}
\end{align*}
The language interface $\mathcal{L}_I$
gives the types of incoming calls and corresponding returns.
But instead of immediately replying to an incoming call of $Q_I$
with a return in $R_I$,
the module may perform an external call
according to the interface $\mathcal{L}_E$:
it will ``reply'' with a query of $Q_E$,
and expect a subsequent ``query'' from the replies of $R_E$
to resume its execution.

\subsection{Compcert games}

The game associated with a language interface $\mathcal{L} = (Q, R)$
has the moves
$q \in Q$, $r \in R$, $e \in \mathbb{E}$, $\Uparrow$ and $\lightning$.
In addition to queries $q$ and replies $r$,
the moves $e$ denote Compcert events,
$\Uparrow$ denotes divergence,
and $\lightning$ is used to distinguish unsafe behaviors.
The $q$ moves are inputs,
while the $r$, $e$ and $\lightning$ moves are outputs.
The status of the $\Uparrow$ move depends on the context:
it can be considered
an output if we wish to express total correctness ($\kw{tc}$), or
an input if we wish to express partial correctness ($\kw{pc}$).

The framework of
Compcert small-step semantics and backward simulations
can be embedded into
the setting of game trees and (total-correctness) alternating refinements:
\begin{equation}
  \AxiomC{$L_1 \ge L_2$}
  \UnaryInfC{$\llbracket L_2 \rrbracket \sqsubseteq_\kw{tc} \llbracket L_1 \rrbracket$}
  \DisplayProof
  \label{eqn:hcompm}
\end{equation}

\subsection{Horizontal composition}

We want to define a composition operator $\bullet$
with two important properties.
First, like all of our operators,
we expect it to be monotonic, so that:
\begin{equation}
  \AxiomC{$\sigma_1 \sqsubseteq_\kw{tc} \sigma_1'$}
  \AxiomC{$\sigma_2 \sqsubseteq_\kw{tc} \sigma_2'$}
  \BinaryInfC{$\sigma_1 \bullet \sigma_2 \sqsubseteq_\kw{tc}
                \sigma_1' \bullet \sigma_2'$}
  \DisplayProof
  \label{eqn:embed}
\end{equation}

Second,
for some Compcert languages $L$,
we will want \emph{syntactic linking} theorems,
namely:
\begin{equation}
  \llbracket L(M_1 + M_2) \rrbracket =
  \llbracket L(M_1) \rrbracket \bullet
  \llbracket L(M_2) \rrbracket
  \label{eqn:slink}
\end{equation}
This is particularly useful for $L = \kw{Asm}$,
but if we prove it for $L = \kw{Clight}$ as well
we could derive a separate compilation theorem
in the style of SepCompCert.

Finally, we will also need to show that the projection operators
associated with our calling conventions
commute with horizontal composition.

\section{Formalizing game trees}

Game trees over a set of moves $M$
are potentially infinite trees with
edges labelled by $M$.
They contain at least a root,
then at each node,
for each possible move $m \in M$
we can attach zero or one subtree.

\subsection{Characterization}

This can be characterized as the coinductive type for the functor:
\[ F X = M \rightarrow \mathcal{P}^1(X)\, \]
where $\mathcal{P}^1(X)$ denotes the type of sets of at most one $X$.
An $F$-coalgebra is a type $A$
together with a destructor of type $\delta : A \rightarrow F A$.
In this case, a coalgebra is a deterministic transition system
labeled by the moves in $M$,
with states in $A$ and a transition relation:
\[ \delta : A \rightarrow M \rightarrow \mathcal{P}^1(A) \, . \]

The type of trees $T$ itself is characterized as a final $F$-colagebra.
There is a destructor:
\[ d : T \rightarrow M \rightarrow \mathcal{P}^1(T) \, , \]
which tells us for each possible move $m \in M$
to which subtree we ``transition'' (if any).
This coalgebra is final in that for any other coalgebra $\delta$,
there is a unique mapping $c_{\delta} : A \rightarrow T$
such that the following diagram commutes:
\[
  \begin{tikzcd}
    A \arrow[r, "\delta"]
      \arrow[d, "c_{\delta}"] &
    F A \arrow[d, "F \, c_\delta"] \\
    T \arrow[r, "d"] &
    F T
  \end{tikzcd}
\]

This anamorphism $c_\delta$ is
the fundamental constructor for trees:
we give a transition system $\delta$ and an initial state $a \in A$
and obtain a tree.
The diagram above explains how the tree is generated:
there is a transition $\delta : a \stackrel{m}{\Longrightarrow} a'$ iff
the subtree associated with $m$ is $c_{\delta}(a')$.
Formally,
\[
  \forall a \, m \,.\,
    d(c_{\delta}(a), m) = \{ c_{\delta}(a') : a' \in \delta(a, m) \}
\]
The uniqueness of $c_\delta$ is
the fundamental way to prove two trees are equal,
and in particular gives us extensionality
in terms of bisimulations.

We can characterize the alternating refinement of trees
in the following way.
Given a relation $R \subseteq A \times B$,
we can build a relation $F R$ that will relate
two transition systems $\alpha, \beta$ iff
$R$ is an alternating simulation relation between them.
Then we can characterize the alternating refinement of trees $\sqsubseteq$
with the following properties:
\begin{gather*}
  c \, [\forall R \, . \, F R \rightarrow R \rightarrow {\sqsubseteq}] \, c \\
  d \, [{\sqsubseteq} \rightarrow F {\sqsubseteq}] \, d
\end{gather*}

\subsection{Interface}

For convenience,
in the interface I separate the determinism condition
for labelled transition systems, and define:
\begin{gather*}
  \kw{lts}_M(A) :=
    A \rightarrow M \rightarrow A \rightarrow \kw{Prop} \\
  \kw{lts\_determ}(\alpha) :=
    \forall a \, m \, a_1' \, a_2' \,.\,
      \{ a_1', a_2' \} \subseteq \alpha(a, m) \Rightarrow
      a_1' = a_2'
\end{gather*}

(...)

\subsection{Implementation}

To avoid having to deal with Coq coinductive types,
I follow the usual technique of representing trees as
prefix-closed sets of traces:
\[
  T = \{ P : M^* \rightarrow \kw{Prop} \ \vert\ 
    P(\varepsilon) \wedge
    \forall u v \,.\, P(u v) \Rightarrow P(u) \}
\]
However this is insubstantial.
The important thing is that I can define the primitives $c, d$
introduced in the previous section and prove that they
satisfy the required properties.

(...)


\section{Embedding Compcert semantics}

Take a Compcert semantics $L = (S, I, F, \rightarrow)$,
with $S$ the set of states,
$I \subseteq Q \times S$
the initial-state predicate,
$F \subseteq S \times R \times \mathcal{P}(Q \times S)$
the final-state predicate, and
${\rightarrow} \subseteq S \times \mathbb{E}^* \times S$
the transition relation (labelled by lists of Compcert events).
To generate the corresponding game tree $\llbracket L \rrbracket$,
I use the LTS defined inductively
from the rules given in Fig.~\ref{fig:embed},
which uses the following states:
\begin{description}
\item[$\kw{waiting}(k)$]
  Read a query $q \in Q$,
  then continue execution according to the continuation
  $k \subseteq Q \times S$.
  The initial state is $\kw{waiting}(I)$.
\item[$\kw{running}(t, s)$]
  Output the pending events in $t \in \mathbb{E}^*$,
  then big-step the transition relation from the current state $s \in S$
  to determine the next move.
\item[$\kw{silent}$]
  We have hit a silently diverging state.
  At the time we output a $\Uparrow$ move;
  now, never do anything again.
\item[$\kw{wrong}$]
  We have hit a stuck state;
  now, generate all possible outputs forever.
\end{description}
Note that that $c_\delta(\kw{wrong}) = \top_\kw{tc}$,
which is the property we want for programs that go wrong.
Moreover, this is the only way to generate a $\lightning$ output,
so that going wrong is distinguishable from
a hypothetical program or specification that would
generate all possible safe outputs.

\begin{figure}
\[
  \AxiomC{$(q, s) \in k$}
  \UnaryInfC{$\kw{waiting}(k) \stackrel{q}{\Longrightarrow} \kw{running(\varepsilon, s)}$}
  \DisplayProof
  \quad
  \AxiomC{$(s, r, k) \in F$}
  \UnaryInfC{$\kw{running}(\varepsilon, s) \stackrel{r}{\Longrightarrow} \kw{waiting}(k)$}
  \DisplayProof
\]
\vspace{.5em}
\[
  \AxiomC{\rule[-.3\baselineskip]{0pt}{\baselineskip}}
  \UnaryInfC{$\kw{running}(e::t, s) \stackrel{e}{\Longrightarrow} \kw{running}(t, s)$}
  \DisplayProof
  \quad
  \AxiomC{$s \stackrel{t}{\longrightarrow} s'$}
  \AxiomC{$\kw{running}(t, s') \stackrel{m}{\Longrightarrow} S$}
  \BinaryInfC{$\kw{running}(\varepsilon, s) \stackrel{m}{\Longrightarrow} S$}
  \DisplayProof
\]
\vspace{.5em}
\[
  \AxiomC{$\kw{Forever\_silent}(s)$}
  \UnaryInfC{$\kw{running}(\varepsilon, s) \stackrel{\Uparrow}{\Longrightarrow} \kw{silent}$}
  \DisplayProof
  \quad
  \AxiomC{$m \mbox{ is an output move}$}
  \UnaryInfC{$\kw{wrong} \stackrel{m}{\Longrightarrow} \kw{wrong}$}
  \DisplayProof
\]
\vspace{.5em}
\[
  \AxiomC{$\kw{Nostep}(s)$}
  \AxiomC{$\forall r k . (s, r, k) \notin F$}
  \AxiomC{$\kw{wrong} \stackrel{m}{\Longrightarrow} S$}
  \TrinaryInfC{$\kw{running}(\varepsilon, s) \stackrel{m}{\Longrightarrow} S$}
  \DisplayProof
\]
\caption{Embedding Compcert small-step semantics into game trees}
\label{fig:embed}
\end{figure}

Using this definition,
I have proved (\ref{eqn:embed}): if we have a backward simulation between
Compcert small-step semantics,
then we have an alternating refinement between
the corresponding game trees.

\section{Horizontal composition}

\subsection{Basic approach}

Following \cite{cpp15},
we define horizontal composition in two steps.
The \emph{flat composition} of two behaviors $\sigma_1 \uplus \sigma_2$
takes both the behaviors of $\sigma_1$ and $\sigma_2$ side-by-side,
but calls of $\sigma_1$ into $\sigma_2$ and conversely remain
external calls of the composite behavior.
We then introduce a \emph{resolution} operator $\mathcal{R}(\sigma)$,
which uses copies of $\sigma$ to handle any such ``internal external'' calls
that $\sigma$ makes into itself.
Horizontal composition is
$\sigma_1 \bullet \sigma_2 = \mathcal{R}(\sigma_1 \uplus \sigma_2)$.

In our setting
we can define flat composition as
$\sigma_1 \sqcap_\kw{tc} \sigma_2$,
which gives monotonicity for free.\footnote{%
This is one of several possible definitions which coincide when
$\sigma_1 \cap \sigma_2 = \varnothing$.}
The resolution operator is defined as the limit
$\bigsqcup^\kw{pc}_{n \in \mathbb{N}} \mathcal{R}_n(\sigma)$
of depth-limited operators $\mathcal{R}_n$ described below.

Additionally,
to prove the syntactic linking theorems (\ref{eqn:slink})
we will want to use a version of horizontal composition
defined at the level of small-step semantics,
so I define a small-step flat composition $\uplus$
and resolution operator $\kw{R}$,
and will show that they commute with our embedding:
\[
  \llbracket L_1 \uplus L_2 \rrbracket =
    \llbracket L_1 \rrbracket \sqcap_\kw{tc}
    \llbracket L_2 \rrbracket
  \qquad
  \llbracket \kw{R}(L) \rrbracket =
    \mathcal{R}(\llbracket L \rrbracket)
\]
Then to prove syntactic linking we can use a pair of forward simulations:
\[
  L(M_1 + M_2) \ \le\  \kw{R}(L(M_1) \uplus L(M_2)) \ \le\  L(M_1 + M_2)
\]
We can show (\ref{eqn:slink}) by
turning the forward into backward simulations,
embedding the backward simulations into refinements using (\ref{eqn:embed}),
applying our commutation properties, and
finally using antisymmetry of refinement.

\subsection{Small-step flat composition}

Given a family $(L_i)$ of Compcert small-step semantics,
with $L_i = (S_i, I_i, F_i, {\rightarrow_i})$,
we can define their flat composition $\biguplus_i L_i = (S, I, F, {\rightarrow})$
by using the disjoint union of their sets of states:
\begin{align*}
  S &:= \sum_i S_i \\
  I &:= \{ (q, (i, s)) \: \vert \: (q, s) \in I_i \} \\
  F &:= \{ ((i, s), r, k@i) \: \vert \: (s, r, k) \in F_i \} \\
  {\rightarrow} &:= \{ ((i, s), t, (i, s')) \: \vert \: s
\stackrel{t}{\rightarrow}_i s' \}
\end{align*}
where $k@i = \{ (q, (i, s)) \: \vert (q, s) \in k \}$
lifts the continuations of $L_i$ to the level of $L$.
Note that $I = \bigcup_i I_i@i$.

Showing the correspondance
$\llbracket \biguplus_i L_i \rrbracket =
 \bigsqcap_i^\kw{tc} \llbracket L_i \rrbracket$
should be straightforward
when the $L_i$'s have disjoint sets of accepted initial queries.

\subsection{Small-step resolution}

Take $L = (S_L, I_L, F_L, {\rightarrow_L})$ a small-step semantics
for the language interface $\mathcal{L} \multimap \mathcal{L}$.
We will write the queries of $\mathcal{L} \multimap \mathcal{L}$
as $\bar{r}$ and $q$,
whereas its replies will be written
as $\bar{q}$ and $r$.
Here $\bar{q}$ represents external calls from the module into the environment,
and $\bar{r}$ is a corresponding return into the module.

We can define $\kw{R}(L) = (S, I, F, {\rightarrow})$ in the following way:
\begin{align*}
  S := &\: S_L \times \mathcal{P}(Q_{\mathcal{L} \multimap \mathcal{L}} \times S_L)^* \\
  I := &\: \{ (q, (s, \varepsilon)) \: \vert \: (q, s) \in I_L \} \\
  F := &\: \{ ((s, S), r, k@S) \: \vert \:
           (s, r, k) \in F_L \: \wedge \: r \mbox{ observable at } S \} \\
  {\rightarrow} := &\: \{ ((s, S), t, (s', S)) \: \vert \: s \stackrel{t}{\longrightarrow}_L s' \} \\
    \cup &\: \{ ((s, S), \varepsilon, (s', k::S)) \: \vert \:
        (s, \bar{q}, k) \in F_L \: \wedge \:
        (q, s') \in I_L \} \\
    \cup &\: \{ ((s, k::S), \varepsilon, (s', S)) \: \vert \:
        (s, r, -) \in F_L \: \wedge \:
        (\bar{r}, s') \in k \}
\end{align*}
The states of $\kw{R}(L)$
consist of a state $s$ of $L$ together with a stack of continuations of $L$.
The stack is initially empty,
and $s$ is initialized following $I_L$.
Internal steps of $\rightarrow_L$ operate on the current state of $\kw{R}(L)$
without modifying the stack.
When a final state of $L$ is reached, three cases are possible:
\begin{description}
\item[Observable replies] are simply passed to the environment
  by triggering a final state of $\kw{R}(L)$.
  An external call of the form $r = \bar{q}$ is observable
  if $q$ does not have a corresponding initial state in $L$.
  An actual reply $r$ is observable when the continuation stack is empty.
  The continuation $k$ will be lifted to
  $k@S := \{ (r, (s, S)) \: \vert \: (r, s) \in k \}$.
\item[Recursive calls] happen when
  $(s, \bar{q}, k) \in F_L$ and $(q, s') \in I_L$.
  In this case, the call is handled as an internal step of $\kw{R}(L)$
  where the continuation $k$ is pushed on the stack,
  and $s$ is used as the new current state.
\item[Returns from recursive calls] happen when $(s, r, -) \in F_L$
  with $r$ an actual return, but the continuation stack is non-empty.
  In this case, the topmost continuation $k$ is popped
  and we pass $r$ to $k$ to obtain the next state $s'$.
\end{description}

\subsection{Gametree resolution operator}

Take $\sigma$ a behavior on the Compcert game for
$\mathcal{L} \multimap \mathcal{L}$.
The moves for this game are $q, r, \bar{q}, \bar{r}, e, \Uparrow, \lightning$.
Again, $\bar{q}, \bar{r}$ represent external calls and their returns
back into the module,
by contrast with the original $q$ and $r$ which represent
incoming calls and the module returning to the environment.

The tree for $\mathcal{R}(\sigma)$ is generated
using the LTS $\Rightarrow$ defined inductively
by the rules shown in Fig.~\ref{fig:res}.
The states are lists of gametrees arranged in a control stack.
The initial state is $\sigma :: \varepsilon$.
As a reminder,
the notation $d(\tau, m) = \{\tau'\}$ means
the tree $\tau$ has the next move $m$
and the corresponding subtree is $\tau'$.
Since $d(\tau, m)$ has at most one element,
as a shorthand I write $d(\tau, m) = \tau'$.

\begin{figure}
\[
  \AxiomC{$m \mbox{ observable at } S$}
  \AxiomC{$d(\tau, m) = \tau'$}
  \BinaryInfC{$\tau :: S \stackrel{m}{\Longrightarrow} \tau' :: S$}
  \DisplayProof
\]
\vspace{.5em}
\[
  \AxiomC{$d(\tau, \bar{q}) = \kappa$}
  \AxiomC{$d(\sigma, q) = \nu$}
  \AxiomC{$\nu :: \kappa :: S \stackrel{m}{\Longrightarrow} S'$}
  \TrinaryInfC{$\tau :: S \stackrel{m}{\Longrightarrow} S'$}
  \DisplayProof
\]
\vspace{.5em}
\[
  \AxiomC{$d(\nu, r) \ne \varnothing$}
  \AxiomC{$d(\kappa, \bar{r}) = \tau$}
  \AxiomC{$\tau :: S \stackrel{m}{\Longrightarrow} S'$}
  \TrinaryInfC{$\nu :: \kappa \stackrel{m}{\Longrightarrow} S'$}
  \DisplayProof
\]
\vspace{.5em}
\[
  \AxiomC{$\kw{Forever\_unobservable}(S)$}
  \UnaryInfC{$S \stackrel{\Uparrow}{\Longrightarrow} \varepsilon$}
  \DisplayProof
\]
\caption{LTS for the resolution operator
  $\mathcal{R}(\sigma)$ on games trees.}
\label{fig:res}
\end{figure}

During normal execution we follow the topmost behavior in the stack.
Observable moves are any moves that do not trigger a recursive call
or non-toplevel return.
The moves $q$, $\bar{r}$, $e$, $\Uparrow$, and $\lightning$
are always observable.
In addition,
an external call $\bar{q}$
is observable if $d(\sigma, q) = \varnothing$,
and a return $r$
is observable when the control stack $S$ has no continuations.

Whenever we encounter a recursive call,
we will use a copy of $\sigma$
to initialize a new behavior $\nu$ and push it on the stack.
When the current behavior returns,
we drop it and use the next element on the stack as a continuation.
In both cases,
the moves that triggered to call and return are hidden,
so we use the constructed state to perform a recursive query
and obtain the next observable move.

It is possible that hiding recursive calls
will result in divergence events not originally present in $\sigma$.
For instance, consider:
\begin{align*}
  \sigma := \: &\llbracket \kw{Clight}(\mbox{\tt void n() \{ \}}) \rrbracket \: + \\
 &\llbracket \kw{Clight}(\mbox{\tt void f() \{ for(;;) n(); \}}) \rrbracket
\end{align*}
In this case, $\sigma$ will contain the behaviors
$n() \cdot \kw{r}$ and $f() \cdot (\bar{n}() \cdot \bar{\kw{r}})^\omega$.
In $\mathcal{R}(\sigma)$,
we substitute the behavior for $n$ within the behavior for $f$,
which should yield the behavior $f() \cdot \Uparrow$.
To identify such cases we introduce the coinductive predicate
$\kw{Forever\_unobservable}(S)$,
defined by the following rules:
\[
  \AxiomC{$d(\tau, \bar{q}) = \kappa$}
  \AxiomC{$d(\sigma, q) = \tau'$}
  \AxiomC{$\kw{Forever\_unobservable}(\tau' :: S)$}
  \TrinaryInfC{$\kw{Forever\_unobservable}(\tau :: \kappa :: S)$}
  \DisplayProof
\]
\[
  \AxiomC{$d(\tau, r) \ne \varnothing$}
  \AxiomC{$d(\kappa, \bar{r}) = \tau')$}
  \AxiomC{$\kw{Forever\_unobservable}(\tau' :: S)$}
  \TrinaryInfC{$\kw{Forever\_unobservable}(\tau :: \kappa :: S)$}
  \DisplayProof
\]

\vfill

\bibliography{lwcc}

\end{document}
